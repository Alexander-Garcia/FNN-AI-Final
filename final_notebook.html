<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>final_notebook</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Phase---1:-Data-analysis-&amp;-preparation">Phase - 1: Data analysis &amp; preparation<a class="anchor-link" href="#Phase---1:-Data-analysis-&amp;-preparation">¶</a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Viewing-the-data">Viewing the data<a class="anchor-link" href="#Viewing-the-data">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'heart_statlog_cleveland_hungary_final.csv'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Index(['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol',
       'fasting blood sugar', 'resting ecg', 'max heart rate',
       'exercise angina', 'oldpeak', 'ST slope', 'target'],
      dtype='object')</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(1190, 12)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[5]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<div class="colab-df-container" id="df-3e9f7f2d-765b-44df-b3be-032b5a9709db">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>age</th>
<th>sex</th>
<th>chest pain type</th>
<th>resting bp s</th>
<th>cholesterol</th>
<th>fasting blood sugar</th>
<th>resting ecg</th>
<th>max heart rate</th>
<th>exercise angina</th>
<th>oldpeak</th>
<th>ST slope</th>
<th>target</th>
</tr>
</thead>
<tbody>
<tr>
<th>0</th>
<td>40</td>
<td>1</td>
<td>2</td>
<td>140</td>
<td>289</td>
<td>0</td>
<td>0</td>
<td>172</td>
<td>0</td>
<td>0.0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<th>1</th>
<td>49</td>
<td>0</td>
<td>3</td>
<td>160</td>
<td>180</td>
<td>0</td>
<td>0</td>
<td>156</td>
<td>0</td>
<td>1.0</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<th>2</th>
<td>37</td>
<td>1</td>
<td>2</td>
<td>130</td>
<td>283</td>
<td>0</td>
<td>1</td>
<td>98</td>
<td>0</td>
<td>0.0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<th>3</th>
<td>48</td>
<td>0</td>
<td>4</td>
<td>138</td>
<td>214</td>
<td>0</td>
<td>0</td>
<td>108</td>
<td>1</td>
<td>1.5</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<th>4</th>
<td>54</td>
<td>1</td>
<td>3</td>
<td>150</td>
<td>195</td>
<td>0</td>
<td>0</td>
<td>122</td>
<td>0</td>
<td>0.0</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<div class="colab-df-buttons">
<div class="colab-df-container">
<button class="colab-df-convert" onclick="convertToInteractive('df-3e9f7f2d-765b-44df-b3be-032b5a9709db')" style="display:none;" title="Convert this dataframe to an interactive table.">
<svg height="24px" viewbox="0 -960 960 960" xmlns="http://www.w3.org/2000/svg">
<path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
</svg>
</button>
<style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>
<script>
      const buttonEl =
        document.querySelector('#df-3e9f7f2d-765b-44df-b3be-032b5a9709db button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-3e9f7f2d-765b-44df-b3be-032b5a9709db');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
</div>
<div id="df-702aa296-1d3a-4998-9fa2-bc77e12e77cd">
<button class="colab-df-quickchart" onclick="quickchart('df-702aa296-1d3a-4998-9fa2-bc77e12e77cd')" style="display:none;" title="Suggest charts">
<svg height="24px" viewbox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
<g>
<path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
</g>
</svg>
</button>
<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>
<script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-702aa296-1d3a-4998-9fa2-bc77e12e77cd button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1190 entries, 0 to 1189
Data columns (total 12 columns):
 #   Column               Non-Null Count  Dtype  
---  ------               --------------  -----  
 0   age                  1190 non-null   int64  
 1   sex                  1190 non-null   int64  
 2   chest pain type      1190 non-null   int64  
 3   resting bp s         1190 non-null   int64  
 4   cholesterol          1190 non-null   int64  
 5   fasting blood sugar  1190 non-null   int64  
 6   resting ecg          1190 non-null   int64  
 7   max heart rate       1190 non-null   int64  
 8   exercise angina      1190 non-null   int64  
 9   oldpeak              1190 non-null   float64
 10  ST slope             1190 non-null   int64  
 11  target               1190 non-null   int64  
dtypes: float64(1), int64(11)
memory usage: 111.7 KB
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[7]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr>
<th>age</th>
<td>0</td>
</tr>
<tr>
<th>sex</th>
<td>0</td>
</tr>
<tr>
<th>chest pain type</th>
<td>0</td>
</tr>
<tr>
<th>resting bp s</th>
<td>0</td>
</tr>
<tr>
<th>cholesterol</th>
<td>0</td>
</tr>
<tr>
<th>fasting blood sugar</th>
<td>0</td>
</tr>
<tr>
<th>resting ecg</th>
<td>0</td>
</tr>
<tr>
<th>max heart rate</th>
<td>0</td>
</tr>
<tr>
<th>exercise angina</th>
<td>0</td>
</tr>
<tr>
<th>oldpeak</th>
<td>0</td>
</tr>
<tr>
<th>ST slope</th>
<td>0</td>
</tr>
<tr>
<th>target</th>
<td>0</td>
</tr>
</tbody>
</table>
</div><br/><label><b>dtype:</b> int64</label>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[8]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<div class="colab-df-container" id="df-1d989902-8b6d-41c1-97f9-9c259a0df80d">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>age</th>
<th>sex</th>
<th>chest pain type</th>
<th>resting bp s</th>
<th>cholesterol</th>
<th>fasting blood sugar</th>
<th>resting ecg</th>
<th>max heart rate</th>
<th>exercise angina</th>
<th>oldpeak</th>
<th>ST slope</th>
<th>target</th>
</tr>
</thead>
<tbody>
<tr>
<th>count</th>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
<td>1190.000000</td>
</tr>
<tr>
<th>mean</th>
<td>53.720168</td>
<td>0.763866</td>
<td>3.232773</td>
<td>132.153782</td>
<td>210.363866</td>
<td>0.213445</td>
<td>0.698319</td>
<td>139.732773</td>
<td>0.387395</td>
<td>0.922773</td>
<td>1.624370</td>
<td>0.528571</td>
</tr>
<tr>
<th>std</th>
<td>9.358203</td>
<td>0.424884</td>
<td>0.935480</td>
<td>18.368823</td>
<td>101.420489</td>
<td>0.409912</td>
<td>0.870359</td>
<td>25.517636</td>
<td>0.487360</td>
<td>1.086337</td>
<td>0.610459</td>
<td>0.499393</td>
</tr>
<tr>
<th>min</th>
<td>28.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>60.000000</td>
<td>0.000000</td>
<td>-2.600000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<th>25%</th>
<td>47.000000</td>
<td>1.000000</td>
<td>3.000000</td>
<td>120.000000</td>
<td>188.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>121.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
</tr>
<tr>
<th>50%</th>
<td>54.000000</td>
<td>1.000000</td>
<td>4.000000</td>
<td>130.000000</td>
<td>229.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>140.500000</td>
<td>0.000000</td>
<td>0.600000</td>
<td>2.000000</td>
<td>1.000000</td>
</tr>
<tr>
<th>75%</th>
<td>60.000000</td>
<td>1.000000</td>
<td>4.000000</td>
<td>140.000000</td>
<td>269.750000</td>
<td>0.000000</td>
<td>2.000000</td>
<td>160.000000</td>
<td>1.000000</td>
<td>1.600000</td>
<td>2.000000</td>
<td>1.000000</td>
</tr>
<tr>
<th>max</th>
<td>77.000000</td>
<td>1.000000</td>
<td>4.000000</td>
<td>200.000000</td>
<td>603.000000</td>
<td>1.000000</td>
<td>2.000000</td>
<td>202.000000</td>
<td>1.000000</td>
<td>6.200000</td>
<td>3.000000</td>
<td>1.000000</td>
</tr>
</tbody>
</table>
</div>
<div class="colab-df-buttons">
<div class="colab-df-container">
<button class="colab-df-convert" onclick="convertToInteractive('df-1d989902-8b6d-41c1-97f9-9c259a0df80d')" style="display:none;" title="Convert this dataframe to an interactive table.">
<svg height="24px" viewbox="0 -960 960 960" xmlns="http://www.w3.org/2000/svg">
<path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
</svg>
</button>
<style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>
<script>
      const buttonEl =
        document.querySelector('#df-1d989902-8b6d-41c1-97f9-9c259a0df80d button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-1d989902-8b6d-41c1-97f9-9c259a0df80d');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
</div>
<div id="df-9bbd8ad4-ba79-456d-b80b-b41bd0b393ff">
<button class="colab-df-quickchart" onclick="quickchart('df-9bbd8ad4-ba79-456d-b80b-b41bd0b393ff')" style="display:none;" title="Suggest charts">
<svg height="24px" viewbox="0 0 24 24" width="24px" xmlns="http://www.w3.org/2000/svg">
<g>
<path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
</g>
</svg>
</button>
<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>
<script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-9bbd8ad4-ba79-456d-b80b-b41bd0b393ff button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Correlations-and-data-distribution">Correlations and data distribution<a class="anchor-link" href="#Correlations-and-data-distribution">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">plt_index</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">c_name</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">plt_index</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">c_name</span><span class="p">)</span>
  <span class="n">plt_index</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"coolwarm"</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">".2f"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">"target"</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[11]:</div>
<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html" tabindex="0">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>count</th>
</tr>
<tr>
<th>target</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<th>1</th>
<td>629</td>
</tr>
<tr>
<th>0</th>
<td>561</td>
</tr>
</tbody>
</table>
</div><br/><label><b>dtype:</b> int64</label>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Shuffle,-np-conversion,-and-splitting">Shuffle, np conversion, and splitting<a class="anchor-link" href="#Shuffle,-np-conversion,-and-splitting">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># set numpy print options</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">formatter</span><span class="o">=</span><span class="p">{</span><span class="s1">'float'</span><span class="p">:</span> <span class="s1">'</span><span class="si">{: 0.2f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># convert DF to numpy array for normalizing</span>
<span class="n">np_data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">np_data</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[13]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>array([[ 40.00,  1.00,  2.00,  140.00,  289.00,  0.00,  0.00,  172.00,
         0.00,  0.00,  1.00,  0.00],
       [ 49.00,  0.00,  3.00,  160.00,  180.00,  0.00,  0.00,  156.00,
         0.00,  1.00,  2.00,  1.00],
       [ 37.00,  1.00,  2.00,  130.00,  283.00,  0.00,  1.00,  98.00,
         0.00,  0.00,  1.00,  0.00],
       [ 48.00,  0.00,  4.00,  138.00,  214.00,  0.00,  0.00,  108.00,
         1.00,  1.50,  2.00,  1.00],
       [ 54.00,  1.00,  3.00,  150.00,  195.00,  0.00,  0.00,  122.00,
         0.00,  0.00,  1.00,  0.00]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">np_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># just checking shuffle</span>
<span class="n">np_data</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[15]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>array([[ 44.00,  1.00,  4.00,  135.00,  491.00,  0.00,  0.00,  135.00,
         0.00,  0.00,  2.00,  1.00],
       [ 61.00,  0.00,  4.00,  130.00,  330.00,  0.00,  2.00,  169.00,
         0.00,  0.00,  1.00,  1.00],
       [ 38.00,  1.00,  3.00,  115.00,  0.00,  0.00,  0.00,  128.00,
         1.00,  0.00,  2.00,  1.00],
       [ 57.00,  1.00,  4.00,  95.00,  0.00,  1.00,  0.00,  182.00,
         0.00,  0.70,  3.00,  1.00],
       [ 64.00,  1.00,  4.00,  144.00,  0.00,  0.00,  1.00,  122.00,
         1.00,  1.00,  2.00,  1.00]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># integer for splitting the data in the next steps</span>
<span class="n">index_20percent</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">np_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span>
<span class="n">index_20percent</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[16]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>238</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># remove last column (target)</span>
<span class="n">XVALID</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[:</span><span class="n">index_20percent</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">YVALID</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[:</span><span class="n">index_20percent</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">XTRAIN</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[</span><span class="n">index_20percent</span><span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">YTRAIN</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[</span><span class="n">index_20percent</span><span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'age'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [19]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'resting bp'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">YTRAIN</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'train output'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">YVALID</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Validation output'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">mean</span> <span class="o">=</span> <span class="n">XTRAIN</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">XTRAIN</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">XTRAIN</span> <span class="o">-=</span> <span class="n">mean</span>
<span class="n">XTRAIN</span> <span class="o">/=</span> <span class="n">std</span>

<span class="n">XVALID</span> <span class="o">-=</span> <span class="n">mean</span>
<span class="n">XVALID</span> <span class="o">/=</span> <span class="n">std</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [22]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[ 53.70  0.77  3.22  132.28  208.96  0.21  0.68  139.93  0.39  0.93  1.62]
[ 9.24  0.42  0.94  18.53  99.32  0.41  0.86  25.45  0.49  1.10  0.62]
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [23]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># verify the values are normalize between 0 and 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'age column'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Phase---2:-Intentional-Overfit">Phase - 2: Intentional Overfit<a class="anchor-link" href="#Phase---2:-Intentional-Overfit">¶</a></h1><ul>
<li>For this phase <strong>do not</strong> split data into training and validation</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [24]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [25]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [26]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>(1190, 11) (1190,)
11
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Overfit-with-1-neuron-(No-overfit-~83%25-acc)">Overfit with 1 neuron (No overfit ~83% acc)<a class="anchor-link" href="#Overfit-with-1-neuron-(No-overfit-~83%25-acc)">¶</a></h2><ul>
<li>256 epochs</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [27]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># set up network architecture</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_one_neuron"</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile model</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [28]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
38/38 [==============================] - 1s 1ms/step - loss: 1.1680 - accuracy: 0.3101
Epoch 2/256
38/38 [==============================] - 0s 1ms/step - loss: 1.0771 - accuracy: 0.3361
Epoch 3/256
38/38 [==============================] - 0s 1ms/step - loss: 0.9970 - accuracy: 0.3672
Epoch 4/256
38/38 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.4143
Epoch 5/256
38/38 [==============================] - 0s 1ms/step - loss: 0.8534 - accuracy: 0.4622
Epoch 6/256
38/38 [==============================] - 0s 1ms/step - loss: 0.7927 - accuracy: 0.5210
Epoch 7/256
38/38 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.5874
Epoch 8/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.6345
Epoch 9/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6706
Epoch 10/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6117 - accuracy: 0.7151
Epoch 11/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5798 - accuracy: 0.7513
Epoch 12/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7622
Epoch 13/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7697
Epoch 14/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7832
Epoch 15/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7933
Epoch 16/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7891
Epoch 17/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7992
Epoch 18/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.8050
Epoch 19/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.8092
Epoch 20/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.8118
Epoch 21/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.8134
Epoch 22/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.8151
Epoch 23/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.8176
Epoch 24/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8193
Epoch 25/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4183 - accuracy: 0.8168
Epoch 26/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8193
Epoch 27/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8218
Epoch 28/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8252
Epoch 29/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4072 - accuracy: 0.8261
Epoch 30/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.8269
Epoch 31/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4035 - accuracy: 0.8286
Epoch 32/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4019 - accuracy: 0.8294
Epoch 33/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8286
Epoch 34/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8277
Epoch 35/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8261
Epoch 36/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3969 - accuracy: 0.8269
Epoch 37/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8277
Epoch 38/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8311
Epoch 39/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8319
Epoch 40/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8336
Epoch 41/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8328
Epoch 42/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3926 - accuracy: 0.8353
Epoch 43/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8353
Epoch 44/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8345
Epoch 45/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8336
Epoch 46/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8336
Epoch 47/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8336
Epoch 48/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8353
Epoch 49/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8336
Epoch 50/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.8353
Epoch 51/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8328
Epoch 52/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8319
Epoch 53/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8345
Epoch 54/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8345
Epoch 55/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8345
Epoch 56/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8345
Epoch 57/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8345
Epoch 58/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8345
Epoch 59/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8345
Epoch 60/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8345
Epoch 61/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8345
Epoch 62/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8336
Epoch 63/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8353
Epoch 64/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8345
Epoch 65/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3879 - accuracy: 0.8336
Epoch 66/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8303
Epoch 67/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8319
Epoch 68/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8303
Epoch 69/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8286
Epoch 70/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8311
Epoch 71/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3877 - accuracy: 0.8311
Epoch 72/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8294
Epoch 73/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8328
Epoch 74/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8294
Epoch 75/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8345
Epoch 76/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8311
Epoch 77/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8336
Epoch 78/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8353
Epoch 79/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8345
Epoch 80/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8336
Epoch 81/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8336
Epoch 82/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8345
Epoch 83/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8345
Epoch 84/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8345
Epoch 85/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8336
Epoch 86/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8353
Epoch 87/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8345
Epoch 88/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8361
Epoch 89/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8345
Epoch 90/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8353
Epoch 91/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8311
Epoch 92/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 93/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 94/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8319
Epoch 95/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 96/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 97/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 98/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 99/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8345
Epoch 100/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 101/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 102/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8336
Epoch 103/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 104/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 105/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 106/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 107/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 108/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 109/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 110/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 111/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 112/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 113/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 114/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 115/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 116/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 117/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 118/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 119/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 120/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8336
Epoch 121/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 122/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 123/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 124/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8336
Epoch 125/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 126/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 127/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8336
Epoch 128/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 129/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 130/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 131/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 132/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 133/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 134/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 135/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 136/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 137/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 138/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 139/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8336
Epoch 140/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 141/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 142/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 143/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 144/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 145/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 146/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 147/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 148/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 149/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8336
Epoch 150/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 151/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 152/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 153/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 154/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 155/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 156/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 157/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 158/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8336
Epoch 159/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 160/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 161/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 162/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 163/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 164/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 165/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 166/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 167/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 168/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 169/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 170/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8303
Epoch 171/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 172/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 173/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 174/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8311
Epoch 175/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 176/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 177/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 178/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 179/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 180/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 181/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 182/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8311
Epoch 183/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 184/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 185/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 186/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 187/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 188/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8303
Epoch 189/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8303
Epoch 190/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 191/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8303
Epoch 192/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 193/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 194/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 195/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 196/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 197/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 198/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 199/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8311
Epoch 200/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8303
Epoch 201/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 202/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 203/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8311
Epoch 204/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 205/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 206/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8311
Epoch 207/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8311
Epoch 208/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 209/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 210/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 211/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8294
Epoch 212/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8303
Epoch 213/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 214/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 215/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 216/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 217/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 218/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 219/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 220/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 221/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 222/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 223/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 224/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 225/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 226/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 227/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 228/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 229/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8303
Epoch 230/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 231/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 232/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 233/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 234/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 235/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 236/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 237/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 238/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 239/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 240/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 241/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 242/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 243/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 244/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 245/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8311
Epoch 246/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 247/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8311
Epoch 248/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8319
Epoch 249/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8319
Epoch 250/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 251/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 252/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8328
Epoch 253/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 254/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 255/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 256/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[28]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e785a31c6d0&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Overfit-with-a-2x1-network-(No-overfit-~85%25-acc)">Overfit with a 2x1 network (No overfit ~85% acc)<a class="anchor-link" href="#Overfit-with-a-2x1-network-(No-overfit-~85%25-acc)">¶</a></h2><ul>
<li>256 epochs</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [29]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># add more neurons</span>
<span class="n">overfit_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_2x1"</span><span class="p">)</span>
<span class="n">overfit_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">overfit_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

<span class="c1"># compile new overfit model</span>
<span class="n">overfit_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [30]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">overfit_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
38/38 [==============================] - 0s 1ms/step - loss: 0.7482 - accuracy: 0.4571
Epoch 2/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6890 - accuracy: 0.6487
Epoch 3/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6983
Epoch 4/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.7496
Epoch 5/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.7681
Epoch 6/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5721 - accuracy: 0.7832
Epoch 7/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7924
Epoch 8/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7950
Epoch 9/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.8000
Epoch 10/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.8042
Epoch 11/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8084
Epoch 12/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.8126
Epoch 13/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.8143
Epoch 14/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.8143
Epoch 15/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.8168
Epoch 16/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.8227
Epoch 17/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8227
Epoch 18/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.8277
Epoch 19/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.8294
Epoch 20/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.8303
Epoch 21/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.8311
Epoch 22/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.8311
Epoch 23/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8319
Epoch 24/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.8311
Epoch 25/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.8328
Epoch 26/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.8345
Epoch 27/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.8361
Epoch 28/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8361
Epoch 29/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8361
Epoch 30/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4204 - accuracy: 0.8378
Epoch 31/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8378
Epoch 32/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8387
Epoch 33/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8378
Epoch 34/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.8353
Epoch 35/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8336
Epoch 36/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8336
Epoch 37/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.8319
Epoch 38/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8353
Epoch 39/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4076 - accuracy: 0.8345
Epoch 40/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8345
Epoch 41/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8345
Epoch 42/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8361
Epoch 43/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8361
Epoch 44/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8353
Epoch 45/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8345
Epoch 46/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8336
Epoch 47/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8328
Epoch 48/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8319
Epoch 49/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8328
Epoch 50/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8319
Epoch 51/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8336
Epoch 52/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8303
Epoch 53/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8336
Epoch 54/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3923 - accuracy: 0.8353
Epoch 55/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8328
Epoch 56/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3908 - accuracy: 0.8311
Epoch 57/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8328
Epoch 58/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8353
Epoch 59/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8319
Epoch 60/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3881 - accuracy: 0.8345
Epoch 61/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8328
Epoch 62/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8336
Epoch 63/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8336
Epoch 64/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.8319
Epoch 65/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8370
Epoch 66/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8370
Epoch 67/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8395
Epoch 68/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8370
Epoch 69/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8387
Epoch 70/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.8403
Epoch 71/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8370
Epoch 72/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8403
Epoch 73/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8403
Epoch 74/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8412
Epoch 75/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3799 - accuracy: 0.8412
Epoch 76/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8412
Epoch 77/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8437
Epoch 78/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8429
Epoch 79/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8420
Epoch 80/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8412
Epoch 81/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8420
Epoch 82/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8429
Epoch 83/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8429
Epoch 84/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8437
Epoch 85/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8429
Epoch 86/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8445
Epoch 87/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8429
Epoch 88/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8412
Epoch 89/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8412
Epoch 90/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8437
Epoch 91/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8403
Epoch 92/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8420
Epoch 93/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8429
Epoch 94/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8412
Epoch 95/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8429
Epoch 96/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8437
Epoch 97/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8412
Epoch 98/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8420
Epoch 99/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8420
Epoch 100/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8429
Epoch 101/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8420
Epoch 102/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8437
Epoch 103/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8370
Epoch 104/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8395
Epoch 105/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8387
Epoch 106/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3731 - accuracy: 0.8403
Epoch 107/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3730 - accuracy: 0.8395
Epoch 108/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8387
Epoch 109/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8395
Epoch 110/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3727 - accuracy: 0.8361
Epoch 111/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8395
Epoch 112/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8378
Epoch 113/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8353
Epoch 114/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8361
Epoch 115/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8378
Epoch 116/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.8378
Epoch 117/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8378
Epoch 118/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8353
Epoch 119/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8378
Epoch 120/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8370
Epoch 121/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8378
Epoch 122/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8370
Epoch 123/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8378
Epoch 124/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8345
Epoch 125/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8361
Epoch 126/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8361
Epoch 127/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8345
Epoch 128/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8370
Epoch 129/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8370
Epoch 130/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.8387
Epoch 131/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8378
Epoch 132/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8395
Epoch 133/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8403
Epoch 134/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8378
Epoch 135/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8412
Epoch 136/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8387
Epoch 137/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8387
Epoch 138/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8387
Epoch 139/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8403
Epoch 140/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8395
Epoch 141/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8420
Epoch 142/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8420
Epoch 143/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8420
Epoch 144/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8395
Epoch 145/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8412
Epoch 146/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8420
Epoch 147/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8412
Epoch 148/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8395
Epoch 149/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8395
Epoch 150/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8395
Epoch 151/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3691 - accuracy: 0.8395
Epoch 152/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8403
Epoch 153/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3689 - accuracy: 0.8395
Epoch 154/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8395
Epoch 155/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8395
Epoch 156/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8395
Epoch 157/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8395
Epoch 158/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8378
Epoch 159/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8395
Epoch 160/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8403
Epoch 161/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8395
Epoch 162/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8395
Epoch 163/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8395
Epoch 164/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8395
Epoch 165/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8395
Epoch 166/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8387
Epoch 167/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8395
Epoch 168/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8387
Epoch 169/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8378
Epoch 170/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8403
Epoch 171/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8387
Epoch 172/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8395
Epoch 173/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8412
Epoch 174/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8412
Epoch 175/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8403
Epoch 176/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8412
Epoch 177/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8395
Epoch 178/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8420
Epoch 179/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8420
Epoch 180/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8420
Epoch 181/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8420
Epoch 182/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8412
Epoch 183/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8429
Epoch 184/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8412
Epoch 185/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8420
Epoch 186/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8420
Epoch 187/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8429
Epoch 188/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8429
Epoch 189/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8429
Epoch 190/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8429
Epoch 191/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8420
Epoch 192/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8420
Epoch 193/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8412
Epoch 194/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8412
Epoch 195/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8429
Epoch 196/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8412
Epoch 197/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8412
Epoch 198/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8412
Epoch 199/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8412
Epoch 200/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8412
Epoch 201/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8412
Epoch 202/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8387
Epoch 203/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8412
Epoch 204/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8387
Epoch 205/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8412
Epoch 206/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8420
Epoch 207/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8420
Epoch 208/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8412
Epoch 209/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8412
Epoch 210/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8403
Epoch 211/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8403
Epoch 212/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8403
Epoch 213/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8412
Epoch 214/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8403
Epoch 215/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8403
Epoch 216/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8429
Epoch 217/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8429
Epoch 218/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8437
Epoch 219/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8420
Epoch 220/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8429
Epoch 221/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8445
Epoch 222/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8445
Epoch 223/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8420
Epoch 224/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8420
Epoch 225/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8429
Epoch 226/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8429
Epoch 227/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8437
Epoch 228/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8471
Epoch 229/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8445
Epoch 230/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8437
Epoch 231/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8471
Epoch 232/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8471
Epoch 233/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8479
Epoch 234/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8462
Epoch 235/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8479
Epoch 236/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8479
Epoch 237/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8479
Epoch 238/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8462
Epoch 239/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8479
Epoch 240/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8479
Epoch 241/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8479
Epoch 242/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8479
Epoch 243/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8479
Epoch 244/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8471
Epoch 245/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8479
Epoch 246/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8479
Epoch 247/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8479
Epoch 248/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8471
Epoch 249/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8479
Epoch 250/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8471
Epoch 251/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8479
Epoch 252/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8471
Epoch 253/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8479
Epoch 254/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8479
Epoch 255/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8479
Epoch 256/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8479
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[30]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e70545df6a0&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Overfit-with-8x1-network-(No-overfit-~90%25-acc)">Overfit with 8x1 network (No overfit ~90% acc)<a class="anchor-link" href="#Overfit-with-8x1-network-(No-overfit-~90%25-acc)">¶</a></h2><ul>
<li>256 epochs</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [31]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># add more neurons</span>
<span class="n">overfit_model_2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_8x1"</span><span class="p">)</span>
<span class="n">overfit_model_2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">overfit_model_2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

<span class="c1"># compile new overfit model</span>
<span class="n">overfit_model_2</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="c1"># fit model</span>
<span class="n">overfit_model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7782
Epoch 2/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.8008
Epoch 3/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.8042
Epoch 4/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8126
Epoch 5/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8118
Epoch 6/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8151
Epoch 7/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8193
Epoch 8/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8261
Epoch 9/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.8294
Epoch 10/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8294
Epoch 11/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8319
Epoch 12/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8319
Epoch 13/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8319
Epoch 14/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8336
Epoch 15/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.8336
Epoch 16/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8311
Epoch 17/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8336
Epoch 18/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8345
Epoch 19/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8353
Epoch 20/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8361
Epoch 21/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8345
Epoch 22/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8361
Epoch 23/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8353
Epoch 24/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8370
Epoch 25/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8378
Epoch 26/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8412
Epoch 27/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8403
Epoch 28/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8403
Epoch 29/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8403
Epoch 30/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8429
Epoch 31/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8437
Epoch 32/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3589 - accuracy: 0.8429
Epoch 33/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8445
Epoch 34/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8445
Epoch 35/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8437
Epoch 36/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8462
Epoch 37/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8454
Epoch 38/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8454
Epoch 39/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8462
Epoch 40/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8454
Epoch 41/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8471
Epoch 42/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8471
Epoch 43/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8479
Epoch 44/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8479
Epoch 45/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8462
Epoch 46/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8462
Epoch 47/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8462
Epoch 48/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8454
Epoch 49/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8471
Epoch 50/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8462
Epoch 51/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8462
Epoch 52/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8454
Epoch 53/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8462
Epoch 54/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8445
Epoch 55/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8471
Epoch 56/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8462
Epoch 57/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8496
Epoch 58/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8496
Epoch 59/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8487
Epoch 60/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8496
Epoch 61/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8496
Epoch 62/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8487
Epoch 63/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8504
Epoch 64/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8504
Epoch 65/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8496
Epoch 66/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8496
Epoch 67/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8538
Epoch 68/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8546
Epoch 69/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8538
Epoch 70/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8571
Epoch 71/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8571
Epoch 72/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8588
Epoch 73/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8571
Epoch 74/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8580
Epoch 75/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8580
Epoch 76/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8622
Epoch 77/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8613
Epoch 78/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8622
Epoch 79/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8613
Epoch 80/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8630
Epoch 81/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8630
Epoch 82/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8639
Epoch 83/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8605
Epoch 84/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8605
Epoch 85/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8630
Epoch 86/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.8613
Epoch 87/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8639
Epoch 88/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8613
Epoch 89/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8630
Epoch 90/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3232 - accuracy: 0.8647
Epoch 91/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8630
Epoch 92/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8639
Epoch 93/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8630
Epoch 94/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8622
Epoch 95/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8630
Epoch 96/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8639
Epoch 97/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.8647
Epoch 98/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8647
Epoch 99/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8630
Epoch 100/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.8630
Epoch 101/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8639
Epoch 102/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8639
Epoch 103/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3176 - accuracy: 0.8647
Epoch 104/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8655
Epoch 105/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8647
Epoch 106/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8655
Epoch 107/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8655
Epoch 108/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8655
Epoch 109/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8647
Epoch 110/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8664
Epoch 111/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.8655
Epoch 112/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8655
Epoch 113/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8630
Epoch 114/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3137 - accuracy: 0.8647
Epoch 115/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8664
Epoch 116/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8672
Epoch 117/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8672
Epoch 118/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8647
Epoch 119/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8647
Epoch 120/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8655
Epoch 121/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8639
Epoch 122/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8639
Epoch 123/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.8672
Epoch 124/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8647
Epoch 125/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8672
Epoch 126/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8681
Epoch 127/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8697
Epoch 128/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.8697
Epoch 129/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8706
Epoch 130/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8664
Epoch 131/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8681
Epoch 132/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.8697
Epoch 133/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8731
Epoch 134/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.8731
Epoch 135/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.8714
Epoch 136/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8731
Epoch 137/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.8731
Epoch 138/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8723
Epoch 139/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8739
Epoch 140/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3062 - accuracy: 0.8731
Epoch 141/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8748
Epoch 142/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8773
Epoch 143/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8773
Epoch 144/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8756
Epoch 145/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8748
Epoch 146/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8773
Epoch 147/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.8790
Epoch 148/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8765
Epoch 149/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8782
Epoch 150/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8773
Epoch 151/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8807
Epoch 152/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8790
Epoch 153/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.8773
Epoch 154/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8773
Epoch 155/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8782
Epoch 156/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8773
Epoch 157/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3025 - accuracy: 0.8773
Epoch 158/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.8773
Epoch 159/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.8782
Epoch 160/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.8782
Epoch 161/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8798
Epoch 162/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8765
Epoch 163/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8782
Epoch 164/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8773
Epoch 165/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8756
Epoch 166/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8782
Epoch 167/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8765
Epoch 168/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.8790
Epoch 169/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3008 - accuracy: 0.8773
Epoch 170/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.8765
Epoch 171/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.8773
Epoch 172/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3005 - accuracy: 0.8790
Epoch 173/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8798
Epoch 174/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.8798
Epoch 175/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8832
Epoch 176/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8807
Epoch 177/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8782
Epoch 178/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8807
Epoch 179/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8815
Epoch 180/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8815
Epoch 181/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8807
Epoch 182/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2994 - accuracy: 0.8849
Epoch 183/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8824
Epoch 184/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8832
Epoch 185/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8798
Epoch 186/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2992 - accuracy: 0.8832
Epoch 187/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8832
Epoch 188/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8824
Epoch 189/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8824
Epoch 190/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8840
Epoch 191/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8849
Epoch 192/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8866
Epoch 193/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8849
Epoch 194/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8849
Epoch 195/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8849
Epoch 196/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2984 - accuracy: 0.8857
Epoch 197/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8857
Epoch 198/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8874
Epoch 199/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2983 - accuracy: 0.8857
Epoch 200/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8891
Epoch 201/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8866
Epoch 202/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8866
Epoch 203/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.8866
Epoch 204/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.8840
Epoch 205/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8849
Epoch 206/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2978 - accuracy: 0.8866
Epoch 207/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8857
Epoch 208/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2976 - accuracy: 0.8866
Epoch 209/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8857
Epoch 210/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2978 - accuracy: 0.8857
Epoch 211/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8866
Epoch 212/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2973 - accuracy: 0.8866
Epoch 213/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8849
Epoch 214/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8849
Epoch 215/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8874
Epoch 216/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8882
Epoch 217/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8874
Epoch 218/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8857
Epoch 219/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8849
Epoch 220/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2970 - accuracy: 0.8840
Epoch 221/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8874
Epoch 222/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8882
Epoch 223/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8840
Epoch 224/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8866
Epoch 225/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2970 - accuracy: 0.8874
Epoch 226/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8857
Epoch 227/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8857
Epoch 228/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8874
Epoch 229/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2966 - accuracy: 0.8882
Epoch 230/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8891
Epoch 231/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8866
Epoch 232/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2966 - accuracy: 0.8882
Epoch 233/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8916
Epoch 234/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2966 - accuracy: 0.8916
Epoch 235/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.8916
Epoch 236/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8866
Epoch 237/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8891
Epoch 238/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8857
Epoch 239/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8874
Epoch 240/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.8874
Epoch 241/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8916
Epoch 242/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.8908
Epoch 243/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2963 - accuracy: 0.8908
Epoch 244/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8899
Epoch 245/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2960 - accuracy: 0.8916
Epoch 246/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8891
Epoch 247/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8882
Epoch 248/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8908
Epoch 249/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8916
Epoch 250/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8899
Epoch 251/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8899
Epoch 252/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.8899
Epoch 253/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8899
Epoch 254/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.8924
Epoch 255/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8899
Epoch 256/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8891
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[31]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e70544d5ea0&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Overfit-8x4x1-(No-overfit-~90%25-acc)">Overfit 8x4x1 (No overfit ~90% acc)<a class="anchor-link" href="#Overfit-8x4x1-(No-overfit-~90%25-acc)">¶</a></h2><ul>
<li>256 epochs</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># add more neurons and another layer</span>
<span class="n">overfit_model_3</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_8x4x1"</span><span class="p">)</span>
<span class="n">overfit_model_3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">overfit_model_3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_3</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

<span class="c1"># compile new overfit model</span>
<span class="n">overfit_model_3</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="c1"># fit model</span>
<span class="n">overfit_model_3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5891
Epoch 2/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6966
Epoch 3/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6265 - accuracy: 0.7521
Epoch 4/256
38/38 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.7706
Epoch 5/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.7908
Epoch 6/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7983
Epoch 7/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.8050
Epoch 8/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.8092
Epoch 9/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.8126
Epoch 10/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.8143
Epoch 11/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.8227
Epoch 12/256
38/38 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8269
Epoch 13/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8319
Epoch 14/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.8437
Epoch 15/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.8445
Epoch 16/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.8429
Epoch 17/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8403
Epoch 18/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.8462
Epoch 19/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.8429
Epoch 20/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.8462
Epoch 21/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.8487
Epoch 22/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.8479
Epoch 23/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.8504
Epoch 24/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.8521
Epoch 25/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.8538
Epoch 26/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8521
Epoch 27/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8538
Epoch 28/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8546
Epoch 29/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8571
Epoch 30/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8555
Epoch 31/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8538
Epoch 32/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4086 - accuracy: 0.8571
Epoch 33/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8555
Epoch 34/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8563
Epoch 35/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8597
Epoch 36/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8571
Epoch 37/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8597
Epoch 38/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3933 - accuracy: 0.8580
Epoch 39/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8597
Epoch 40/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.8597
Epoch 41/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3880 - accuracy: 0.8571
Epoch 42/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3860 - accuracy: 0.8580
Epoch 43/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8613
Epoch 44/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8613
Epoch 45/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8597
Epoch 46/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8605
Epoch 47/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8597
Epoch 48/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3763 - accuracy: 0.8613
Epoch 49/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8639
Epoch 50/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8622
Epoch 51/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8605
Epoch 52/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8605
Epoch 53/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8613
Epoch 54/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3680 - accuracy: 0.8622
Epoch 55/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8622
Epoch 56/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8622
Epoch 57/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8605
Epoch 58/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8630
Epoch 59/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8622
Epoch 60/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8639
Epoch 61/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8630
Epoch 62/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8647
Epoch 63/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3574 - accuracy: 0.8639
Epoch 64/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8639
Epoch 65/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8655
Epoch 66/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8655
Epoch 67/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8664
Epoch 68/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8681
Epoch 69/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8681
Epoch 70/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8689
Epoch 71/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8706
Epoch 72/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8697
Epoch 73/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8697
Epoch 74/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8697
Epoch 75/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8697
Epoch 76/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8706
Epoch 77/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8706
Epoch 78/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8731
Epoch 79/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8748
Epoch 80/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8748
Epoch 81/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8782
Epoch 82/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8765
Epoch 83/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8790
Epoch 84/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8773
Epoch 85/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8790
Epoch 86/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8815
Epoch 87/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8824
Epoch 88/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8824
Epoch 89/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8824
Epoch 90/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8824
Epoch 91/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8849
Epoch 92/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8832
Epoch 93/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8832
Epoch 94/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8832
Epoch 95/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8798
Epoch 96/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8798
Epoch 97/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8815
Epoch 98/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8832
Epoch 99/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8840
Epoch 100/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8857
Epoch 101/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8815
Epoch 102/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8815
Epoch 103/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8866
Epoch 104/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8782
Epoch 105/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8824
Epoch 106/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8840
Epoch 107/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8832
Epoch 108/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8807
Epoch 109/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8832
Epoch 110/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8824
Epoch 111/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8840
Epoch 112/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8832
Epoch 113/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8857
Epoch 114/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8832
Epoch 115/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8849
Epoch 116/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8832
Epoch 117/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8815
Epoch 118/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8840
Epoch 119/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8832
Epoch 120/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8832
Epoch 121/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3224 - accuracy: 0.8824
Epoch 122/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8849
Epoch 123/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8866
Epoch 124/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8824
Epoch 125/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8849
Epoch 126/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.8849
Epoch 127/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8849
Epoch 128/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3206 - accuracy: 0.8840
Epoch 129/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8866
Epoch 130/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8857
Epoch 131/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.8866
Epoch 132/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8840
Epoch 133/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8874
Epoch 134/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8849
Epoch 135/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8857
Epoch 136/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8866
Epoch 137/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8866
Epoch 138/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3182 - accuracy: 0.8866
Epoch 139/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8866
Epoch 140/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.8866
Epoch 141/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.8866
Epoch 142/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8866
Epoch 143/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3172 - accuracy: 0.8874
Epoch 144/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3167 - accuracy: 0.8874
Epoch 145/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3166 - accuracy: 0.8874
Epoch 146/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3164 - accuracy: 0.8874
Epoch 147/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3159 - accuracy: 0.8891
Epoch 148/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8874
Epoch 149/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3156 - accuracy: 0.8891
Epoch 150/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8882
Epoch 151/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3151 - accuracy: 0.8874
Epoch 152/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8882
Epoch 153/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.8882
Epoch 154/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.8882
Epoch 155/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3141 - accuracy: 0.8891
Epoch 156/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8891
Epoch 157/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8899
Epoch 158/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8899
Epoch 159/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3134 - accuracy: 0.8891
Epoch 160/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8908
Epoch 161/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3132 - accuracy: 0.8882
Epoch 162/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8891
Epoch 163/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3127 - accuracy: 0.8908
Epoch 164/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8908
Epoch 165/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3124 - accuracy: 0.8916
Epoch 166/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8916
Epoch 167/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3120 - accuracy: 0.8916
Epoch 168/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.8891
Epoch 169/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8916
Epoch 170/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8924
Epoch 171/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8916
Epoch 172/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3112 - accuracy: 0.8916
Epoch 173/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3110 - accuracy: 0.8908
Epoch 174/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.8924
Epoch 175/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8916
Epoch 176/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3104 - accuracy: 0.8908
Epoch 177/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8933
Epoch 178/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8916
Epoch 179/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8908
Epoch 180/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8916
Epoch 181/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3096 - accuracy: 0.8924
Epoch 182/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.8916
Epoch 183/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8924
Epoch 184/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8933
Epoch 185/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8950
Epoch 186/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.8924
Epoch 187/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8899
Epoch 188/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.8908
Epoch 189/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8916
Epoch 190/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8924
Epoch 191/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8924
Epoch 192/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8899
Epoch 193/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3080 - accuracy: 0.8916
Epoch 194/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8908
Epoch 195/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8924
Epoch 196/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8916
Epoch 197/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8933
Epoch 198/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8916
Epoch 199/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.8899
Epoch 200/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8908
Epoch 201/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8924
Epoch 202/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8916
Epoch 203/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.8941
Epoch 204/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3055 - accuracy: 0.8924
Epoch 205/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3056 - accuracy: 0.8933
Epoch 206/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3053 - accuracy: 0.8916
Epoch 207/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8966
Epoch 208/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3049 - accuracy: 0.8933
Epoch 209/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3047 - accuracy: 0.8941
Epoch 210/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8950
Epoch 211/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8933
Epoch 212/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3044 - accuracy: 0.8933
Epoch 213/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3041 - accuracy: 0.8950
Epoch 214/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8950
Epoch 215/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3037 - accuracy: 0.8933
Epoch 216/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.8950
Epoch 217/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3035 - accuracy: 0.8941
Epoch 218/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8950
Epoch 219/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.8950
Epoch 220/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3030 - accuracy: 0.8916
Epoch 221/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8941
Epoch 222/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3029 - accuracy: 0.8924
Epoch 223/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8966
Epoch 224/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8950
Epoch 225/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3026 - accuracy: 0.8941
Epoch 226/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3026 - accuracy: 0.8966
Epoch 227/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.8966
Epoch 228/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8958
Epoch 229/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.8950
Epoch 230/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8941
Epoch 231/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3022 - accuracy: 0.8966
Epoch 232/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8975
Epoch 233/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.8958
Epoch 234/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8992
Epoch 235/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8975
Epoch 236/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.8983
Epoch 237/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3015 - accuracy: 0.8950
Epoch 238/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8975
Epoch 239/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8983
Epoch 240/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3013 - accuracy: 0.8966
Epoch 241/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8958
Epoch 242/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8975
Epoch 243/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.8983
Epoch 244/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8958
Epoch 245/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3007 - accuracy: 0.9000
Epoch 246/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3004 - accuracy: 0.9000
Epoch 247/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8992
Epoch 248/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8992
Epoch 249/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.8992
Epoch 250/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8975
Epoch 251/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.8992
Epoch 252/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.9017
Epoch 253/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2996 - accuracy: 0.8975
Epoch 254/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2993 - accuracy: 0.9008
Epoch 255/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8992
Epoch 256/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.8983
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[32]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e70544d5000&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Overfit-64x4x1-(success)">Overfit 64x4x1 (success)<a class="anchor-link" href="#Overfit-64x4x1-(success)">¶</a></h2><ul>
<li>256 epochs</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># add more neurons to first layer</span>
<span class="n">overfit_model_4</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_64x4x1"</span><span class="p">)</span>
<span class="n">overfit_model_4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">overfit_model_4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_4</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

<span class="c1"># compile new overfit model</span>
<span class="n">overfit_model_4</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="n">overfit_model_4</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
38/38 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6782
Epoch 2/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7866
Epoch 3/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8151
Epoch 4/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8311
Epoch 5/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8395
Epoch 6/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8395
Epoch 7/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8487
Epoch 8/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8521
Epoch 9/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8571
Epoch 10/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8605
Epoch 11/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8605
Epoch 12/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8639
Epoch 13/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8639
Epoch 14/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8647
Epoch 15/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8664
Epoch 16/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8681
Epoch 17/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8681
Epoch 18/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8706
Epoch 19/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8723
Epoch 20/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8731
Epoch 21/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8723
Epoch 22/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3079 - accuracy: 0.8714
Epoch 23/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8739
Epoch 24/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3012 - accuracy: 0.8773
Epoch 25/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2997 - accuracy: 0.8773
Epoch 26/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.8773
Epoch 27/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8798
Epoch 28/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2923 - accuracy: 0.8798
Epoch 29/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.8765
Epoch 30/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.8840
Epoch 31/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.8782
Epoch 32/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.8798
Epoch 33/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.8866
Epoch 34/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.8832
Epoch 35/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2753 - accuracy: 0.8857
Epoch 36/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8866
Epoch 37/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.8849
Epoch 38/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.8857
Epoch 39/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.8874
Epoch 40/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8882
Epoch 41/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2622 - accuracy: 0.8916
Epoch 42/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.8882
Epoch 43/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2582 - accuracy: 0.8874
Epoch 44/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.8924
Epoch 45/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2538 - accuracy: 0.8966
Epoch 46/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.8975
Epoch 47/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.9034
Epoch 48/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.8975
Epoch 49/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.8983
Epoch 50/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.8975
Epoch 51/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.8992
Epoch 52/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.9034
Epoch 53/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2378 - accuracy: 0.9000
Epoch 54/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9092
Epoch 55/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.9050
Epoch 56/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9076
Epoch 57/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.9067
Epoch 58/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9109
Epoch 59/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9101
Epoch 60/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9126
Epoch 61/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.9134
Epoch 62/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9151
Epoch 63/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9101
Epoch 64/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.9160
Epoch 65/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.9143
Epoch 66/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.9160
Epoch 67/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.9185
Epoch 68/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.9176
Epoch 69/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9218
Epoch 70/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.9202
Epoch 71/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9210
Epoch 72/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9227
Epoch 73/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.9235
Epoch 74/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9244
Epoch 75/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.9218
Epoch 76/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9252
Epoch 77/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9252
Epoch 78/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.9277
Epoch 79/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.9269
Epoch 80/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.9294
Epoch 81/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9269
Epoch 82/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9328
Epoch 83/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9269
Epoch 84/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9353
Epoch 85/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.9311
Epoch 86/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.9328
Epoch 87/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.9378
Epoch 88/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.9361
Epoch 89/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.9353
Epoch 90/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9336
Epoch 91/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9361
Epoch 92/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.9353
Epoch 93/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1705 - accuracy: 0.9361
Epoch 94/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1723 - accuracy: 0.9378
Epoch 95/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9395
Epoch 96/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9420
Epoch 97/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9403
Epoch 98/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9403
Epoch 99/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1637 - accuracy: 0.9420
Epoch 100/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9437
Epoch 101/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9403
Epoch 102/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9412
Epoch 103/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9437
Epoch 104/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9454
Epoch 105/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1570 - accuracy: 0.9445
Epoch 106/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9471
Epoch 107/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9487
Epoch 108/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9471
Epoch 109/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9471
Epoch 110/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.9479
Epoch 111/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9504
Epoch 112/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9496
Epoch 113/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9521
Epoch 114/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9487
Epoch 115/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9487
Epoch 116/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9496
Epoch 117/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9521
Epoch 118/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9487
Epoch 119/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9555
Epoch 120/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1406 - accuracy: 0.9529
Epoch 121/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9563
Epoch 122/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9555
Epoch 123/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9538
Epoch 124/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9513
Epoch 125/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9538
Epoch 126/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9588
Epoch 127/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9538
Epoch 128/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9563
Epoch 129/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1305 - accuracy: 0.9571
Epoch 130/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.9580
Epoch 131/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9580
Epoch 132/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9571
Epoch 133/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9580
Epoch 134/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9588
Epoch 135/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9605
Epoch 136/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9563
Epoch 137/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9571
Epoch 138/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9613
Epoch 139/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9630
Epoch 140/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9630
Epoch 141/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9605
Epoch 142/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9613
Epoch 143/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9630
Epoch 144/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1147 - accuracy: 0.9647
Epoch 145/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9639
Epoch 146/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.9622
Epoch 147/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9664
Epoch 148/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.9647
Epoch 149/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9681
Epoch 150/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9630
Epoch 151/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9706
Epoch 152/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9655
Epoch 153/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.9664
Epoch 154/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9697
Epoch 155/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9681
Epoch 156/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9714
Epoch 157/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.9672
Epoch 158/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9689
Epoch 159/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9664
Epoch 160/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9689
Epoch 161/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9655
Epoch 162/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9697
Epoch 163/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9689
Epoch 164/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.9714
Epoch 165/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9689
Epoch 166/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0970 - accuracy: 0.9706
Epoch 167/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.9714
Epoch 168/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0952 - accuracy: 0.9714
Epoch 169/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9714
Epoch 170/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0946 - accuracy: 0.9689
Epoch 171/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9723
Epoch 172/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9723
Epoch 173/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9706
Epoch 174/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9714
Epoch 175/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0894 - accuracy: 0.9756
Epoch 176/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.9706
Epoch 177/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9731
Epoch 178/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0871 - accuracy: 0.9739
Epoch 179/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9689
Epoch 180/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9765
Epoch 181/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9731
Epoch 182/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9731
Epoch 183/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9739
Epoch 184/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9748
Epoch 185/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9748
Epoch 186/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9731
Epoch 187/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.9756
Epoch 188/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9756
Epoch 189/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0799 - accuracy: 0.9739
Epoch 190/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9765
Epoch 191/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0781 - accuracy: 0.9782
Epoch 192/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9748
Epoch 193/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9739
Epoch 194/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9756
Epoch 195/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9739
Epoch 196/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0748 - accuracy: 0.9790
Epoch 197/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9756
Epoch 198/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9748
Epoch 199/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9756
Epoch 200/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9798
Epoch 201/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9790
Epoch 202/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9773
Epoch 203/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9815
Epoch 204/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9815
Epoch 205/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9782
Epoch 206/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9815
Epoch 207/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9790
Epoch 208/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9798
Epoch 209/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9832
Epoch 210/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9782
Epoch 211/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9807
Epoch 212/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9798
Epoch 213/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9815
Epoch 214/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9807
Epoch 215/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9807
Epoch 216/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9840
Epoch 217/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9815
Epoch 218/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9815
Epoch 219/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9815
Epoch 220/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9832
Epoch 221/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9824
Epoch 222/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9824
Epoch 223/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9824
Epoch 224/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9815
Epoch 225/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9824
Epoch 226/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0546 - accuracy: 0.9849
Epoch 227/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9832
Epoch 228/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0545 - accuracy: 0.9832
Epoch 229/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9832
Epoch 230/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9824
Epoch 231/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0531 - accuracy: 0.9824
Epoch 232/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9849
Epoch 233/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9832
Epoch 234/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9832
Epoch 235/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0513 - accuracy: 0.9849
Epoch 236/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9832
Epoch 237/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0511 - accuracy: 0.9832
Epoch 238/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9857
Epoch 239/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0495 - accuracy: 0.9840
Epoch 240/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9849
Epoch 241/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9840
Epoch 242/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9840
Epoch 243/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9857
Epoch 244/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9849
Epoch 245/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9832
Epoch 246/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9849
Epoch 247/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9849
Epoch 248/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9857
Epoch 249/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9849
Epoch 250/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9866
Epoch 251/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9874
Epoch 252/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9849
Epoch 253/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0430 - accuracy: 0.9840
Epoch 254/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0433 - accuracy: 0.9849
Epoch 255/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9857
Epoch 256/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9866
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[33]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e6f943b29b0&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Overfit-64x32x1-(success)">Overfit 64x32x1 (success)<a class="anchor-link" href="#Overfit-64x32x1-(success)">¶</a></h2><ul>
<li>100 epochs</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># add more neurons</span>
<span class="n">overfit_model_5</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_64x32x1"</span><span class="p">)</span>
<span class="n">overfit_model_5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">overfit_model_5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_5</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

<span class="c1"># compile new overfit model</span>
<span class="n">overfit_model_5</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="n">overfit_model_5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
38/38 [==============================] - 1s 1ms/step - loss: 0.5720 - accuracy: 0.7563
Epoch 2/100
38/38 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.8176
Epoch 3/100
38/38 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8395
Epoch 4/100
38/38 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8429
Epoch 5/100
38/38 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8479
Epoch 6/100
38/38 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8546
Epoch 7/100
38/38 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8588
Epoch 8/100
38/38 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8622
Epoch 9/100
38/38 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8655
Epoch 10/100
38/38 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.8655
Epoch 11/100
38/38 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8714
Epoch 12/100
38/38 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8748
Epoch 13/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8832
Epoch 14/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8866
Epoch 15/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8874
Epoch 16/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8849
Epoch 17/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8958
Epoch 18/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2724 - accuracy: 0.8933
Epoch 19/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8941
Epoch 20/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8924
Epoch 21/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8933
Epoch 22/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.8958
Epoch 23/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9000
Epoch 24/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9025
Epoch 25/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9067
Epoch 26/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9000
Epoch 27/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2318 - accuracy: 0.9143
Epoch 28/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9126
Epoch 29/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9143
Epoch 30/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2218 - accuracy: 0.9126
Epoch 31/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9151
Epoch 32/100
38/38 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9168
Epoch 33/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.9202
Epoch 34/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9202
Epoch 35/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9210
Epoch 36/100
38/38 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.9252
Epoch 37/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.9311
Epoch 38/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.9336
Epoch 39/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.9345
Epoch 40/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.9319
Epoch 41/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9395
Epoch 42/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9319
Epoch 43/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9420
Epoch 44/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9387
Epoch 45/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1715 - accuracy: 0.9462
Epoch 46/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9403
Epoch 47/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9471
Epoch 48/100
38/38 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9462
Epoch 49/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9504
Epoch 50/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.9538
Epoch 51/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9513
Epoch 52/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.9521
Epoch 53/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9538
Epoch 54/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9597
Epoch 55/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9605
Epoch 56/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9588
Epoch 57/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9605
Epoch 58/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.9605
Epoch 59/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9630
Epoch 60/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.9655
Epoch 61/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9647
Epoch 62/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9622
Epoch 63/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9630
Epoch 64/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9681
Epoch 65/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9689
Epoch 66/100
38/38 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9706
Epoch 67/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9672
Epoch 68/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9697
Epoch 69/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9731
Epoch 70/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9706
Epoch 71/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.9714
Epoch 72/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9689
Epoch 73/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9723
Epoch 74/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9723
Epoch 75/100
38/38 [==============================] - 0s 1ms/step - loss: 0.1010 - accuracy: 0.9739
Epoch 76/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.9765
Epoch 77/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9731
Epoch 78/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9756
Epoch 79/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9756
Epoch 80/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9765
Epoch 81/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9773
Epoch 82/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9765
Epoch 83/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9773
Epoch 84/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9798
Epoch 85/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9790
Epoch 86/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9807
Epoch 87/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9824
Epoch 88/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0770 - accuracy: 0.9790
Epoch 89/100
38/38 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9849
Epoch 90/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9824
Epoch 91/100
38/38 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9849
Epoch 92/100
38/38 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9832
Epoch 93/100
38/38 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9824
Epoch 94/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.9824
Epoch 95/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9857
Epoch 96/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9815
Epoch 97/100
38/38 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9874
Epoch 98/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9857
Epoch 99/100
38/38 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9857
Epoch 100/100
38/38 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9874
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[34]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e6f942beef0&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Overfit-500x1-(success)">Overfit 500x1 (success)<a class="anchor-link" href="#Overfit-500x1-(success)">¶</a></h2><ul>
<li>256 epochs</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># add more neurons</span>
<span class="n">overfit_model_6</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_mode_6"</span><span class="p">)</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

<span class="c1"># compile new overfit model</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
38/38 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.8025
Epoch 2/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8395
Epoch 3/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8412
Epoch 4/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8496
Epoch 5/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8546
Epoch 6/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8622
Epoch 7/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8630
Epoch 8/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8689
Epoch 9/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8756
Epoch 10/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3070 - accuracy: 0.8790
Epoch 11/256
38/38 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8798
Epoch 12/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8874
Epoch 13/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2943 - accuracy: 0.8874
Epoch 14/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2903 - accuracy: 0.8882
Epoch 15/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8866
Epoch 16/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8874
Epoch 17/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2799 - accuracy: 0.8882
Epoch 18/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.8933
Epoch 19/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8891
Epoch 20/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.8866
Epoch 21/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.8916
Epoch 22/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.8950
Epoch 23/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.9008
Epoch 24/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.8983
Epoch 25/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.8933
Epoch 26/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.8958
Epoch 27/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.8958
Epoch 28/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.8992
Epoch 29/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.8983
Epoch 30/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.8966
Epoch 31/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.9034
Epoch 32/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.9050
Epoch 33/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.9042
Epoch 34/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.9042
Epoch 35/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.9118
Epoch 36/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9067
Epoch 37/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9109
Epoch 38/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9134
Epoch 39/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9143
Epoch 40/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9143
Epoch 41/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9126
Epoch 42/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9118
Epoch 43/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.9210
Epoch 44/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2154 - accuracy: 0.9202
Epoch 45/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9176
Epoch 46/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.9160
Epoch 47/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2097 - accuracy: 0.9185
Epoch 48/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.9176
Epoch 49/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9261
Epoch 50/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9252
Epoch 51/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9227
Epoch 52/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9210
Epoch 53/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9261
Epoch 54/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9370
Epoch 55/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9261
Epoch 56/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9311
Epoch 57/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9328
Epoch 58/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9311
Epoch 59/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.9336
Epoch 60/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9345
Epoch 61/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.9370
Epoch 62/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9336
Epoch 63/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.9395
Epoch 64/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9319
Epoch 65/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9420
Epoch 66/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.9403
Epoch 67/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.9412
Epoch 68/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9487
Epoch 69/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9445
Epoch 70/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9513
Epoch 71/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9429
Epoch 72/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9462
Epoch 73/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9462
Epoch 74/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9487
Epoch 75/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.9437
Epoch 76/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9504
Epoch 77/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9504
Epoch 78/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1524 - accuracy: 0.9521
Epoch 79/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9563
Epoch 80/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9563
Epoch 81/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9580
Epoch 82/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9538
Epoch 83/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1454 - accuracy: 0.9513
Epoch 84/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9546
Epoch 85/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9529
Epoch 86/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9597
Epoch 87/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9588
Epoch 88/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1380 - accuracy: 0.9588
Epoch 89/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1362 - accuracy: 0.9613
Epoch 90/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9613
Epoch 91/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.9630
Epoch 92/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.9655
Epoch 93/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.9605
Epoch 94/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1288 - accuracy: 0.9605
Epoch 95/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.9613
Epoch 96/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9639
Epoch 97/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9664
Epoch 98/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1220 - accuracy: 0.9655
Epoch 99/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9681
Epoch 100/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1207 - accuracy: 0.9655
Epoch 101/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.9639
Epoch 102/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9689
Epoch 103/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9689
Epoch 104/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9681
Epoch 105/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.9664
Epoch 106/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9714
Epoch 107/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9723
Epoch 108/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1113 - accuracy: 0.9672
Epoch 109/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9739
Epoch 110/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9681
Epoch 111/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9697
Epoch 112/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9706
Epoch 113/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9773
Epoch 114/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9756
Epoch 115/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.9723
Epoch 116/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9756
Epoch 117/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9756
Epoch 118/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9756
Epoch 119/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.9765
Epoch 120/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9756
Epoch 121/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9748
Epoch 122/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9790
Epoch 123/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9748
Epoch 124/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0922 - accuracy: 0.9714
Epoch 125/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9807
Epoch 126/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9765
Epoch 127/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9773
Epoch 128/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.9798
Epoch 129/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9790
Epoch 130/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0833 - accuracy: 0.9807
Epoch 131/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9807
Epoch 132/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9773
Epoch 133/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0816 - accuracy: 0.9824
Epoch 134/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9798
Epoch 135/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9782
Epoch 136/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9807
Epoch 137/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9815
Epoch 138/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9815
Epoch 139/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9815
Epoch 140/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9798
Epoch 141/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9798
Epoch 142/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0715 - accuracy: 0.9832
Epoch 143/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0711 - accuracy: 0.9824
Epoch 144/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9840
Epoch 145/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.9832
Epoch 146/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9866
Epoch 147/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9857
Epoch 148/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9840
Epoch 149/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.9832
Epoch 150/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9882
Epoch 151/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9874
Epoch 152/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9840
Epoch 153/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9849
Epoch 154/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9874
Epoch 155/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9840
Epoch 156/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9866
Epoch 157/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0591 - accuracy: 0.9882
Epoch 158/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9849
Epoch 159/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9857
Epoch 160/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9908
Epoch 161/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9874
Epoch 162/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9891
Epoch 163/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9849
Epoch 164/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9899
Epoch 165/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9874
Epoch 166/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9899
Epoch 167/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9874
Epoch 168/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9916
Epoch 169/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9891
Epoch 170/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9924
Epoch 171/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9916
Epoch 172/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9882
Epoch 173/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9924
Epoch 174/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9916
Epoch 175/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9891
Epoch 176/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9908
Epoch 177/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9908
Epoch 178/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9924
Epoch 179/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9891
Epoch 180/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9924
Epoch 181/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9924
Epoch 182/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9899
Epoch 183/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9908
Epoch 184/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9916
Epoch 185/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9933
Epoch 186/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9908
Epoch 187/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9950
Epoch 188/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0370 - accuracy: 0.9958
Epoch 189/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9958
Epoch 190/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9933
Epoch 191/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0361 - accuracy: 0.9933
Epoch 192/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9958
Epoch 193/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9950
Epoch 194/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9924
Epoch 195/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9933
Epoch 196/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 0.9975
Epoch 197/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9941
Epoch 198/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0332 - accuracy: 0.9958
Epoch 199/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9958
Epoch 200/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9950
Epoch 201/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9966
Epoch 202/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9966
Epoch 203/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9958
Epoch 204/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9966
Epoch 205/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9983
Epoch 206/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9966
Epoch 207/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9983
Epoch 208/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9983
Epoch 209/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9950
Epoch 210/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9983
Epoch 211/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9958
Epoch 212/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9958
Epoch 213/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9983
Epoch 214/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9975
Epoch 215/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9992
Epoch 216/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9958
Epoch 217/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9966
Epoch 218/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9975
Epoch 219/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9992
Epoch 220/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9992
Epoch 221/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9975
Epoch 222/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 1.0000
Epoch 223/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9983
Epoch 224/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9983
Epoch 225/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9992
Epoch 226/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9975
Epoch 227/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9992
Epoch 228/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9983
Epoch 229/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9992
Epoch 230/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9992
Epoch 231/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9992
Epoch 232/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000
Epoch 233/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9975
Epoch 234/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9992
Epoch 235/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000
Epoch 236/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000
Epoch 237/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 1.0000
Epoch 238/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9983
Epoch 239/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9992
Epoch 240/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9992
Epoch 241/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000
Epoch 242/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9992
Epoch 243/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9992
Epoch 244/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9992
Epoch 245/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000
Epoch 246/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000
Epoch 247/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000
Epoch 248/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.9992
Epoch 249/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 1.0000
Epoch 250/256
38/38 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9992
Epoch 251/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9992
Epoch 252/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0134 - accuracy: 1.0000
Epoch 253/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9992
Epoch 254/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9983
Epoch 255/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000
Epoch 256/256
38/38 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[35]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e6f941ce380&gt;</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># add more neurons</span>
<span class="n">overfit_model_6</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"overfit_mode_6"</span><span class="p">)</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

<span class="c1"># compile new overfit model</span>
<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="n">overfit_model_6</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
38/38 [==============================] - 1s 2ms/step - loss: 0.6102 - accuracy: 0.7622
Epoch 2/256
38/38 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7723
Epoch 3/256
38/38 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7832
Epoch 4/256
38/38 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7924
Epoch 5/256
38/38 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8017
Epoch 6/256
38/38 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8101
Epoch 7/256
38/38 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8176
Epoch 8/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8235
Epoch 9/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8286
Epoch 10/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8277
Epoch 11/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8336
Epoch 12/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8303
Epoch 13/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8345
Epoch 14/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3705 - accuracy: 0.8387
Epoch 15/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8370
Epoch 16/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8420
Epoch 17/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8429
Epoch 18/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8445
Epoch 19/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8471
Epoch 20/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8529
Epoch 21/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8521
Epoch 22/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8521
Epoch 23/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8529
Epoch 24/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8555
Epoch 25/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8546
Epoch 26/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8563
Epoch 27/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8580
Epoch 28/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8571
Epoch 29/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8563
Epoch 30/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8605
Epoch 31/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8588
Epoch 32/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8605
Epoch 33/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8622
Epoch 34/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8597
Epoch 35/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8605
Epoch 36/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8613
Epoch 37/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8588
Epoch 38/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8622
Epoch 39/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8664
Epoch 40/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3179 - accuracy: 0.8639
Epoch 41/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8647
Epoch 42/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8689
Epoch 43/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.8664
Epoch 44/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8714
Epoch 45/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8714
Epoch 46/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8706
Epoch 47/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8773
Epoch 48/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8706
Epoch 49/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8706
Epoch 50/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8756
Epoch 51/256
38/38 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8807
Epoch 52/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8739
Epoch 53/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8798
Epoch 54/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8815
Epoch 55/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8807
Epoch 56/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8874
Epoch 57/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8866
Epoch 58/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.8849
Epoch 59/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8891
Epoch 60/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8899
Epoch 61/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.8891
Epoch 62/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8891
Epoch 63/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8874
Epoch 64/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8882
Epoch 65/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2827 - accuracy: 0.8891
Epoch 66/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8966
Epoch 67/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8908
Epoch 68/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8916
Epoch 69/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2782 - accuracy: 0.8983
Epoch 70/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2767 - accuracy: 0.8983
Epoch 71/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8941
Epoch 72/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2740 - accuracy: 0.8992
Epoch 73/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2720 - accuracy: 0.9034
Epoch 74/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8950
Epoch 75/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2702 - accuracy: 0.9017
Epoch 76/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.9017
Epoch 77/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2690 - accuracy: 0.9008
Epoch 78/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9000
Epoch 79/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2655 - accuracy: 0.9034
Epoch 80/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2643 - accuracy: 0.9025
Epoch 81/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.9042
Epoch 82/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9101
Epoch 83/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.9025
Epoch 84/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.9076
Epoch 85/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9101
Epoch 86/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2592 - accuracy: 0.9050
Epoch 87/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.9092
Epoch 88/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.9084
Epoch 89/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9059
Epoch 90/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9067
Epoch 91/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.9076
Epoch 92/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9084
Epoch 93/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.9084
Epoch 94/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9109
Epoch 95/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2501 - accuracy: 0.9126
Epoch 96/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.9151
Epoch 97/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.9101
Epoch 98/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9134
Epoch 99/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9151
Epoch 100/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.9126
Epoch 101/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9143
Epoch 102/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9185
Epoch 103/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9151
Epoch 104/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9176
Epoch 105/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9151
Epoch 106/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9176
Epoch 107/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9185
Epoch 108/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9218
Epoch 109/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9168
Epoch 110/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9168
Epoch 111/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9168
Epoch 112/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9185
Epoch 113/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9218
Epoch 114/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9193
Epoch 115/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9218
Epoch 116/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9176
Epoch 117/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9168
Epoch 118/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.9202
Epoch 119/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9218
Epoch 120/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9185
Epoch 121/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9176
Epoch 122/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9218
Epoch 123/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9193
Epoch 124/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2244 - accuracy: 0.9235
Epoch 125/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9143
Epoch 126/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.9193
Epoch 127/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9202
Epoch 128/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9252
Epoch 129/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9244
Epoch 130/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9185
Epoch 131/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9261
Epoch 132/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9227
Epoch 133/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9261
Epoch 134/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2205 - accuracy: 0.9193
Epoch 135/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9311
Epoch 136/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9261
Epoch 137/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9252
Epoch 138/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9252
Epoch 139/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9244
Epoch 140/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9227
Epoch 141/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9210
Epoch 142/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.9227
Epoch 143/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9210
Epoch 144/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9252
Epoch 145/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9252
Epoch 146/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9252
Epoch 147/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9218
Epoch 148/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9218
Epoch 149/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9252
Epoch 150/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9277
Epoch 151/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2082 - accuracy: 0.9235
Epoch 152/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9252
Epoch 153/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9269
Epoch 154/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2068 - accuracy: 0.9218
Epoch 155/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2055 - accuracy: 0.9269
Epoch 156/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9269
Epoch 157/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9261
Epoch 158/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9269
Epoch 159/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9227
Epoch 160/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9303
Epoch 161/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9294
Epoch 162/256
38/38 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9261
Epoch 163/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9261
Epoch 164/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9244
Epoch 165/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9294
Epoch 166/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9311
Epoch 167/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9294
Epoch 168/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9336
Epoch 169/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9286
Epoch 170/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9269
Epoch 171/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9294
Epoch 172/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9286
Epoch 173/256
38/38 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9294
Epoch 174/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9319
Epoch 175/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9277
Epoch 176/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9303
Epoch 177/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9319
Epoch 178/256
38/38 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9303
Epoch 179/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9336
Epoch 180/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9303
Epoch 181/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9311
Epoch 182/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9294
Epoch 183/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9328
Epoch 184/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9328
Epoch 185/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9345
Epoch 186/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9336
Epoch 187/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9311
Epoch 188/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9345
Epoch 189/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.9252
Epoch 190/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9336
Epoch 191/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1913 - accuracy: 0.9353
Epoch 192/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9370
Epoch 193/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9319
Epoch 194/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9336
Epoch 195/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9353
Epoch 196/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9303
Epoch 197/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9311
Epoch 198/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9328
Epoch 199/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9345
Epoch 200/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9319
Epoch 201/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9353
Epoch 202/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9336
Epoch 203/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9370
Epoch 204/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9345
Epoch 205/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9378
Epoch 206/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9345
Epoch 207/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9336
Epoch 208/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9353
Epoch 209/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9345
Epoch 210/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9303
Epoch 211/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9353
Epoch 212/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9361
Epoch 213/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9303
Epoch 214/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9353
Epoch 215/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9294
Epoch 216/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9353
Epoch 217/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9303
Epoch 218/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9328
Epoch 219/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9387
Epoch 220/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9336
Epoch 221/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9361
Epoch 222/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9353
Epoch 223/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9361
Epoch 224/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9345
Epoch 225/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9328
Epoch 226/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9361
Epoch 227/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9370
Epoch 228/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9378
Epoch 229/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9311
Epoch 230/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9336
Epoch 231/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9361
Epoch 232/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9361
Epoch 233/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9370
Epoch 234/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.9403
Epoch 235/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9311
Epoch 236/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9378
Epoch 237/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9345
Epoch 238/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.9387
Epoch 239/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9361
Epoch 240/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9420
Epoch 241/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9336
Epoch 242/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9387
Epoch 243/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.9395
Epoch 244/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9412
Epoch 245/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9387
Epoch 246/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9353
Epoch 247/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9353
Epoch 248/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9353
Epoch 249/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9429
Epoch 250/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9420
Epoch 251/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9412
Epoch 252/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9454
Epoch 253/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9387
Epoch 254/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9429
Epoch 255/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9445
Epoch 256/256
38/38 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9420
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[36]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>&lt;keras.src.callbacks.History at 0x7e6f607d6740&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Phase-3---Model-selection-&amp;-evaluation">Phase 3 - Model selection &amp; evaluation<a class="anchor-link" href="#Phase-3---Model-selection-&amp;-evaluation">¶</a></h1><ul>
<li>Goal: obtain highest possible acc on validation set</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.metrics</span> <span class="kn">import</span> <span class="n">Precision</span><span class="p">,</span> <span class="n">Recall</span><span class="p">,</span> <span class="n">F1Score</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># double check train and validation sets</span>
<span class="nb">print</span><span class="p">(</span><span class="n">XTRAIN</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">XVALID</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">YVALID</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>(952, 11) (952,)
(238, 11) (238,)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Create-metric-classes-and-model-callbacks">Create metric classes and model callbacks<a class="anchor-link" href="#Create-metric-classes-and-model-callbacks">¶</a></h2><ul>
<li>Accuracy, Precision, Recall, F1Score</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">prec</span> <span class="o">=</span> <span class="n">Precision</span><span class="p">()</span>
<span class="n">rec</span> <span class="o">=</span> <span class="n">Recall</span><span class="p">()</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">F1Score</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [94]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>
<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span> <span class="o">=</span> <span class="s1">'model.keras'</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">)</span>
<span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Create-a-neural-network-logistic-regression-model">Create a neural network logistic regression model<a class="anchor-link" href="#Create-a-neural-network-logistic-regression-model">¶</a></h2><ul>
<li>One output neuron with sigmoid</li>
<li>val_accuracy: 0.8319</li>
<li>val_loss: 0.3709</li>
<li>val_precision: 0.8382</li>
<li>val_recall: 0.8636</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [95]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">baseline_regression_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"baseline_regression_model"</span><span class="p">)</span>
<span class="n">baseline_regression_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">baseline_regression_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">baseline_regression_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [96]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">baseline_regression_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
 1/30 [&gt;.............................] - ETA: 12s - loss: 0.6750 - accuracy: 0.6250 - precision_1: 0.5385 - recall_1: 0.5385
Epoch 1: val_loss improved from inf to 0.64056, saving model to model.keras
30/30 [==============================] - 1s 10ms/step - loss: 0.6569 - accuracy: 0.6239 - precision_1: 0.6486 - recall_1: 0.6040 - val_loss: 0.6406 - val_accuracy: 0.6261 - val_precision_1: 0.6923 - val_recall_1: 0.6045
Epoch 2/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5295 - accuracy: 0.7188 - precision_1: 0.8824 - recall_1: 0.6818
Epoch 2: val_loss improved from 0.64056 to 0.61228, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.6544 - precision_1: 0.6797 - recall_1: 0.6343 - val_loss: 0.6123 - val_accuracy: 0.6681 - val_precision_1: 0.7350 - val_recall_1: 0.6418
Epoch 3/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5035 - accuracy: 0.6875 - precision_1: 0.8667 - recall_1: 0.6190
Epoch 3: val_loss improved from 0.61228 to 0.58590, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.6891 - precision_1: 0.7122 - recall_1: 0.6747 - val_loss: 0.5859 - val_accuracy: 0.6891 - val_precision_1: 0.7500 - val_recall_1: 0.6716
Epoch 4/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6817 - accuracy: 0.6250 - precision_1: 0.5385 - recall_1: 0.5385
Epoch 4: val_loss improved from 0.58590 to 0.56317, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7174 - precision_1: 0.7374 - recall_1: 0.7091 - val_loss: 0.5632 - val_accuracy: 0.7227 - val_precision_1: 0.7742 - val_recall_1: 0.7164
Epoch 5/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5407 - accuracy: 0.7812 - precision_1: 0.7727 - recall_1: 0.8947
Epoch 5: val_loss improved from 0.56317 to 0.54295, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7311 - precision_1: 0.7495 - recall_1: 0.7253 - val_loss: 0.5429 - val_accuracy: 0.7353 - val_precision_1: 0.7840 - val_recall_1: 0.7313
Epoch 6/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6766 - accuracy: 0.6562 - precision_1: 0.8462 - recall_1: 0.5500
Epoch 6: val_loss improved from 0.54295 to 0.52493, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7511 - precision_1: 0.7676 - recall_1: 0.7475 - val_loss: 0.5249 - val_accuracy: 0.7647 - val_precision_1: 0.8145 - val_recall_1: 0.7537
Epoch 7/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5257 - accuracy: 0.7500 - precision_1: 0.7857 - recall_1: 0.6875
Epoch 7: val_loss improved from 0.52493 to 0.50849, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7710 - precision_1: 0.7891 - recall_1: 0.7636 - val_loss: 0.5085 - val_accuracy: 0.7689 - val_precision_1: 0.8211 - val_recall_1: 0.7537
Epoch 8/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6249 - accuracy: 0.7188 - precision_1: 0.7000 - recall_1: 0.8235
Epoch 8: val_loss improved from 0.50849 to 0.49406, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7836 - precision_1: 0.8029 - recall_1: 0.7737 - val_loss: 0.4941 - val_accuracy: 0.7857 - val_precision_1: 0.8268 - val_recall_1: 0.7836
Epoch 9/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4241 - accuracy: 0.8438 - precision_1: 0.9167 - recall_1: 0.7333
Epoch 9: val_loss improved from 0.49406 to 0.48077, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7910 - precision_1: 0.8071 - recall_1: 0.7859 - val_loss: 0.4808 - val_accuracy: 0.7941 - val_precision_1: 0.8346 - val_recall_1: 0.7910
Epoch 10/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5068 - accuracy: 0.7500 - precision_1: 0.8421 - recall_1: 0.7619
Epoch 10: val_loss improved from 0.48077 to 0.46959, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7973 - precision_1: 0.8133 - recall_1: 0.7919 - val_loss: 0.4696 - val_accuracy: 0.8109 - val_precision_1: 0.8560 - val_recall_1: 0.7985
Epoch 11/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5643 - accuracy: 0.7500 - precision_1: 0.7059 - recall_1: 0.8000
Epoch 11: val_loss improved from 0.46959 to 0.45891, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8078 - precision_1: 0.8237 - recall_1: 0.8020 - val_loss: 0.4589 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 12/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3717 - accuracy: 0.8750 - precision_1: 0.9231 - recall_1: 0.8000
Epoch 12: val_loss improved from 0.45891 to 0.44992, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.8151 - precision_1: 0.8275 - recall_1: 0.8141 - val_loss: 0.4499 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 13/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4331 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 13: val_loss improved from 0.44992 to 0.44218, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8151 - precision_1: 0.8275 - recall_1: 0.8141 - val_loss: 0.4422 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 14/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4097 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 14: val_loss improved from 0.44218 to 0.43488, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8183 - precision_1: 0.8299 - recall_1: 0.8182 - val_loss: 0.4349 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 15/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4565 - accuracy: 0.8125 - precision_1: 0.8182 - recall_1: 0.6923
Epoch 15: val_loss improved from 0.43488 to 0.42881, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8193 - precision_1: 0.8303 - recall_1: 0.8202 - val_loss: 0.4288 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 16/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4670 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 16: val_loss improved from 0.42881 to 0.42344, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.8204 - precision_1: 0.8320 - recall_1: 0.8202 - val_loss: 0.4234 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 17/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2624 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 17: val_loss improved from 0.42344 to 0.41833, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8204 - precision_1: 0.8306 - recall_1: 0.8222 - val_loss: 0.4183 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 18/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4728 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 18: val_loss improved from 0.41833 to 0.41411, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8256 - precision_1: 0.8364 - recall_1: 0.8263 - val_loss: 0.4141 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 19/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4736 - accuracy: 0.7812 - precision_1: 0.7692 - recall_1: 0.7143
Epoch 19: val_loss improved from 0.41411 to 0.41039, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8288 - precision_1: 0.8388 - recall_1: 0.8303 - val_loss: 0.4104 - val_accuracy: 0.8403 - val_precision_1: 0.8810 - val_recall_1: 0.8284
Epoch 20/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5049 - accuracy: 0.7500 - precision_1: 0.7692 - recall_1: 0.6667
Epoch 20: val_loss improved from 0.41039 to 0.40662, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8277 - precision_1: 0.8371 - recall_1: 0.8303 - val_loss: 0.4066 - val_accuracy: 0.8403 - val_precision_1: 0.8810 - val_recall_1: 0.8284
Epoch 21/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4211 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 21: val_loss improved from 0.40662 to 0.40336, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8288 - precision_1: 0.8388 - recall_1: 0.8303 - val_loss: 0.4034 - val_accuracy: 0.8403 - val_precision_1: 0.8810 - val_recall_1: 0.8284
Epoch 22/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3694 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 22: val_loss improved from 0.40336 to 0.40064, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8288 - precision_1: 0.8374 - recall_1: 0.8323 - val_loss: 0.4006 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 23/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4483 - accuracy: 0.8125 - precision_1: 0.8462 - recall_1: 0.7333
Epoch 23: val_loss improved from 0.40064 to 0.39822, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8267 - precision_1: 0.8367 - recall_1: 0.8283 - val_loss: 0.3982 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 24/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3936 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 24: val_loss improved from 0.39822 to 0.39589, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8277 - precision_1: 0.8384 - recall_1: 0.8283 - val_loss: 0.3959 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 25/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3077 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 25: val_loss improved from 0.39589 to 0.39395, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8288 - precision_1: 0.8402 - recall_1: 0.8283 - val_loss: 0.3940 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 26/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2681 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8333
Epoch 26: val_loss improved from 0.39395 to 0.39176, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8288 - precision_1: 0.8402 - recall_1: 0.8283 - val_loss: 0.3918 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 27/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3445 - accuracy: 0.8438 - precision_1: 1.0000 - recall_1: 0.7368
Epoch 27: val_loss improved from 0.39176 to 0.38994, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8309 - precision_1: 0.8408 - recall_1: 0.8323 - val_loss: 0.3899 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 28/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5540 - accuracy: 0.7500 - precision_1: 0.8947 - recall_1: 0.7391
Epoch 28: val_loss improved from 0.38994 to 0.38828, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8309 - precision_1: 0.8394 - recall_1: 0.8343 - val_loss: 0.3883 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 29/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4404 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.7692
Epoch 29: val_loss improved from 0.38828 to 0.38684, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8309 - precision_1: 0.8394 - recall_1: 0.8343 - val_loss: 0.3868 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 30/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5347 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.7500
Epoch 30: val_loss improved from 0.38684 to 0.38522, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8309 - precision_1: 0.8394 - recall_1: 0.8343 - val_loss: 0.3852 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 31/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4457 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 31: val_loss improved from 0.38522 to 0.38402, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8330 - precision_1: 0.8401 - recall_1: 0.8384 - val_loss: 0.3840 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 32/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4699 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500
Epoch 32: val_loss improved from 0.38402 to 0.38300, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8340 - precision_1: 0.8418 - recall_1: 0.8384 - val_loss: 0.3830 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 33/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3841 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 33: val_loss improved from 0.38300 to 0.38194, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3819 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 34/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2828 - accuracy: 0.8438 - precision_1: 0.9375 - recall_1: 0.7895
Epoch 34: val_loss improved from 0.38194 to 0.38081, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8372 - precision_1: 0.8427 - recall_1: 0.8444 - val_loss: 0.3808 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 35/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4606 - accuracy: 0.8125 - precision_1: 0.7333 - recall_1: 0.8462
Epoch 35: val_loss improved from 0.38081 to 0.37985, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8340 - precision_1: 0.8418 - recall_1: 0.8384 - val_loss: 0.3798 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 36/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4516 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 36: val_loss improved from 0.37985 to 0.37899, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8372 - precision_1: 0.8427 - recall_1: 0.8444 - val_loss: 0.3790 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 37/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4925 - accuracy: 0.8125 - precision_1: 0.7368 - recall_1: 0.9333
Epoch 37: val_loss improved from 0.37899 to 0.37815, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8382 - precision_1: 0.8431 - recall_1: 0.8465 - val_loss: 0.3782 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 38/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4461 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.8571
Epoch 38: val_loss improved from 0.37815 to 0.37743, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8382 - precision_1: 0.8431 - recall_1: 0.8465 - val_loss: 0.3774 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 39/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3697 - accuracy: 0.8750 - precision_1: 0.7692 - recall_1: 0.9091
Epoch 39: val_loss improved from 0.37743 to 0.37687, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8414 - precision_1: 0.8440 - recall_1: 0.8525 - val_loss: 0.3769 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 40/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2430 - accuracy: 0.9062 - precision_1: 0.9286 - recall_1: 0.8667
Epoch 40: val_loss improved from 0.37687 to 0.37643, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8403 - precision_1: 0.8437 - recall_1: 0.8505 - val_loss: 0.3764 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 41/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3210 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 41: val_loss improved from 0.37643 to 0.37595, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8393 - precision_1: 0.8434 - recall_1: 0.8485 - val_loss: 0.3759 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 42/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3796 - accuracy: 0.8750 - precision_1: 0.7692 - recall_1: 0.9091
Epoch 42: val_loss improved from 0.37595 to 0.37548, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8393 - precision_1: 0.8434 - recall_1: 0.8485 - val_loss: 0.3755 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 43/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4124 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 43: val_loss improved from 0.37548 to 0.37506, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8393 - precision_1: 0.8434 - recall_1: 0.8485 - val_loss: 0.3751 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 44/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4424 - accuracy: 0.8125 - precision_1: 0.9286 - recall_1: 0.7222
Epoch 44: val_loss improved from 0.37506 to 0.37464, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8393 - precision_1: 0.8434 - recall_1: 0.8485 - val_loss: 0.3746 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 45/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5987 - accuracy: 0.7188 - precision_1: 0.7857 - recall_1: 0.6471
Epoch 45: val_loss improved from 0.37464 to 0.37421, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8393 - precision_1: 0.8434 - recall_1: 0.8485 - val_loss: 0.3742 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 46/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6564 - accuracy: 0.7500 - precision_1: 0.8125 - recall_1: 0.7222
Epoch 46: val_loss improved from 0.37421 to 0.37389, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8403 - precision_1: 0.8451 - recall_1: 0.8485 - val_loss: 0.3739 - val_accuracy: 0.8403 - val_precision_1: 0.8810 - val_recall_1: 0.8284
Epoch 47/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5104 - accuracy: 0.8125 - precision_1: 0.7368 - recall_1: 0.9333
Epoch 47: val_loss improved from 0.37389 to 0.37366, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8403 - precision_1: 0.8451 - recall_1: 0.8485 - val_loss: 0.3737 - val_accuracy: 0.8403 - val_precision_1: 0.8810 - val_recall_1: 0.8284
Epoch 48/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3824 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 48: val_loss improved from 0.37366 to 0.37344, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8393 - precision_1: 0.8448 - recall_1: 0.8465 - val_loss: 0.3734 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 49/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3141 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 49: val_loss improved from 0.37344 to 0.37317, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8414 - precision_1: 0.8468 - recall_1: 0.8485 - val_loss: 0.3732 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 50/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5341 - accuracy: 0.7500 - precision_1: 0.9048 - recall_1: 0.7600
Epoch 50: val_loss improved from 0.37317 to 0.37286, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3729 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 51/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3656 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 51: val_loss improved from 0.37286 to 0.37266, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3727 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 52/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4791 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 52: val_loss improved from 0.37266 to 0.37247, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3725 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 53/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5318 - accuracy: 0.7188 - precision_1: 0.6471 - recall_1: 0.7857
Epoch 53: val_loss improved from 0.37247 to 0.37224, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3722 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 54/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3971 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 54: val_loss improved from 0.37224 to 0.37201, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3720 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 55/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4766 - accuracy: 0.7500 - precision_1: 0.6842 - recall_1: 0.8667
Epoch 55: val_loss improved from 0.37201 to 0.37178, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3718 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 56/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4446 - accuracy: 0.8125 - precision_1: 0.8261 - recall_1: 0.9048
Epoch 56: val_loss improved from 0.37178 to 0.37158, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8361 - precision_1: 0.8424 - recall_1: 0.8424 - val_loss: 0.3716 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 57/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2472 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 57: val_loss improved from 0.37158 to 0.37134, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3939 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3713 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 58/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3062 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 58: val_loss improved from 0.37134 to 0.37132, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3713 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 59/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3988 - accuracy: 0.8438 - precision_1: 0.8261 - recall_1: 0.9500
Epoch 59: val_loss improved from 0.37132 to 0.37110, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3711 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 60/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4513 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 60: val_loss improved from 0.37110 to 0.37102, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8340 - precision_1: 0.8390 - recall_1: 0.8424 - val_loss: 0.3710 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 61/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2458 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8500
Epoch 61: val_loss improved from 0.37102 to 0.37080, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8330 - precision_1: 0.8387 - recall_1: 0.8404 - val_loss: 0.3708 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 62/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4069 - accuracy: 0.8125 - precision_1: 0.9167 - recall_1: 0.6875
Epoch 62: val_loss improved from 0.37080 to 0.37058, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3706 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 63/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3140 - accuracy: 0.9062 - precision_1: 0.9545 - recall_1: 0.9130
Epoch 63: val_loss did not improve from 0.37058
30/30 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8309 - precision_1: 0.8353 - recall_1: 0.8404 - val_loss: 0.3706 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 64/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2723 - accuracy: 0.8750 - precision_1: 0.8000 - recall_1: 0.9231
Epoch 64: val_loss improved from 0.37058 to 0.37056, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8319 - precision_1: 0.8357 - recall_1: 0.8424 - val_loss: 0.3706 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 65/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2369 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 65: val_loss improved from 0.37056 to 0.37042, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8319 - precision_1: 0.8357 - recall_1: 0.8424 - val_loss: 0.3704 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 66/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5657 - accuracy: 0.7188 - precision_1: 0.7778 - recall_1: 0.7368
Epoch 66: val_loss improved from 0.37042 to 0.37037, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3704 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 67/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4459 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 67: val_loss improved from 0.37037 to 0.37031, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8319 - precision_1: 0.8357 - recall_1: 0.8424 - val_loss: 0.3703 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 68/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3773 - accuracy: 0.8125 - precision_1: 0.6667 - recall_1: 0.8000
Epoch 68: val_loss improved from 0.37031 to 0.37029, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3703 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 69/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3791 - accuracy: 0.8438 - precision_1: 0.7333 - recall_1: 0.9167
Epoch 69: val_loss improved from 0.37029 to 0.37024, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8319 - precision_1: 0.8357 - recall_1: 0.8424 - val_loss: 0.3702 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 70/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3410 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 70: val_loss improved from 0.37024 to 0.37017, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3702 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 71/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4987 - accuracy: 0.7188 - precision_1: 0.7895 - recall_1: 0.7500
Epoch 71: val_loss did not improve from 0.37017
30/30 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3702 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 72/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4402 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.8571
Epoch 72: val_loss did not improve from 0.37017
30/30 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3702 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 73/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2539 - accuracy: 0.9375 - precision_1: 0.9412 - recall_1: 0.9412
Epoch 73: val_loss improved from 0.37017 to 0.37011, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3701 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 74/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2818 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 74: val_loss improved from 0.37011 to 0.37001, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3700 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 75/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2388 - accuracy: 0.9375 - precision_1: 0.9545 - recall_1: 0.9545
Epoch 75: val_loss improved from 0.37001 to 0.36997, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3700 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 76/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4725 - accuracy: 0.8125 - precision_1: 0.9474 - recall_1: 0.7826
Epoch 76: val_loss did not improve from 0.36997
30/30 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8309 - precision_1: 0.8340 - recall_1: 0.8424 - val_loss: 0.3700 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 77/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6734 - accuracy: 0.7500 - precision_1: 0.7000 - recall_1: 0.8750
Epoch 77: val_loss improved from 0.36997 to 0.36996, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3700 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 78/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3634 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 78: val_loss improved from 0.36996 to 0.36989, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3699 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 79/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4601 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 79: val_loss did not improve from 0.36989
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3699 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 80/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3652 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 80: val_loss improved from 0.36989 to 0.36985, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3698 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 81/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5893 - accuracy: 0.6875 - precision_1: 0.6190 - recall_1: 0.8667
Epoch 81: val_loss improved from 0.36985 to 0.36980, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3698 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 82/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4402 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 82: val_loss improved from 0.36980 to 0.36977, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8319 - precision_1: 0.8357 - recall_1: 0.8424 - val_loss: 0.3698 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 83/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4990 - accuracy: 0.8125 - precision_1: 0.7895 - recall_1: 0.8824
Epoch 83: val_loss improved from 0.36977 to 0.36965, saving model to model.keras
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8309 - precision_1: 0.8367 - recall_1: 0.8384 - val_loss: 0.3696 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 84/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2929 - accuracy: 0.8750 - precision_1: 0.7857 - recall_1: 0.9167
Epoch 84: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8298 - precision_1: 0.8350 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 85/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6178 - accuracy: 0.7812 - precision_1: 0.7059 - recall_1: 0.8571
Epoch 85: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8319 - precision_1: 0.8357 - recall_1: 0.8424 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 86/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3724 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 86: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8330 - precision_1: 0.8373 - recall_1: 0.8424 - val_loss: 0.3698 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 87/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2535 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 87: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8288 - precision_1: 0.8333 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 88/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5178 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 88: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8319 - precision_1: 0.8370 - recall_1: 0.8404 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 89/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3756 - accuracy: 0.7812 - precision_1: 0.7727 - recall_1: 0.8947
Epoch 89: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8309 - precision_1: 0.8367 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 90/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3188 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 90: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8298 - precision_1: 0.8337 - recall_1: 0.8404 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 91/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5681 - accuracy: 0.6875 - precision_1: 0.7500 - recall_1: 0.6667
Epoch 91: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8298 - precision_1: 0.8337 - recall_1: 0.8404 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 92/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4305 - accuracy: 0.8125 - precision_1: 0.8261 - recall_1: 0.9048
Epoch 92: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8298 - precision_1: 0.8350 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 93/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 93: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8309 - precision_1: 0.8367 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 94/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4409 - accuracy: 0.7500 - precision_1: 0.7333 - recall_1: 0.7333
Epoch 94: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8288 - precision_1: 0.8333 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 95/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3863 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 95: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8319 - precision_1: 0.8384 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 96/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3499 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 96: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8298 - precision_1: 0.8350 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 97/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4336 - accuracy: 0.8438 - precision_1: 0.9286 - recall_1: 0.7647
Epoch 97: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8319 - precision_1: 0.8384 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 98/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6500 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.6667
Epoch 98: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8309 - precision_1: 0.8353 - recall_1: 0.8404 - val_loss: 0.3698 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 99/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3005 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8462
Epoch 99: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8330 - precision_1: 0.8401 - recall_1: 0.8384 - val_loss: 0.3697 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 100/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4523 - accuracy: 0.8750 - precision_1: 0.7895 - recall_1: 1.0000
Epoch 100: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8330 - precision_1: 0.8401 - recall_1: 0.8384 - val_loss: 0.3698 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 101/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4494 - accuracy: 0.8125 - precision_1: 0.8750 - recall_1: 0.7778
Epoch 101: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8319 - precision_1: 0.8384 - recall_1: 0.8384 - val_loss: 0.3698 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 102/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4501 - accuracy: 0.8125 - precision_1: 0.7692 - recall_1: 0.7692
Epoch 102: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8340 - precision_1: 0.8404 - recall_1: 0.8404 - val_loss: 0.3699 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 103/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2635 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 103: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8340 - precision_1: 0.8404 - recall_1: 0.8404 - val_loss: 0.3700 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 103: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Model-8x8x8x1">Model 8x8x8x1<a class="anchor-link" href="#Model-8x8x8x1">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [97]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">all_eights_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"all_eights_model"</span><span class="p">)</span>
<span class="n">all_eights_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">all_eights_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">all_eights_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">all_eights_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">all_eights_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">all_eights_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">all_eights_history</span> <span class="o">=</span> <span class="n">all_eights_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.7477 - accuracy: 0.3750 - precision_1: 0.8943 - recall_1: 0.7143
Epoch 1: val_loss did not improve from 0.36965
30/30 [==============================] - 1s 10ms/step - loss: 0.6971 - accuracy: 0.4811 - precision_1: 0.6738 - recall_1: 0.3021 - val_loss: 0.6948 - val_accuracy: 0.5294 - val_precision_1: 0.6486 - val_recall_1: 0.3582
Epoch 2/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6753 - accuracy: 0.5625 - precision_1: 0.4545 - recall_1: 0.3846
Epoch 2: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5998 - precision_1: 0.6759 - recall_1: 0.4424 - val_loss: 0.6821 - val_accuracy: 0.5966 - val_precision_1: 0.6979 - val_recall_1: 0.5000
Epoch 3/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6753 - accuracy: 0.7188 - precision_1: 0.8000 - recall_1: 0.6667
Epoch 3: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6838 - precision_1: 0.7487 - recall_1: 0.5899 - val_loss: 0.6668 - val_accuracy: 0.6597 - val_precision_1: 0.7624 - val_recall_1: 0.5746
Epoch 4/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6822 - accuracy: 0.7188 - precision_1: 0.7647 - recall_1: 0.7222
Epoch 4: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7374 - precision_1: 0.8025 - recall_1: 0.6566 - val_loss: 0.6449 - val_accuracy: 0.7101 - val_precision_1: 0.8037 - val_recall_1: 0.6418
Epoch 5/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6520 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 5: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7658 - precision_1: 0.8269 - recall_1: 0.6949 - val_loss: 0.6149 - val_accuracy: 0.7269 - val_precision_1: 0.8108 - val_recall_1: 0.6716
Epoch 6/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6555 - accuracy: 0.7500 - precision_1: 0.9167 - recall_1: 0.6111
Epoch 6: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7857 - precision_1: 0.8360 - recall_1: 0.7313 - val_loss: 0.5802 - val_accuracy: 0.7521 - val_precision_1: 0.8261 - val_recall_1: 0.7090
Epoch 7/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5371 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 7: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7994 - precision_1: 0.8423 - recall_1: 0.7556 - val_loss: 0.5462 - val_accuracy: 0.7521 - val_precision_1: 0.8151 - val_recall_1: 0.7239
Epoch 8/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5352 - accuracy: 0.6875 - precision_1: 0.5333 - recall_1: 0.7273
Epoch 8: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.8109 - precision_1: 0.8402 - recall_1: 0.7859 - val_loss: 0.5149 - val_accuracy: 0.7521 - val_precision_1: 0.8049 - val_recall_1: 0.7388
Epoch 9/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4384 - accuracy: 0.7812 - precision_1: 0.6471 - recall_1: 0.9167
Epoch 9: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.8172 - precision_1: 0.8422 - recall_1: 0.7980 - val_loss: 0.4844 - val_accuracy: 0.7647 - val_precision_1: 0.8095 - val_recall_1: 0.7612
Epoch 10/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5085 - accuracy: 0.7812 - precision_1: 0.9412 - recall_1: 0.7273
Epoch 10: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.8214 - precision_1: 0.8364 - recall_1: 0.8162 - val_loss: 0.4613 - val_accuracy: 0.7815 - val_precision_1: 0.8154 - val_recall_1: 0.7910
Epoch 11/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4776 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 11: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8225 - precision_1: 0.8286 - recall_1: 0.8303 - val_loss: 0.4411 - val_accuracy: 0.7815 - val_precision_1: 0.8154 - val_recall_1: 0.7910
Epoch 12/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4256 - accuracy: 0.8125 - precision_1: 0.8462 - recall_1: 0.7333
Epoch 12: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8246 - precision_1: 0.8293 - recall_1: 0.8343 - val_loss: 0.4246 - val_accuracy: 0.7857 - val_precision_1: 0.8168 - val_recall_1: 0.7985
Epoch 13/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3860 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 13: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8225 - precision_1: 0.8221 - recall_1: 0.8404 - val_loss: 0.4137 - val_accuracy: 0.7773 - val_precision_1: 0.8045 - val_recall_1: 0.7985
Epoch 14/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4560 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 14: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8288 - precision_1: 0.8307 - recall_1: 0.8424 - val_loss: 0.4034 - val_accuracy: 0.7815 - val_precision_1: 0.8015 - val_recall_1: 0.8134
Epoch 15/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3708 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 15: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8246 - precision_1: 0.8228 - recall_1: 0.8444 - val_loss: 0.3968 - val_accuracy: 0.7857 - val_precision_1: 0.8029 - val_recall_1: 0.8209
Epoch 16/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4885 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 16: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8267 - precision_1: 0.8287 - recall_1: 0.8404 - val_loss: 0.3908 - val_accuracy: 0.7983 - val_precision_1: 0.8116 - val_recall_1: 0.8358
Epoch 17/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2247 - accuracy: 0.9062 - precision_1: 0.9474 - recall_1: 0.9000
Epoch 17: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8267 - precision_1: 0.8287 - recall_1: 0.8404 - val_loss: 0.3858 - val_accuracy: 0.8025 - val_precision_1: 0.8129 - val_recall_1: 0.8433
Epoch 18/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2607 - accuracy: 0.8750 - precision_1: 0.9048 - recall_1: 0.9048
Epoch 18: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8298 - precision_1: 0.8310 - recall_1: 0.8444 - val_loss: 0.3821 - val_accuracy: 0.8067 - val_precision_1: 0.8188 - val_recall_1: 0.8433
Epoch 19/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3020 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 19: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8340 - precision_1: 0.8297 - recall_1: 0.8566 - val_loss: 0.3789 - val_accuracy: 0.8025 - val_precision_1: 0.8175 - val_recall_1: 0.8358
Epoch 20/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4595 - accuracy: 0.7188 - precision_1: 0.6667 - recall_1: 0.7143
Epoch 20: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8361 - precision_1: 0.8356 - recall_1: 0.8525 - val_loss: 0.3750 - val_accuracy: 0.8025 - val_precision_1: 0.8175 - val_recall_1: 0.8358
Epoch 21/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1907 - accuracy: 0.9375 - precision_1: 0.9048 - recall_1: 1.0000
Epoch 21: val_loss did not improve from 0.36965
30/30 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8445 - precision_1: 0.8422 - recall_1: 0.8626 - val_loss: 0.3714 - val_accuracy: 0.8067 - val_precision_1: 0.8235 - val_recall_1: 0.8358
Epoch 22/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3153 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 22: val_loss improved from 0.36965 to 0.36799, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8456 - precision_1: 0.8452 - recall_1: 0.8606 - val_loss: 0.3680 - val_accuracy: 0.8109 - val_precision_1: 0.8248 - val_recall_1: 0.8433
Epoch 23/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4697 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 23: val_loss improved from 0.36799 to 0.36597, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8477 - precision_1: 0.8445 - recall_1: 0.8667 - val_loss: 0.3660 - val_accuracy: 0.8109 - val_precision_1: 0.8248 - val_recall_1: 0.8433
Epoch 24/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2707 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 24: val_loss improved from 0.36597 to 0.36356, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8487 - precision_1: 0.8448 - recall_1: 0.8687 - val_loss: 0.3636 - val_accuracy: 0.8109 - val_precision_1: 0.8248 - val_recall_1: 0.8433
Epoch 25/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3944 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 25: val_loss improved from 0.36356 to 0.36219, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8508 - precision_1: 0.8454 - recall_1: 0.8727 - val_loss: 0.3622 - val_accuracy: 0.8109 - val_precision_1: 0.8201 - val_recall_1: 0.8507
Epoch 26/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3160 - accuracy: 0.8438 - precision_1: 0.7895 - recall_1: 0.9375
Epoch 26: val_loss improved from 0.36219 to 0.36080, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3580 - accuracy: 0.8487 - precision_1: 0.8462 - recall_1: 0.8667 - val_loss: 0.3608 - val_accuracy: 0.8151 - val_precision_1: 0.8214 - val_recall_1: 0.8582
Epoch 27/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2431 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8667
Epoch 27: val_loss improved from 0.36080 to 0.36001, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.8540 - precision_1: 0.8463 - recall_1: 0.8788 - val_loss: 0.3600 - val_accuracy: 0.8151 - val_precision_1: 0.8214 - val_recall_1: 0.8582
Epoch 28/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1847 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 28: val_loss improved from 0.36001 to 0.35850, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8561 - precision_1: 0.8496 - recall_1: 0.8788 - val_loss: 0.3585 - val_accuracy: 0.8151 - val_precision_1: 0.8214 - val_recall_1: 0.8582
Epoch 29/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5058 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 29: val_loss improved from 0.35850 to 0.35710, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8561 - precision_1: 0.8510 - recall_1: 0.8768 - val_loss: 0.3571 - val_accuracy: 0.8109 - val_precision_1: 0.8156 - val_recall_1: 0.8582
Epoch 30/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4279 - accuracy: 0.7812 - precision_1: 0.7059 - recall_1: 0.8571
Epoch 30: val_loss improved from 0.35710 to 0.35682, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.8592 - precision_1: 0.8478 - recall_1: 0.8889 - val_loss: 0.3568 - val_accuracy: 0.8109 - val_precision_1: 0.8156 - val_recall_1: 0.8582
Epoch 31/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1647 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 31: val_loss improved from 0.35682 to 0.35584, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3515 - accuracy: 0.8603 - precision_1: 0.8521 - recall_1: 0.8848 - val_loss: 0.3558 - val_accuracy: 0.8109 - val_precision_1: 0.8156 - val_recall_1: 0.8582
Epoch 32/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2370 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 32: val_loss improved from 0.35584 to 0.35507, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.8624 - precision_1: 0.8514 - recall_1: 0.8909 - val_loss: 0.3551 - val_accuracy: 0.8151 - val_precision_1: 0.8169 - val_recall_1: 0.8657
Epoch 33/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2814 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.9545
Epoch 33: val_loss did not improve from 0.35507
30/30 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8613 - precision_1: 0.8470 - recall_1: 0.8949 - val_loss: 0.3556 - val_accuracy: 0.8193 - val_precision_1: 0.8273 - val_recall_1: 0.8582
Epoch 34/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3983 - accuracy: 0.8438 - precision_1: 0.7368 - recall_1: 1.0000
Epoch 34: val_loss improved from 0.35507 to 0.35417, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8613 - precision_1: 0.8524 - recall_1: 0.8869 - val_loss: 0.3542 - val_accuracy: 0.8277 - val_precision_1: 0.8345 - val_recall_1: 0.8657
Epoch 35/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4534 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 35: val_loss improved from 0.35417 to 0.35383, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8655 - precision_1: 0.8563 - recall_1: 0.8909 - val_loss: 0.3538 - val_accuracy: 0.8277 - val_precision_1: 0.8394 - val_recall_1: 0.8582
Epoch 36/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3624 - accuracy: 0.8438 - precision_1: 0.7500 - recall_1: 1.0000
Epoch 36: val_loss improved from 0.35383 to 0.35214, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8645 - precision_1: 0.8560 - recall_1: 0.8889 - val_loss: 0.3521 - val_accuracy: 0.8277 - val_precision_1: 0.8345 - val_recall_1: 0.8657
Epoch 37/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3616 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 37: val_loss improved from 0.35214 to 0.35142, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8645 - precision_1: 0.8533 - recall_1: 0.8929 - val_loss: 0.3514 - val_accuracy: 0.8277 - val_precision_1: 0.8394 - val_recall_1: 0.8582
Epoch 38/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2959 - accuracy: 0.9062 - precision_1: 0.8636 - recall_1: 1.0000
Epoch 38: val_loss improved from 0.35142 to 0.35025, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8655 - precision_1: 0.8549 - recall_1: 0.8929 - val_loss: 0.3503 - val_accuracy: 0.8403 - val_precision_1: 0.8429 - val_recall_1: 0.8806
Epoch 39/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5087 - accuracy: 0.7812 - precision_1: 0.7143 - recall_1: 0.7692
Epoch 39: val_loss improved from 0.35025 to 0.34920, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8634 - precision_1: 0.8503 - recall_1: 0.8949 - val_loss: 0.3492 - val_accuracy: 0.8361 - val_precision_1: 0.8417 - val_recall_1: 0.8731
Epoch 40/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4817 - accuracy: 0.7812 - precision_1: 0.7778 - recall_1: 0.8235
Epoch 40: val_loss did not improve from 0.34920
30/30 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8624 - precision_1: 0.8527 - recall_1: 0.8889 - val_loss: 0.3492 - val_accuracy: 0.8361 - val_precision_1: 0.8417 - val_recall_1: 0.8731
Epoch 41/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4359 - accuracy: 0.8125 - precision_1: 0.8421 - recall_1: 0.8421
Epoch 41: val_loss improved from 0.34920 to 0.34813, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8603 - precision_1: 0.8494 - recall_1: 0.8889 - val_loss: 0.3481 - val_accuracy: 0.8445 - val_precision_1: 0.8440 - val_recall_1: 0.8881
Epoch 42/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4651 - accuracy: 0.8125 - precision_1: 0.8750 - recall_1: 0.7778
Epoch 42: val_loss improved from 0.34813 to 0.34810, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8613 - precision_1: 0.8511 - recall_1: 0.8889 - val_loss: 0.3481 - val_accuracy: 0.8487 - val_precision_1: 0.8500 - val_recall_1: 0.8881
Epoch 43/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3617 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 43: val_loss improved from 0.34810 to 0.34779, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8624 - precision_1: 0.8527 - recall_1: 0.8889 - val_loss: 0.3478 - val_accuracy: 0.8445 - val_precision_1: 0.8489 - val_recall_1: 0.8806
Epoch 44/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4071 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8824
Epoch 44: val_loss did not improve from 0.34779
30/30 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8624 - precision_1: 0.8527 - recall_1: 0.8889 - val_loss: 0.3481 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 45/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4790 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 45: val_loss improved from 0.34779 to 0.34759, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8655 - precision_1: 0.8549 - recall_1: 0.8929 - val_loss: 0.3476 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 46/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2397 - accuracy: 0.9062 - precision_1: 0.8235 - recall_1: 1.0000
Epoch 46: val_loss did not improve from 0.34759
30/30 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8634 - precision_1: 0.8544 - recall_1: 0.8889 - val_loss: 0.3478 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 47/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2355 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9286
Epoch 47: val_loss improved from 0.34759 to 0.34754, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8655 - precision_1: 0.8563 - recall_1: 0.8909 - val_loss: 0.3475 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 48/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4220 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 48: val_loss improved from 0.34754 to 0.34538, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8666 - precision_1: 0.8608 - recall_1: 0.8869 - val_loss: 0.3454 - val_accuracy: 0.8445 - val_precision_1: 0.8489 - val_recall_1: 0.8806
Epoch 49/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3821 - accuracy: 0.8125 - precision_1: 0.7647 - recall_1: 0.8667
Epoch 49: val_loss did not improve from 0.34538
30/30 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8655 - precision_1: 0.8563 - recall_1: 0.8909 - val_loss: 0.3459 - val_accuracy: 0.8445 - val_precision_1: 0.8489 - val_recall_1: 0.8806
Epoch 50/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2535 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 1.0000
Epoch 50: val_loss did not improve from 0.34538
30/30 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8666 - precision_1: 0.8566 - recall_1: 0.8929 - val_loss: 0.3457 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 51/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2496 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 51: val_loss improved from 0.34538 to 0.34467, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8655 - precision_1: 0.8563 - recall_1: 0.8909 - val_loss: 0.3447 - val_accuracy: 0.8445 - val_precision_1: 0.8489 - val_recall_1: 0.8806
Epoch 52/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3446 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 52: val_loss improved from 0.34467 to 0.34438, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8655 - precision_1: 0.8577 - recall_1: 0.8889 - val_loss: 0.3444 - val_accuracy: 0.8445 - val_precision_1: 0.8489 - val_recall_1: 0.8806
Epoch 53/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2592 - accuracy: 0.9062 - precision_1: 0.8462 - recall_1: 0.9167
Epoch 53: val_loss improved from 0.34438 to 0.34360, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8666 - precision_1: 0.8580 - recall_1: 0.8909 - val_loss: 0.3436 - val_accuracy: 0.8445 - val_precision_1: 0.8489 - val_recall_1: 0.8806
Epoch 54/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3740 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 54: val_loss did not improve from 0.34360
30/30 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8676 - precision_1: 0.8569 - recall_1: 0.8949 - val_loss: 0.3448 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 55/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3387 - accuracy: 0.9062 - precision_1: 0.9000 - recall_1: 0.9474
Epoch 55: val_loss improved from 0.34360 to 0.34351, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8676 - precision_1: 0.8596 - recall_1: 0.8909 - val_loss: 0.3435 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 56/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2503 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8947
Epoch 56: val_loss improved from 0.34351 to 0.34342, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8687 - precision_1: 0.8585 - recall_1: 0.8949 - val_loss: 0.3434 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 57/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3403 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 57: val_loss improved from 0.34342 to 0.34311, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8666 - precision_1: 0.8580 - recall_1: 0.8909 - val_loss: 0.3431 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 58/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2310 - accuracy: 0.9062 - precision_1: 0.7500 - recall_1: 1.0000
Epoch 58: val_loss improved from 0.34311 to 0.34293, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8676 - precision_1: 0.8596 - recall_1: 0.8909 - val_loss: 0.3429 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 59/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2765 - accuracy: 0.9375 - precision_1: 0.9048 - recall_1: 1.0000
Epoch 59: val_loss improved from 0.34293 to 0.34185, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8687 - precision_1: 0.8613 - recall_1: 0.8909 - val_loss: 0.3419 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 60/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2837 - accuracy: 0.9062 - precision_1: 0.8000 - recall_1: 1.0000
Epoch 60: val_loss did not improve from 0.34185
30/30 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8655 - precision_1: 0.8577 - recall_1: 0.8889 - val_loss: 0.3430 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 61/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3928 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 61: val_loss did not improve from 0.34185
30/30 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8655 - precision_1: 0.8577 - recall_1: 0.8889 - val_loss: 0.3422 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 62/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4825 - accuracy: 0.8125 - precision_1: 0.7273 - recall_1: 1.0000
Epoch 62: val_loss improved from 0.34185 to 0.34138, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8645 - precision_1: 0.8574 - recall_1: 0.8869 - val_loss: 0.3414 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 63/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3587 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 63: val_loss improved from 0.34138 to 0.34110, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8666 - precision_1: 0.8580 - recall_1: 0.8909 - val_loss: 0.3411 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 64/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2136 - accuracy: 0.9062 - precision_1: 0.8421 - recall_1: 1.0000
Epoch 64: val_loss improved from 0.34110 to 0.34041, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8666 - precision_1: 0.8580 - recall_1: 0.8909 - val_loss: 0.3404 - val_accuracy: 0.8403 - val_precision_1: 0.8429 - val_recall_1: 0.8806
Epoch 65/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2492 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 65: val_loss improved from 0.34041 to 0.34038, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8666 - precision_1: 0.8594 - recall_1: 0.8889 - val_loss: 0.3404 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 66/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3275 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 66: val_loss did not improve from 0.34038
30/30 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8666 - precision_1: 0.8566 - recall_1: 0.8929 - val_loss: 0.3408 - val_accuracy: 0.8445 - val_precision_1: 0.8540 - val_recall_1: 0.8731
Epoch 67/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3872 - accuracy: 0.9062 - precision_1: 0.8333 - recall_1: 1.0000
Epoch 67: val_loss did not improve from 0.34038
30/30 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8655 - precision_1: 0.8577 - recall_1: 0.8889 - val_loss: 0.3408 - val_accuracy: 0.8487 - val_precision_1: 0.8551 - val_recall_1: 0.8806
Epoch 68/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4365 - accuracy: 0.7812 - precision_1: 0.7619 - recall_1: 0.8889
Epoch 68: val_loss did not improve from 0.34038
30/30 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8666 - precision_1: 0.8580 - recall_1: 0.8909 - val_loss: 0.3408 - val_accuracy: 0.8445 - val_precision_1: 0.8540 - val_recall_1: 0.8731
Epoch 69/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3137 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 69: val_loss improved from 0.34038 to 0.33998, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8655 - precision_1: 0.8591 - recall_1: 0.8869 - val_loss: 0.3400 - val_accuracy: 0.8445 - val_precision_1: 0.8540 - val_recall_1: 0.8731
Epoch 70/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2155 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 70: val_loss did not improve from 0.33998
30/30 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8676 - precision_1: 0.8596 - recall_1: 0.8909 - val_loss: 0.3403 - val_accuracy: 0.8445 - val_precision_1: 0.8540 - val_recall_1: 0.8731
Epoch 71/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2989 - accuracy: 0.8750 - precision_1: 0.7500 - recall_1: 0.9000
Epoch 71: val_loss did not improve from 0.33998
30/30 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8645 - precision_1: 0.8560 - recall_1: 0.8889 - val_loss: 0.3401 - val_accuracy: 0.8445 - val_precision_1: 0.8540 - val_recall_1: 0.8731
Epoch 72/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3567 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 72: val_loss did not improve from 0.33998
30/30 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8676 - precision_1: 0.8611 - recall_1: 0.8889 - val_loss: 0.3403 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 73/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2831 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 73: val_loss improved from 0.33998 to 0.33968, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8676 - precision_1: 0.8611 - recall_1: 0.8889 - val_loss: 0.3397 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 74/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3631 - accuracy: 0.8438 - precision_1: 0.9444 - recall_1: 0.8095
Epoch 74: val_loss did not improve from 0.33968
30/30 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8655 - precision_1: 0.8563 - recall_1: 0.8909 - val_loss: 0.3399 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 75/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 75: val_loss improved from 0.33968 to 0.33903, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8718 - precision_1: 0.8664 - recall_1: 0.8909 - val_loss: 0.3390 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 76/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4847 - accuracy: 0.8438 - precision_1: 0.8095 - recall_1: 0.9444
Epoch 76: val_loss did not improve from 0.33903
30/30 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8666 - precision_1: 0.8594 - recall_1: 0.8889 - val_loss: 0.3391 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 77/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3177 - accuracy: 0.8438 - precision_1: 0.7333 - recall_1: 0.9167
Epoch 77: val_loss did not improve from 0.33903
30/30 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8687 - precision_1: 0.8613 - recall_1: 0.8909 - val_loss: 0.3392 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 78/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2150 - accuracy: 0.9375 - precision_1: 0.9500 - recall_1: 0.9500
Epoch 78: val_loss did not improve from 0.33903
30/30 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8687 - precision_1: 0.8599 - recall_1: 0.8929 - val_loss: 0.3399 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 79/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2524 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9048
Epoch 79: val_loss did not improve from 0.33903
30/30 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8676 - precision_1: 0.8596 - recall_1: 0.8909 - val_loss: 0.3400 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 80/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2510 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 80: val_loss improved from 0.33903 to 0.33885, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8687 - precision_1: 0.8642 - recall_1: 0.8869 - val_loss: 0.3388 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 81/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2276 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9130
Epoch 81: val_loss did not improve from 0.33885
30/30 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8697 - precision_1: 0.8602 - recall_1: 0.8949 - val_loss: 0.3407 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 82/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2553 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 82: val_loss improved from 0.33885 to 0.33866, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3219 - accuracy: 0.8697 - precision_1: 0.8659 - recall_1: 0.8869 - val_loss: 0.3387 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 83/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3197 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 83: val_loss did not improve from 0.33866
30/30 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8708 - precision_1: 0.8647 - recall_1: 0.8909 - val_loss: 0.3396 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 84/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3802 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 84: val_loss improved from 0.33866 to 0.33800, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8687 - precision_1: 0.8642 - recall_1: 0.8869 - val_loss: 0.3380 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 85/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2327 - accuracy: 0.9062 - precision_1: 0.8889 - recall_1: 0.9412
Epoch 85: val_loss did not improve from 0.33800
30/30 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8708 - precision_1: 0.8647 - recall_1: 0.8909 - val_loss: 0.3388 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 86/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2365 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 1.0000
Epoch 86: val_loss did not improve from 0.33800
30/30 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8676 - precision_1: 0.8611 - recall_1: 0.8889 - val_loss: 0.3385 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 87/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2805 - accuracy: 0.8750 - precision_1: 0.9167 - recall_1: 0.9167
Epoch 87: val_loss improved from 0.33800 to 0.33778, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8687 - precision_1: 0.8642 - recall_1: 0.8869 - val_loss: 0.3378 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 88/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1716 - accuracy: 0.9062 - precision_1: 0.8571 - recall_1: 0.9231
Epoch 88: val_loss improved from 0.33778 to 0.33763, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8687 - precision_1: 0.8613 - recall_1: 0.8909 - val_loss: 0.3376 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 89/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2832 - accuracy: 0.8750 - precision_1: 0.8947 - recall_1: 0.8947
Epoch 89: val_loss improved from 0.33763 to 0.33691, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3186 - accuracy: 0.8676 - precision_1: 0.8625 - recall_1: 0.8869 - val_loss: 0.3369 - val_accuracy: 0.8277 - val_precision_1: 0.8345 - val_recall_1: 0.8657
Epoch 90/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2547 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 90: val_loss improved from 0.33691 to 0.33584, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8687 - precision_1: 0.8642 - recall_1: 0.8869 - val_loss: 0.3358 - val_accuracy: 0.8277 - val_precision_1: 0.8345 - val_recall_1: 0.8657
Epoch 91/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2527 - accuracy: 0.9375 - precision_1: 0.9000 - recall_1: 1.0000
Epoch 91: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8708 - precision_1: 0.8647 - recall_1: 0.8909 - val_loss: 0.3359 - val_accuracy: 0.8277 - val_precision_1: 0.8345 - val_recall_1: 0.8657
Epoch 92/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4933 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.6667
Epoch 92: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8718 - precision_1: 0.8621 - recall_1: 0.8970 - val_loss: 0.3382 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 93/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3851 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7059
Epoch 93: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8687 - precision_1: 0.8642 - recall_1: 0.8869 - val_loss: 0.3373 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 94/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2984 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 94: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8687 - precision_1: 0.8642 - recall_1: 0.8869 - val_loss: 0.3359 - val_accuracy: 0.8277 - val_precision_1: 0.8345 - val_recall_1: 0.8657
Epoch 95/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3176 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 95: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8697 - precision_1: 0.8616 - recall_1: 0.8929 - val_loss: 0.3374 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 96/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3625 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 96: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8687 - precision_1: 0.8642 - recall_1: 0.8869 - val_loss: 0.3366 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 97/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2375 - accuracy: 0.9375 - precision_1: 0.9545 - recall_1: 0.9545
Epoch 97: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8718 - precision_1: 0.8621 - recall_1: 0.8970 - val_loss: 0.3395 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 98/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2932 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 98: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8718 - precision_1: 0.8679 - recall_1: 0.8889 - val_loss: 0.3361 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 99/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3831 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 99: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8718 - precision_1: 0.8635 - recall_1: 0.8949 - val_loss: 0.3364 - val_accuracy: 0.8277 - val_precision_1: 0.8345 - val_recall_1: 0.8657
Epoch 100/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2041 - accuracy: 0.8438 - precision_1: 0.9286 - recall_1: 0.7647
Epoch 100: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8708 - precision_1: 0.8619 - recall_1: 0.8949 - val_loss: 0.3372 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 101/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5195 - accuracy: 0.7188 - precision_1: 0.6154 - recall_1: 0.6667
Epoch 101: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8697 - precision_1: 0.8616 - recall_1: 0.8929 - val_loss: 0.3378 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 102/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4822 - accuracy: 0.7188 - precision_1: 0.6250 - recall_1: 0.7692
Epoch 102: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8718 - precision_1: 0.8664 - recall_1: 0.8909 - val_loss: 0.3381 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 103/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2220 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 103: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8739 - precision_1: 0.8684 - recall_1: 0.8929 - val_loss: 0.3382 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 104/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2329 - accuracy: 0.9375 - precision_1: 0.9130 - recall_1: 1.0000
Epoch 104: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8771 - precision_1: 0.8720 - recall_1: 0.8949 - val_loss: 0.3365 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 105/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3052 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 105: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8718 - precision_1: 0.8650 - recall_1: 0.8929 - val_loss: 0.3365 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 106/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3930 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 106: val_loss did not improve from 0.33584
30/30 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8750 - precision_1: 0.8686 - recall_1: 0.8949 - val_loss: 0.3360 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 107/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3803 - accuracy: 0.8438 - precision_1: 0.8095 - recall_1: 0.9444
Epoch 107: val_loss improved from 0.33584 to 0.33457, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8750 - precision_1: 0.8730 - recall_1: 0.8889 - val_loss: 0.3346 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 108/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2843 - accuracy: 0.9062 - precision_1: 0.8462 - recall_1: 0.9167
Epoch 108: val_loss improved from 0.33457 to 0.33444, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3093 - accuracy: 0.8708 - precision_1: 0.8661 - recall_1: 0.8889 - val_loss: 0.3344 - val_accuracy: 0.8193 - val_precision_1: 0.8227 - val_recall_1: 0.8657
Epoch 109/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4702 - accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125
Epoch 109: val_loss improved from 0.33444 to 0.33434, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8718 - precision_1: 0.8635 - recall_1: 0.8949 - val_loss: 0.3343 - val_accuracy: 0.8319 - val_precision_1: 0.8406 - val_recall_1: 0.8657
Epoch 110/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3518 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 110: val_loss did not improve from 0.33434
30/30 [==============================] - 0s 3ms/step - loss: 0.3083 - accuracy: 0.8739 - precision_1: 0.8684 - recall_1: 0.8929 - val_loss: 0.3345 - val_accuracy: 0.8319 - val_precision_1: 0.8406 - val_recall_1: 0.8657
Epoch 111/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2797 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 111: val_loss improved from 0.33434 to 0.33367, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3075 - accuracy: 0.8739 - precision_1: 0.8713 - recall_1: 0.8889 - val_loss: 0.3337 - val_accuracy: 0.8319 - val_precision_1: 0.8406 - val_recall_1: 0.8657
Epoch 112/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2702 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9091
Epoch 112: val_loss improved from 0.33367 to 0.33254, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8771 - precision_1: 0.8735 - recall_1: 0.8929 - val_loss: 0.3325 - val_accuracy: 0.8193 - val_precision_1: 0.8227 - val_recall_1: 0.8657
Epoch 113/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3945 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 113: val_loss did not improve from 0.33254
30/30 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8792 - precision_1: 0.8755 - recall_1: 0.8949 - val_loss: 0.3326 - val_accuracy: 0.8319 - val_precision_1: 0.8406 - val_recall_1: 0.8657
Epoch 114/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2454 - accuracy: 0.8750 - precision_1: 0.9500 - recall_1: 0.8636
Epoch 114: val_loss did not improve from 0.33254
30/30 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8750 - precision_1: 0.8686 - recall_1: 0.8949 - val_loss: 0.3333 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 115/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3942 - accuracy: 0.8438 - precision_1: 0.8182 - recall_1: 0.9474
Epoch 115: val_loss improved from 0.33254 to 0.33191, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3052 - accuracy: 0.8771 - precision_1: 0.8720 - recall_1: 0.8949 - val_loss: 0.3319 - val_accuracy: 0.8361 - val_precision_1: 0.8467 - val_recall_1: 0.8657
Epoch 116/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2658 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9091
Epoch 116: val_loss did not improve from 0.33191
30/30 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8771 - precision_1: 0.8706 - recall_1: 0.8970 - val_loss: 0.3335 - val_accuracy: 0.8403 - val_precision_1: 0.8529 - val_recall_1: 0.8657
Epoch 117/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4039 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 117: val_loss improved from 0.33191 to 0.32926, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8782 - precision_1: 0.8767 - recall_1: 0.8909 - val_loss: 0.3293 - val_accuracy: 0.8319 - val_precision_1: 0.8406 - val_recall_1: 0.8657
Epoch 118/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4338 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.7500
Epoch 118: val_loss did not improve from 0.32926
30/30 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8750 - precision_1: 0.8701 - recall_1: 0.8929 - val_loss: 0.3300 - val_accuracy: 0.8319 - val_precision_1: 0.8406 - val_recall_1: 0.8657
Epoch 119/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3149 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 119: val_loss improved from 0.32926 to 0.32821, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.8803 - precision_1: 0.8772 - recall_1: 0.8949 - val_loss: 0.3282 - val_accuracy: 0.8319 - val_precision_1: 0.8406 - val_recall_1: 0.8657
Epoch 120/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5112 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 120: val_loss did not improve from 0.32821
30/30 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8739 - precision_1: 0.8698 - recall_1: 0.8909 - val_loss: 0.3282 - val_accuracy: 0.8361 - val_precision_1: 0.8417 - val_recall_1: 0.8731
Epoch 121/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1632 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9444
Epoch 121: val_loss improved from 0.32821 to 0.32806, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8792 - precision_1: 0.8755 - recall_1: 0.8949 - val_loss: 0.3281 - val_accuracy: 0.8361 - val_precision_1: 0.8417 - val_recall_1: 0.8731
Epoch 122/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1751 - accuracy: 0.9062 - precision_1: 0.9231 - recall_1: 0.8571
Epoch 122: val_loss improved from 0.32806 to 0.32651, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3015 - accuracy: 0.8792 - precision_1: 0.8770 - recall_1: 0.8929 - val_loss: 0.3265 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 123/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3136 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 123: val_loss did not improve from 0.32651
30/30 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8782 - precision_1: 0.8738 - recall_1: 0.8949 - val_loss: 0.3266 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 124/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4754 - accuracy: 0.7500 - precision_1: 0.8421 - recall_1: 0.7619
Epoch 124: val_loss improved from 0.32651 to 0.32553, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3006 - accuracy: 0.8750 - precision_1: 0.8686 - recall_1: 0.8949 - val_loss: 0.3255 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 125/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3231 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 125: val_loss improved from 0.32553 to 0.32532, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.8782 - precision_1: 0.8738 - recall_1: 0.8949 - val_loss: 0.3253 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 126/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2540 - accuracy: 0.9375 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 126: val_loss improved from 0.32532 to 0.32515, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.8782 - precision_1: 0.8738 - recall_1: 0.8949 - val_loss: 0.3252 - val_accuracy: 0.8361 - val_precision_1: 0.8417 - val_recall_1: 0.8731
Epoch 127/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4504 - accuracy: 0.7188 - precision_1: 0.7222 - recall_1: 0.7647
Epoch 127: val_loss improved from 0.32515 to 0.32263, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2986 - accuracy: 0.8782 - precision_1: 0.8767 - recall_1: 0.8909 - val_loss: 0.3226 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 128/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2739 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 0.9231
Epoch 128: val_loss improved from 0.32263 to 0.32208, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8782 - precision_1: 0.8738 - recall_1: 0.8949 - val_loss: 0.3221 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 129/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1190 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9412
Epoch 129: val_loss did not improve from 0.32208
30/30 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8761 - precision_1: 0.8703 - recall_1: 0.8949 - val_loss: 0.3237 - val_accuracy: 0.8403 - val_precision_1: 0.8478 - val_recall_1: 0.8731
Epoch 130/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2392 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 130: val_loss improved from 0.32208 to 0.32070, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8803 - precision_1: 0.8802 - recall_1: 0.8909 - val_loss: 0.3207 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 131/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1089 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 131: val_loss improved from 0.32070 to 0.32041, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8782 - precision_1: 0.8708 - recall_1: 0.8990 - val_loss: 0.3204 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 132/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3368 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 132: val_loss improved from 0.32041 to 0.31832, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2954 - accuracy: 0.8824 - precision_1: 0.8822 - recall_1: 0.8929 - val_loss: 0.3183 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 133/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2438 - accuracy: 0.9062 - precision_1: 0.8235 - recall_1: 1.0000
Epoch 133: val_loss improved from 0.31832 to 0.31743, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8792 - precision_1: 0.8740 - recall_1: 0.8970 - val_loss: 0.3174 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 134/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1755 - accuracy: 0.9375 - precision_1: 0.8947 - recall_1: 1.0000
Epoch 134: val_loss did not improve from 0.31743
30/30 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8782 - precision_1: 0.8694 - recall_1: 0.9010 - val_loss: 0.3185 - val_accuracy: 0.8403 - val_precision_1: 0.8478 - val_recall_1: 0.8731
Epoch 135/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3619 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 135: val_loss did not improve from 0.31743
30/30 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8803 - precision_1: 0.8757 - recall_1: 0.8970 - val_loss: 0.3178 - val_accuracy: 0.8403 - val_precision_1: 0.8478 - val_recall_1: 0.8731
Epoch 136/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1740 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 0.9231
Epoch 136: val_loss improved from 0.31743 to 0.31494, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8834 - precision_1: 0.8810 - recall_1: 0.8970 - val_loss: 0.3149 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 137/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4872 - accuracy: 0.8125 - precision_1: 0.7647 - recall_1: 0.8667
Epoch 137: val_loss improved from 0.31494 to 0.31451, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.8845 - precision_1: 0.8797 - recall_1: 0.9010 - val_loss: 0.3145 - val_accuracy: 0.8403 - val_precision_1: 0.8478 - val_recall_1: 0.8731
Epoch 138/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2298 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 138: val_loss did not improve from 0.31451
30/30 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8876 - precision_1: 0.8849 - recall_1: 0.9010 - val_loss: 0.3146 - val_accuracy: 0.8445 - val_precision_1: 0.8540 - val_recall_1: 0.8731
Epoch 139/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3263 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 139: val_loss improved from 0.31451 to 0.31153, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2908 - accuracy: 0.8876 - precision_1: 0.8865 - recall_1: 0.8990 - val_loss: 0.3115 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 140/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3096 - accuracy: 0.8438 - precision_1: 0.7333 - recall_1: 0.9167
Epoch 140: val_loss did not improve from 0.31153
30/30 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8834 - precision_1: 0.8780 - recall_1: 0.9010 - val_loss: 0.3135 - val_accuracy: 0.8487 - val_precision_1: 0.8603 - val_recall_1: 0.8731
Epoch 141/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3515 - accuracy: 0.8438 - precision_1: 1.0000 - recall_1: 0.6875
Epoch 141: val_loss did not improve from 0.31153
30/30 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8845 - precision_1: 0.8812 - recall_1: 0.8990 - val_loss: 0.3119 - val_accuracy: 0.8487 - val_precision_1: 0.8603 - val_recall_1: 0.8731
Epoch 142/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3542 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 142: val_loss did not improve from 0.31153
30/30 [==============================] - 0s 3ms/step - loss: 0.2887 - accuracy: 0.8824 - precision_1: 0.8792 - recall_1: 0.8970 - val_loss: 0.3127 - val_accuracy: 0.8445 - val_precision_1: 0.8593 - val_recall_1: 0.8657
Epoch 143/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2597 - accuracy: 0.9062 - precision_1: 0.8333 - recall_1: 0.9091
Epoch 143: val_loss did not improve from 0.31153
30/30 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8824 - precision_1: 0.8777 - recall_1: 0.8990 - val_loss: 0.3125 - val_accuracy: 0.8445 - val_precision_1: 0.8593 - val_recall_1: 0.8657
Epoch 144/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3766 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 144: val_loss improved from 0.31153 to 0.31032, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.8887 - precision_1: 0.8867 - recall_1: 0.9010 - val_loss: 0.3103 - val_accuracy: 0.8445 - val_precision_1: 0.8593 - val_recall_1: 0.8657
Epoch 145/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3475 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 145: val_loss improved from 0.31032 to 0.31022, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.8866 - precision_1: 0.8817 - recall_1: 0.9030 - val_loss: 0.3102 - val_accuracy: 0.8445 - val_precision_1: 0.8593 - val_recall_1: 0.8657
Epoch 146/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3936 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 146: val_loss improved from 0.31022 to 0.30814, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2869 - accuracy: 0.8845 - precision_1: 0.8812 - recall_1: 0.8990 - val_loss: 0.3081 - val_accuracy: 0.8487 - val_precision_1: 0.8603 - val_recall_1: 0.8731
Epoch 147/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2433 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 147: val_loss improved from 0.30814 to 0.30695, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2864 - accuracy: 0.8824 - precision_1: 0.8762 - recall_1: 0.9010 - val_loss: 0.3069 - val_accuracy: 0.8487 - val_precision_1: 0.8603 - val_recall_1: 0.8731
Epoch 148/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4580 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 148: val_loss did not improve from 0.30695
30/30 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8866 - precision_1: 0.8802 - recall_1: 0.9051 - val_loss: 0.3076 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 149/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2839 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 149: val_loss improved from 0.30695 to 0.30414, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8866 - precision_1: 0.8847 - recall_1: 0.8990 - val_loss: 0.3041 - val_accuracy: 0.8445 - val_precision_1: 0.8489 - val_recall_1: 0.8806
Epoch 150/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4104 - accuracy: 0.8125 - precision_1: 0.9231 - recall_1: 0.7059
Epoch 150: val_loss did not improve from 0.30414
30/30 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8855 - precision_1: 0.8784 - recall_1: 0.9051 - val_loss: 0.3060 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 151/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3407 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 151: val_loss did not improve from 0.30414
30/30 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8855 - precision_1: 0.8799 - recall_1: 0.9030 - val_loss: 0.3046 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 152/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2396 - accuracy: 0.8750 - precision_1: 0.9231 - recall_1: 0.8000
Epoch 152: val_loss did not improve from 0.30414
30/30 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.8824 - precision_1: 0.8792 - recall_1: 0.8970 - val_loss: 0.3050 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 153/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2503 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 153: val_loss did not improve from 0.30414
30/30 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.8918 - precision_1: 0.8889 - recall_1: 0.9051 - val_loss: 0.3061 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 154/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1513 - accuracy: 0.9688 - precision_1: 0.9524 - recall_1: 1.0000
Epoch 154: val_loss did not improve from 0.30414
30/30 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8855 - precision_1: 0.8784 - recall_1: 0.9051 - val_loss: 0.3097 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 155/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2672 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 155: val_loss improved from 0.30414 to 0.30394, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8897 - precision_1: 0.8884 - recall_1: 0.9010 - val_loss: 0.3039 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 156/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3261 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 0.7778
Epoch 156: val_loss improved from 0.30394 to 0.30167, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.8887 - precision_1: 0.8836 - recall_1: 0.9051 - val_loss: 0.3017 - val_accuracy: 0.8571 - val_precision_1: 0.8623 - val_recall_1: 0.8881
Epoch 157/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2624 - accuracy: 0.9375 - precision_1: 0.8667 - recall_1: 1.0000
Epoch 157: val_loss did not improve from 0.30167
30/30 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8897 - precision_1: 0.8854 - recall_1: 0.9051 - val_loss: 0.3025 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 158/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2230 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 158: val_loss did not improve from 0.30167
30/30 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8876 - precision_1: 0.8819 - recall_1: 0.9051 - val_loss: 0.3019 - val_accuracy: 0.8571 - val_precision_1: 0.8676 - val_recall_1: 0.8806
Epoch 159/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4372 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.6429
Epoch 159: val_loss improved from 0.30167 to 0.30012, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8908 - precision_1: 0.8871 - recall_1: 0.9051 - val_loss: 0.3001 - val_accuracy: 0.8613 - val_precision_1: 0.8686 - val_recall_1: 0.8881
Epoch 160/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1542 - accuracy: 0.9375 - precision_1: 0.9048 - recall_1: 1.0000
Epoch 160: val_loss did not improve from 0.30012
30/30 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8887 - precision_1: 0.8851 - recall_1: 0.9030 - val_loss: 0.3009 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 161/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3271 - accuracy: 0.9062 - precision_1: 0.8333 - recall_1: 0.9091
Epoch 161: val_loss improved from 0.30012 to 0.29915, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.8887 - precision_1: 0.8867 - recall_1: 0.9010 - val_loss: 0.2992 - val_accuracy: 0.8571 - val_precision_1: 0.8623 - val_recall_1: 0.8881
Epoch 162/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2024 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9130
Epoch 162: val_loss did not improve from 0.29915
30/30 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8929 - precision_1: 0.8861 - recall_1: 0.9111 - val_loss: 0.3027 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 163/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3951 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 163: val_loss did not improve from 0.29915
30/30 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8897 - precision_1: 0.8854 - recall_1: 0.9051 - val_loss: 0.3017 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 164/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2602 - accuracy: 0.9375 - precision_1: 0.9333 - recall_1: 0.9333
Epoch 164: val_loss did not improve from 0.29915
30/30 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8908 - precision_1: 0.8856 - recall_1: 0.9071 - val_loss: 0.3024 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 165/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3074 - accuracy: 0.8750 - precision_1: 0.9500 - recall_1: 0.8636
Epoch 165: val_loss did not improve from 0.29915
30/30 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8897 - precision_1: 0.8869 - recall_1: 0.9030 - val_loss: 0.3016 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 166/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1601 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 166: val_loss improved from 0.29915 to 0.29579, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2755 - accuracy: 0.8908 - precision_1: 0.8934 - recall_1: 0.8970 - val_loss: 0.2958 - val_accuracy: 0.8571 - val_precision_1: 0.8521 - val_recall_1: 0.9030
Epoch 167/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2014 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 167: val_loss did not improve from 0.29579
30/30 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8939 - precision_1: 0.8863 - recall_1: 0.9131 - val_loss: 0.2975 - val_accuracy: 0.8571 - val_precision_1: 0.8676 - val_recall_1: 0.8806
Epoch 168/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1248 - accuracy: 0.9688 - precision_1: 0.9524 - recall_1: 1.0000
Epoch 168: val_loss did not improve from 0.29579
30/30 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.8908 - precision_1: 0.8841 - recall_1: 0.9091 - val_loss: 0.2979 - val_accuracy: 0.8571 - val_precision_1: 0.8676 - val_recall_1: 0.8806
Epoch 169/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4082 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 169: val_loss improved from 0.29579 to 0.29456, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.8971 - precision_1: 0.8946 - recall_1: 0.9091 - val_loss: 0.2946 - val_accuracy: 0.8613 - val_precision_1: 0.8686 - val_recall_1: 0.8881
Epoch 170/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2233 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 170: val_loss did not improve from 0.29456
30/30 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8950 - precision_1: 0.8880 - recall_1: 0.9131 - val_loss: 0.2966 - val_accuracy: 0.8613 - val_precision_1: 0.8741 - val_recall_1: 0.8806
Epoch 171/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1715 - accuracy: 0.9688 - precision_1: 0.9333 - recall_1: 1.0000
Epoch 171: val_loss did not improve from 0.29456
30/30 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8929 - precision_1: 0.8891 - recall_1: 0.9071 - val_loss: 0.2949 - val_accuracy: 0.8697 - val_precision_1: 0.8759 - val_recall_1: 0.8955
Epoch 172/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2017 - accuracy: 0.9062 - precision_1: 0.9167 - recall_1: 0.8462
Epoch 172: val_loss did not improve from 0.29456
30/30 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.9002 - precision_1: 0.8906 - recall_1: 0.9212 - val_loss: 0.2963 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 173/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1997 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 173: val_loss improved from 0.29456 to 0.29407, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.8939 - precision_1: 0.8893 - recall_1: 0.9091 - val_loss: 0.2941 - val_accuracy: 0.8655 - val_precision_1: 0.8750 - val_recall_1: 0.8881
Epoch 174/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1803 - accuracy: 0.9375 - precision_1: 0.8571 - recall_1: 1.0000
Epoch 174: val_loss did not improve from 0.29407
30/30 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8960 - precision_1: 0.8898 - recall_1: 0.9131 - val_loss: 0.2958 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 175/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1851 - accuracy: 0.9062 - precision_1: 0.8889 - recall_1: 0.9412
Epoch 175: val_loss did not improve from 0.29407
30/30 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8992 - precision_1: 0.8919 - recall_1: 0.9172 - val_loss: 0.2945 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 176/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2001 - accuracy: 0.9375 - precision_1: 0.9524 - recall_1: 0.9524
Epoch 176: val_loss did not improve from 0.29407
30/30 [==============================] - 0s 3ms/step - loss: 0.2717 - accuracy: 0.8939 - precision_1: 0.8893 - recall_1: 0.9091 - val_loss: 0.2942 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 177/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3094 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 177: val_loss improved from 0.29407 to 0.29149, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8971 - precision_1: 0.8915 - recall_1: 0.9131 - val_loss: 0.2915 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 178/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2417 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 178: val_loss did not improve from 0.29149
30/30 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8971 - precision_1: 0.8900 - recall_1: 0.9152 - val_loss: 0.2928 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 179/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 179: val_loss improved from 0.29149 to 0.29110, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2702 - accuracy: 0.8960 - precision_1: 0.8913 - recall_1: 0.9111 - val_loss: 0.2911 - val_accuracy: 0.8571 - val_precision_1: 0.8731 - val_recall_1: 0.8731
Epoch 180/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1389 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9545
Epoch 180: val_loss did not improve from 0.29110
30/30 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.9002 - precision_1: 0.8922 - recall_1: 0.9192 - val_loss: 0.2952 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 181/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3230 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 181: val_loss improved from 0.29110 to 0.29010, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8981 - precision_1: 0.8933 - recall_1: 0.9131 - val_loss: 0.2901 - val_accuracy: 0.8571 - val_precision_1: 0.8731 - val_recall_1: 0.8731
Epoch 182/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3609 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 182: val_loss improved from 0.29010 to 0.29000, saving model to model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8992 - precision_1: 0.8919 - recall_1: 0.9172 - val_loss: 0.2900 - val_accuracy: 0.8571 - val_precision_1: 0.8731 - val_recall_1: 0.8731
Epoch 183/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2788 - accuracy: 0.9375 - precision_1: 0.8750 - recall_1: 1.0000
Epoch 183: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.8960 - precision_1: 0.8898 - recall_1: 0.9131 - val_loss: 0.2924 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 184/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3905 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.7143
Epoch 184: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 0.8992 - precision_1: 0.8919 - recall_1: 0.9172 - val_loss: 0.2932 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 185/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2234 - accuracy: 0.9062 - precision_1: 0.9333 - recall_1: 0.8750
Epoch 185: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.9002 - precision_1: 0.8953 - recall_1: 0.9152 - val_loss: 0.2913 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 186/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 186: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8981 - precision_1: 0.8902 - recall_1: 0.9172 - val_loss: 0.2924 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 187/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1943 - accuracy: 0.9375 - precision_1: 0.9048 - recall_1: 1.0000
Epoch 187: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8971 - precision_1: 0.8900 - recall_1: 0.9152 - val_loss: 0.2948 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 188/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2101 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 188: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8971 - precision_1: 0.8915 - recall_1: 0.9131 - val_loss: 0.2912 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 189/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1752 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 189: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8981 - precision_1: 0.8933 - recall_1: 0.9131 - val_loss: 0.2901 - val_accuracy: 0.8571 - val_precision_1: 0.8731 - val_recall_1: 0.8731
Epoch 190/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3184 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 190: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.8981 - precision_1: 0.8887 - recall_1: 0.9192 - val_loss: 0.2912 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 191/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2691 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 191: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2638 - accuracy: 0.8971 - precision_1: 0.8900 - recall_1: 0.9152 - val_loss: 0.2931 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 192/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1926 - accuracy: 0.8750 - precision_1: 0.8636 - recall_1: 0.9500
Epoch 192: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8960 - precision_1: 0.8929 - recall_1: 0.9091 - val_loss: 0.2908 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 193/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2092 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 193: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8971 - precision_1: 0.8915 - recall_1: 0.9131 - val_loss: 0.2909 - val_accuracy: 0.8487 - val_precision_1: 0.8603 - val_recall_1: 0.8731
Epoch 194/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1903 - accuracy: 0.9062 - precision_1: 0.9545 - recall_1: 0.9130
Epoch 194: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8992 - precision_1: 0.8904 - recall_1: 0.9192 - val_loss: 0.2955 - val_accuracy: 0.8613 - val_precision_1: 0.8797 - val_recall_1: 0.8731
Epoch 195/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8750 - precision_1: 0.9231 - recall_1: 0.8000
Epoch 195: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8981 - precision_1: 0.8902 - recall_1: 0.9172 - val_loss: 0.2937 - val_accuracy: 0.8571 - val_precision_1: 0.8731 - val_recall_1: 0.8731
Epoch 196/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3384 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 196: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.8992 - precision_1: 0.8904 - recall_1: 0.9192 - val_loss: 0.2953 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 197/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2190 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 197: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.8981 - precision_1: 0.8948 - recall_1: 0.9111 - val_loss: 0.2922 - val_accuracy: 0.8571 - val_precision_1: 0.8731 - val_recall_1: 0.8731
Epoch 198/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1307 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9545
Epoch 198: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8960 - precision_1: 0.8913 - recall_1: 0.9111 - val_loss: 0.2915 - val_accuracy: 0.8571 - val_precision_1: 0.8731 - val_recall_1: 0.8731
Epoch 199/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3601 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 199: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9002 - precision_1: 0.8937 - recall_1: 0.9172 - val_loss: 0.2922 - val_accuracy: 0.8487 - val_precision_1: 0.8603 - val_recall_1: 0.8731
Epoch 200/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2744 - accuracy: 0.8750 - precision_1: 0.9167 - recall_1: 0.7857
Epoch 200: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8981 - precision_1: 0.8917 - recall_1: 0.9152 - val_loss: 0.2937 - val_accuracy: 0.8529 - val_precision_1: 0.8667 - val_recall_1: 0.8731
Epoch 201/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4482 - accuracy: 0.8125 - precision_1: 0.9048 - recall_1: 0.8261
Epoch 201: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.8992 - precision_1: 0.8919 - recall_1: 0.9172 - val_loss: 0.2930 - val_accuracy: 0.8613 - val_precision_1: 0.8797 - val_recall_1: 0.8731
Epoch 202/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1423 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9167
Epoch 202: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8981 - precision_1: 0.8948 - recall_1: 0.9111 - val_loss: 0.2917 - val_accuracy: 0.8529 - val_precision_1: 0.8613 - val_recall_1: 0.8806
Epoch 202: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Model-8x4x1">Model 8x4x1<a class="anchor-link" href="#Model-8x4x1">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [98]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">eightxfourxone_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"8x4x1_model"</span><span class="p">)</span>
<span class="n">eightxfourxone_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">eightxfourxone_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">eightxfourxone_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">eightxfourxone_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">eightxfourxone_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">eightxfourxone_history</span> <span class="o">=</span> <span class="n">eightxfourxone_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
 1/30 [&gt;.............................] - ETA: 17s - loss: 0.7393 - accuracy: 0.4375 - precision_1: 0.8345 - recall_1: 0.8067
Epoch 1: val_loss did not improve from 0.29000
30/30 [==============================] - 1s 11ms/step - loss: 0.7019 - accuracy: 0.5651 - precision_1: 0.7356 - recall_1: 0.4467 - val_loss: 0.7310 - val_accuracy: 0.5126 - val_precision_1: 0.6250 - val_recall_1: 0.3358
Epoch 2/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7608 - accuracy: 0.4375 - precision_1: 0.6364 - recall_1: 0.3333
Epoch 2: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6250 - precision_1: 0.7363 - recall_1: 0.4343 - val_loss: 0.6841 - val_accuracy: 0.5588 - val_precision_1: 0.6667 - val_recall_1: 0.4328
Epoch 3/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5258 - accuracy: 0.6875 - precision_1: 0.8750 - recall_1: 0.4375
Epoch 3: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6712 - precision_1: 0.7630 - recall_1: 0.5333 - val_loss: 0.6456 - val_accuracy: 0.6134 - val_precision_1: 0.7059 - val_recall_1: 0.5373
Epoch 4/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6358 - accuracy: 0.5625 - precision_1: 0.5833 - recall_1: 0.4375
Epoch 4: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7237 - precision_1: 0.7915 - recall_1: 0.6364 - val_loss: 0.6155 - val_accuracy: 0.6639 - val_precision_1: 0.7328 - val_recall_1: 0.6343
Epoch 5/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6027 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7059
Epoch 5: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7637 - precision_1: 0.8000 - recall_1: 0.7273 - val_loss: 0.5910 - val_accuracy: 0.7059 - val_precision_1: 0.7500 - val_recall_1: 0.7164
Epoch 6/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4949 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 6: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7847 - precision_1: 0.8021 - recall_1: 0.7778 - val_loss: 0.5704 - val_accuracy: 0.7311 - val_precision_1: 0.7612 - val_recall_1: 0.7612
Epoch 7/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6549 - accuracy: 0.7188 - precision_1: 0.8636 - recall_1: 0.7600
Epoch 7: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7941 - precision_1: 0.8008 - recall_1: 0.8040 - val_loss: 0.5522 - val_accuracy: 0.7353 - val_precision_1: 0.7630 - val_recall_1: 0.7687
Epoch 8/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4089 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 8: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.8004 - precision_1: 0.8056 - recall_1: 0.8121 - val_loss: 0.5361 - val_accuracy: 0.7437 - val_precision_1: 0.7744 - val_recall_1: 0.7687
Epoch 9/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4690 - accuracy: 0.7812 - precision_1: 0.7857 - recall_1: 0.7333
Epoch 9: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8088 - precision_1: 0.8111 - recall_1: 0.8242 - val_loss: 0.5207 - val_accuracy: 0.7689 - val_precision_1: 0.7926 - val_recall_1: 0.7985
Epoch 10/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4572 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 10: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8172 - precision_1: 0.8166 - recall_1: 0.8364 - val_loss: 0.5067 - val_accuracy: 0.7815 - val_precision_1: 0.8015 - val_recall_1: 0.8134
Epoch 11/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3809 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 11: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.8162 - precision_1: 0.8089 - recall_1: 0.8465 - val_loss: 0.4941 - val_accuracy: 0.7815 - val_precision_1: 0.8015 - val_recall_1: 0.8134
Epoch 12/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5764 - accuracy: 0.7500 - precision_1: 0.7083 - recall_1: 0.9444
Epoch 12: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8225 - precision_1: 0.8135 - recall_1: 0.8545 - val_loss: 0.4819 - val_accuracy: 0.7899 - val_precision_1: 0.8088 - val_recall_1: 0.8209
Epoch 13/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5393 - accuracy: 0.7812 - precision_1: 0.5000 - recall_1: 0.8571
Epoch 13: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8319 - precision_1: 0.8227 - recall_1: 0.8626 - val_loss: 0.4711 - val_accuracy: 0.7941 - val_precision_1: 0.8102 - val_recall_1: 0.8284
Epoch 14/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4360 - accuracy: 0.8750 - precision_1: 0.8636 - recall_1: 0.9500
Epoch 14: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8319 - precision_1: 0.8178 - recall_1: 0.8707 - val_loss: 0.4614 - val_accuracy: 0.8025 - val_precision_1: 0.8129 - val_recall_1: 0.8433
Epoch 15/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3460 - accuracy: 0.8750 - precision_1: 0.8696 - recall_1: 0.9524
Epoch 15: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8351 - precision_1: 0.8201 - recall_1: 0.8747 - val_loss: 0.4518 - val_accuracy: 0.8025 - val_precision_1: 0.8129 - val_recall_1: 0.8433
Epoch 16/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3825 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 16: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8351 - precision_1: 0.8201 - recall_1: 0.8747 - val_loss: 0.4433 - val_accuracy: 0.8025 - val_precision_1: 0.8129 - val_recall_1: 0.8433
Epoch 17/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3748 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.8571
Epoch 17: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8372 - precision_1: 0.8244 - recall_1: 0.8727 - val_loss: 0.4356 - val_accuracy: 0.8025 - val_precision_1: 0.8129 - val_recall_1: 0.8433
Epoch 18/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4126 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 18: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8361 - precision_1: 0.8229 - recall_1: 0.8727 - val_loss: 0.4295 - val_accuracy: 0.8067 - val_precision_1: 0.8143 - val_recall_1: 0.8507
Epoch 19/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3621 - accuracy: 0.8438 - precision_1: 0.7857 - recall_1: 0.8462
Epoch 19: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8382 - precision_1: 0.8248 - recall_1: 0.8747 - val_loss: 0.4235 - val_accuracy: 0.8109 - val_precision_1: 0.8156 - val_recall_1: 0.8582
Epoch 20/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3468 - accuracy: 0.8125 - precision_1: 0.8667 - recall_1: 0.7647
Epoch 20: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8382 - precision_1: 0.8223 - recall_1: 0.8788 - val_loss: 0.4188 - val_accuracy: 0.8109 - val_precision_1: 0.8156 - val_recall_1: 0.8582
Epoch 21/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3553 - accuracy: 0.8438 - precision_1: 0.9444 - recall_1: 0.8095
Epoch 21: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8403 - precision_1: 0.8254 - recall_1: 0.8788 - val_loss: 0.4136 - val_accuracy: 0.8151 - val_precision_1: 0.8169 - val_recall_1: 0.8657
Epoch 22/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8750 - precision_1: 0.8000 - recall_1: 0.9231
Epoch 22: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8424 - precision_1: 0.8286 - recall_1: 0.8788 - val_loss: 0.4092 - val_accuracy: 0.8193 - val_precision_1: 0.8227 - val_recall_1: 0.8657
Epoch 23/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2427 - accuracy: 0.9375 - precision_1: 0.9545 - recall_1: 0.9545
Epoch 23: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8456 - precision_1: 0.8295 - recall_1: 0.8848 - val_loss: 0.4047 - val_accuracy: 0.8193 - val_precision_1: 0.8227 - val_recall_1: 0.8657
Epoch 24/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6006 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 24: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8456 - precision_1: 0.8295 - recall_1: 0.8848 - val_loss: 0.4009 - val_accuracy: 0.8193 - val_precision_1: 0.8227 - val_recall_1: 0.8657
Epoch 25/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3024 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 25: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3708 - accuracy: 0.8466 - precision_1: 0.8311 - recall_1: 0.8848 - val_loss: 0.3971 - val_accuracy: 0.8193 - val_precision_1: 0.8227 - val_recall_1: 0.8657
Epoch 26/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2903 - accuracy: 0.9375 - precision_1: 0.9565 - recall_1: 0.9565
Epoch 26: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8466 - precision_1: 0.8262 - recall_1: 0.8929 - val_loss: 0.3946 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 27/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3507 - accuracy: 0.8125 - precision_1: 0.5714 - recall_1: 1.0000
Epoch 27: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8466 - precision_1: 0.8262 - recall_1: 0.8929 - val_loss: 0.3910 - val_accuracy: 0.8235 - val_precision_1: 0.8239 - val_recall_1: 0.8731
Epoch 28/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3580 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 28: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8466 - precision_1: 0.8250 - recall_1: 0.8949 - val_loss: 0.3888 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 29/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3164 - accuracy: 0.8125 - precision_1: 0.8667 - recall_1: 0.7647
Epoch 29: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8498 - precision_1: 0.8321 - recall_1: 0.8909 - val_loss: 0.3849 - val_accuracy: 0.8277 - val_precision_1: 0.8298 - val_recall_1: 0.8731
Epoch 30/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2402 - accuracy: 0.9062 - precision_1: 0.8636 - recall_1: 1.0000
Epoch 30: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8487 - precision_1: 0.8256 - recall_1: 0.8990 - val_loss: 0.3825 - val_accuracy: 0.8277 - val_precision_1: 0.8298 - val_recall_1: 0.8731
Epoch 31/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8750 - precision_1: 0.7895 - recall_1: 1.0000
Epoch 31: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8519 - precision_1: 0.8315 - recall_1: 0.8970 - val_loss: 0.3804 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 32/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9688 - precision_1: 0.9444 - recall_1: 1.0000
Epoch 32: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8582 - precision_1: 0.8396 - recall_1: 0.8990 - val_loss: 0.3784 - val_accuracy: 0.8319 - val_precision_1: 0.8357 - val_recall_1: 0.8731
Epoch 33/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3033 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 33: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8561 - precision_1: 0.8377 - recall_1: 0.8970 - val_loss: 0.3763 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 34/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4051 - accuracy: 0.7812 - precision_1: 0.6842 - recall_1: 0.9286
Epoch 34: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8571 - precision_1: 0.8380 - recall_1: 0.8990 - val_loss: 0.3736 - val_accuracy: 0.8277 - val_precision_1: 0.8298 - val_recall_1: 0.8731
Epoch 35/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2462 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 35: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8582 - precision_1: 0.8396 - recall_1: 0.8990 - val_loss: 0.3716 - val_accuracy: 0.8193 - val_precision_1: 0.8182 - val_recall_1: 0.8731
Epoch 36/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4052 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 36: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8550 - precision_1: 0.8336 - recall_1: 0.9010 - val_loss: 0.3699 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 37/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3530 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 37: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8582 - precision_1: 0.8358 - recall_1: 0.9051 - val_loss: 0.3692 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 38/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5078 - accuracy: 0.7812 - precision_1: 0.7619 - recall_1: 0.8889
Epoch 38: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8550 - precision_1: 0.8374 - recall_1: 0.8949 - val_loss: 0.3668 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 39/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3619 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 39: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8571 - precision_1: 0.8355 - recall_1: 0.9030 - val_loss: 0.3659 - val_accuracy: 0.8235 - val_precision_1: 0.8286 - val_recall_1: 0.8657
Epoch 40/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2262 - accuracy: 0.8750 - precision_1: 0.9048 - recall_1: 0.9048
Epoch 40: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8540 - precision_1: 0.8346 - recall_1: 0.8970 - val_loss: 0.3646 - val_accuracy: 0.8235 - val_precision_1: 0.8333 - val_recall_1: 0.8582
Epoch 41/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2503 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 41: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8561 - precision_1: 0.8365 - recall_1: 0.8990 - val_loss: 0.3636 - val_accuracy: 0.8235 - val_precision_1: 0.8333 - val_recall_1: 0.8582
Epoch 42/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3677 - accuracy: 0.8125 - precision_1: 0.8421 - recall_1: 0.8421
Epoch 42: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8529 - precision_1: 0.8368 - recall_1: 0.8909 - val_loss: 0.3613 - val_accuracy: 0.8235 - val_precision_1: 0.8333 - val_recall_1: 0.8582
Epoch 43/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1741 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 43: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8561 - precision_1: 0.8377 - recall_1: 0.8970 - val_loss: 0.3608 - val_accuracy: 0.8361 - val_precision_1: 0.8519 - val_recall_1: 0.8582
Epoch 44/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3408 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 44: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8592 - precision_1: 0.8386 - recall_1: 0.9030 - val_loss: 0.3602 - val_accuracy: 0.8361 - val_precision_1: 0.8519 - val_recall_1: 0.8582
Epoch 45/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2564 - accuracy: 0.9062 - precision_1: 0.8696 - recall_1: 1.0000
Epoch 45: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8529 - precision_1: 0.8381 - recall_1: 0.8889 - val_loss: 0.3584 - val_accuracy: 0.8361 - val_precision_1: 0.8519 - val_recall_1: 0.8582
Epoch 46/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2639 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 46: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8550 - precision_1: 0.8374 - recall_1: 0.8949 - val_loss: 0.3571 - val_accuracy: 0.8361 - val_precision_1: 0.8519 - val_recall_1: 0.8582
Epoch 47/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4527 - accuracy: 0.8438 - precision_1: 0.7895 - recall_1: 0.9375
Epoch 47: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8529 - precision_1: 0.8381 - recall_1: 0.8889 - val_loss: 0.3554 - val_accuracy: 0.8361 - val_precision_1: 0.8519 - val_recall_1: 0.8582
Epoch 48/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4871 - accuracy: 0.7188 - precision_1: 0.6316 - recall_1: 0.8571
Epoch 48: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8571 - precision_1: 0.8406 - recall_1: 0.8949 - val_loss: 0.3542 - val_accuracy: 0.8403 - val_precision_1: 0.8582 - val_recall_1: 0.8582
Epoch 49/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2932 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 49: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8540 - precision_1: 0.8397 - recall_1: 0.8889 - val_loss: 0.3536 - val_accuracy: 0.8403 - val_precision_1: 0.8582 - val_recall_1: 0.8582
Epoch 50/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3255 - accuracy: 0.8125 - precision_1: 0.7368 - recall_1: 0.9333
Epoch 50: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8550 - precision_1: 0.8400 - recall_1: 0.8909 - val_loss: 0.3524 - val_accuracy: 0.8361 - val_precision_1: 0.8519 - val_recall_1: 0.8582
Epoch 51/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3788 - accuracy: 0.8750 - precision_1: 0.8500 - recall_1: 0.9444
Epoch 51: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8561 - precision_1: 0.8390 - recall_1: 0.8949 - val_loss: 0.3529 - val_accuracy: 0.8403 - val_precision_1: 0.8582 - val_recall_1: 0.8582
Epoch 52/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1222 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 52: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8550 - precision_1: 0.8387 - recall_1: 0.8929 - val_loss: 0.3521 - val_accuracy: 0.8403 - val_precision_1: 0.8582 - val_recall_1: 0.8582
Epoch 53/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3408 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 53: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8540 - precision_1: 0.8410 - recall_1: 0.8869 - val_loss: 0.3505 - val_accuracy: 0.8361 - val_precision_1: 0.8519 - val_recall_1: 0.8582
Epoch 54/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2917 - accuracy: 0.8438 - precision_1: 0.8261 - recall_1: 0.9500
Epoch 54: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8561 - precision_1: 0.8416 - recall_1: 0.8909 - val_loss: 0.3486 - val_accuracy: 0.8319 - val_precision_1: 0.8456 - val_recall_1: 0.8582
Epoch 55/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2869 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 55: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8582 - precision_1: 0.8409 - recall_1: 0.8970 - val_loss: 0.3489 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 56/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1702 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9474
Epoch 56: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8582 - precision_1: 0.8422 - recall_1: 0.8949 - val_loss: 0.3485 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 57/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1741 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9474
Epoch 57: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8603 - precision_1: 0.8441 - recall_1: 0.8970 - val_loss: 0.3480 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 58/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3273 - accuracy: 0.8438 - precision_1: 0.8095 - recall_1: 0.9444
Epoch 58: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8624 - precision_1: 0.8473 - recall_1: 0.8970 - val_loss: 0.3483 - val_accuracy: 0.8361 - val_precision_1: 0.8571 - val_recall_1: 0.8507
Epoch 59/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3809 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 59: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8645 - precision_1: 0.8506 - recall_1: 0.8970 - val_loss: 0.3474 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 60/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1687 - accuracy: 0.9375 - precision_1: 0.8947 - recall_1: 1.0000
Epoch 60: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8624 - precision_1: 0.8500 - recall_1: 0.8929 - val_loss: 0.3461 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 61/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4627 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.8889
Epoch 61: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8624 - precision_1: 0.8473 - recall_1: 0.8970 - val_loss: 0.3465 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 62/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3211 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 62: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8634 - precision_1: 0.8503 - recall_1: 0.8949 - val_loss: 0.3455 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 63/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3330 - accuracy: 0.7812 - precision_1: 0.6000 - recall_1: 0.9000
Epoch 63: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8624 - precision_1: 0.8473 - recall_1: 0.8970 - val_loss: 0.3456 - val_accuracy: 0.8361 - val_precision_1: 0.8571 - val_recall_1: 0.8507
Epoch 64/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 64: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8624 - precision_1: 0.8473 - recall_1: 0.8970 - val_loss: 0.3445 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 65/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2891 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 65: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.8634 - precision_1: 0.8489 - recall_1: 0.8970 - val_loss: 0.3447 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 66/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3747 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 66: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8655 - precision_1: 0.8536 - recall_1: 0.8949 - val_loss: 0.3445 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 67/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3845 - accuracy: 0.8438 - precision_1: 0.8500 - recall_1: 0.8947
Epoch 67: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8634 - precision_1: 0.8489 - recall_1: 0.8970 - val_loss: 0.3445 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 68/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3758 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 68: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8655 - precision_1: 0.8509 - recall_1: 0.8990 - val_loss: 0.3447 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 69/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2562 - accuracy: 0.8750 - precision_1: 0.7692 - recall_1: 0.9091
Epoch 69: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8655 - precision_1: 0.8536 - recall_1: 0.8949 - val_loss: 0.3423 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 70/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3009 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 70: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.8666 - precision_1: 0.8525 - recall_1: 0.8990 - val_loss: 0.3412 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 71/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2386 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 1.0000
Epoch 71: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8645 - precision_1: 0.8492 - recall_1: 0.8990 - val_loss: 0.3410 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 72/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2377 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 72: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8666 - precision_1: 0.8525 - recall_1: 0.8990 - val_loss: 0.3398 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 73/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4430 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 73: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8676 - precision_1: 0.8528 - recall_1: 0.9010 - val_loss: 0.3407 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 74/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2105 - accuracy: 0.9062 - precision_1: 0.8182 - recall_1: 0.9000
Epoch 74: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8697 - precision_1: 0.8574 - recall_1: 0.8990 - val_loss: 0.3403 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 75/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3142 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 75: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8697 - precision_1: 0.8574 - recall_1: 0.8990 - val_loss: 0.3393 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 76/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2556 - accuracy: 0.9062 - precision_1: 0.8182 - recall_1: 0.9000
Epoch 76: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8687 - precision_1: 0.8531 - recall_1: 0.9030 - val_loss: 0.3401 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 77/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4274 - accuracy: 0.7500 - precision_1: 0.7619 - recall_1: 0.8421
Epoch 77: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8697 - precision_1: 0.8574 - recall_1: 0.8990 - val_loss: 0.3390 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 78/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6323 - accuracy: 0.6562 - precision_1: 0.7000 - recall_1: 0.7368
Epoch 78: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8666 - precision_1: 0.8511 - recall_1: 0.9010 - val_loss: 0.3381 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 79/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1589 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 79: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8687 - precision_1: 0.8544 - recall_1: 0.9010 - val_loss: 0.3380 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 80/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3796 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 80: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8655 - precision_1: 0.8522 - recall_1: 0.8970 - val_loss: 0.3366 - val_accuracy: 0.8361 - val_precision_1: 0.8571 - val_recall_1: 0.8507
Epoch 81/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4571 - accuracy: 0.7500 - precision_1: 0.7143 - recall_1: 0.7143
Epoch 81: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8697 - precision_1: 0.8533 - recall_1: 0.9051 - val_loss: 0.3377 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 82/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 82: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8645 - precision_1: 0.8533 - recall_1: 0.8929 - val_loss: 0.3375 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 83/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4544 - accuracy: 0.7500 - precision_1: 0.7273 - recall_1: 0.8889
Epoch 83: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8718 - precision_1: 0.8566 - recall_1: 0.9051 - val_loss: 0.3370 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 84/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3531 - accuracy: 0.8438 - precision_1: 0.6667 - recall_1: 1.0000
Epoch 84: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8676 - precision_1: 0.8583 - recall_1: 0.8929 - val_loss: 0.3356 - val_accuracy: 0.8361 - val_precision_1: 0.8571 - val_recall_1: 0.8507
Epoch 85/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4273 - accuracy: 0.8125 - precision_1: 0.8889 - recall_1: 0.8000
Epoch 85: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8655 - precision_1: 0.8522 - recall_1: 0.8970 - val_loss: 0.3359 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 86/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2459 - accuracy: 0.8750 - precision_1: 0.8000 - recall_1: 1.0000
Epoch 86: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8697 - precision_1: 0.8574 - recall_1: 0.8990 - val_loss: 0.3358 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 87/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1510 - accuracy: 0.9062 - precision_1: 0.8571 - recall_1: 1.0000
Epoch 87: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8676 - precision_1: 0.8583 - recall_1: 0.8929 - val_loss: 0.3342 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 88/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3979 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 88: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8687 - precision_1: 0.8571 - recall_1: 0.8970 - val_loss: 0.3347 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 89/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2087 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 0.9231
Epoch 89: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8666 - precision_1: 0.8552 - recall_1: 0.8949 - val_loss: 0.3335 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 90/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1787 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 90: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.8687 - precision_1: 0.8585 - recall_1: 0.8949 - val_loss: 0.3330 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 91/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2890 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 91: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8676 - precision_1: 0.8569 - recall_1: 0.8949 - val_loss: 0.3335 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 92/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3583 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 92: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8718 - precision_1: 0.8607 - recall_1: 0.8990 - val_loss: 0.3343 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 93/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2619 - accuracy: 0.8750 - precision_1: 0.9091 - recall_1: 0.9091
Epoch 93: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8687 - precision_1: 0.8585 - recall_1: 0.8949 - val_loss: 0.3331 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 94/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3323 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 94: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8718 - precision_1: 0.8580 - recall_1: 0.9030 - val_loss: 0.3340 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 95/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3492 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 95: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8687 - precision_1: 0.8585 - recall_1: 0.8949 - val_loss: 0.3328 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 96/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2802 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 96: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8708 - precision_1: 0.8591 - recall_1: 0.8990 - val_loss: 0.3338 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 97/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3685 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 97: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8708 - precision_1: 0.8591 - recall_1: 0.8990 - val_loss: 0.3336 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 98/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2541 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 98: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8729 - precision_1: 0.8624 - recall_1: 0.8990 - val_loss: 0.3328 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 99/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3708 - accuracy: 0.8750 - precision_1: 0.8261 - recall_1: 1.0000
Epoch 99: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8739 - precision_1: 0.8655 - recall_1: 0.8970 - val_loss: 0.3316 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 100/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3340 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 100: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8697 - precision_1: 0.8574 - recall_1: 0.8990 - val_loss: 0.3316 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 101/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2111 - accuracy: 0.9062 - precision_1: 0.9000 - recall_1: 0.9474
Epoch 101: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8771 - precision_1: 0.8691 - recall_1: 0.8990 - val_loss: 0.3310 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 102/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3093 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 102: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8697 - precision_1: 0.8588 - recall_1: 0.8970 - val_loss: 0.3311 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 103/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4392 - accuracy: 0.8125 - precision_1: 0.8095 - recall_1: 0.8947
Epoch 103: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8771 - precision_1: 0.8691 - recall_1: 0.8990 - val_loss: 0.3315 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 104/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3943 - accuracy: 0.8125 - precision_1: 0.8750 - recall_1: 0.7778
Epoch 104: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8739 - precision_1: 0.8641 - recall_1: 0.8990 - val_loss: 0.3329 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 105/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1779 - accuracy: 0.9688 - precision_1: 0.9474 - recall_1: 1.0000
Epoch 105: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2950 - accuracy: 0.8771 - precision_1: 0.8691 - recall_1: 0.8990 - val_loss: 0.3318 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 106/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2924 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 106: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8782 - precision_1: 0.8708 - recall_1: 0.8990 - val_loss: 0.3311 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 107/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3472 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 107: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8739 - precision_1: 0.8655 - recall_1: 0.8970 - val_loss: 0.3317 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 108/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4828 - accuracy: 0.7500 - precision_1: 0.7826 - recall_1: 0.8571
Epoch 108: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8803 - precision_1: 0.8757 - recall_1: 0.8970 - val_loss: 0.3307 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 109/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 109: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8792 - precision_1: 0.8682 - recall_1: 0.9051 - val_loss: 0.3320 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 110/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4985 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 110: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8813 - precision_1: 0.8760 - recall_1: 0.8990 - val_loss: 0.3311 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 111/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3951 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 111: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8782 - precision_1: 0.8723 - recall_1: 0.8970 - val_loss: 0.3296 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 112/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2126 - accuracy: 0.9375 - precision_1: 0.9286 - recall_1: 0.9286
Epoch 112: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8771 - precision_1: 0.8706 - recall_1: 0.8970 - val_loss: 0.3300 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 113/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3164 - accuracy: 0.9375 - precision_1: 0.9130 - recall_1: 1.0000
Epoch 113: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8803 - precision_1: 0.8757 - recall_1: 0.8970 - val_loss: 0.3297 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 114/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2856 - accuracy: 0.9062 - precision_1: 0.9474 - recall_1: 0.9000
Epoch 114: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8803 - precision_1: 0.8713 - recall_1: 0.9030 - val_loss: 0.3317 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 115/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2261 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 0.9231
Epoch 115: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8824 - precision_1: 0.8807 - recall_1: 0.8949 - val_loss: 0.3312 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 116/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2424 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9091
Epoch 116: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8750 - precision_1: 0.8686 - recall_1: 0.8949 - val_loss: 0.3312 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 117/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4646 - accuracy: 0.8125 - precision_1: 0.7333 - recall_1: 0.8462
Epoch 117: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8824 - precision_1: 0.8748 - recall_1: 0.9030 - val_loss: 0.3321 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 118/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4936 - accuracy: 0.7188 - precision_1: 0.8333 - recall_1: 0.7143
Epoch 118: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2903 - accuracy: 0.8792 - precision_1: 0.8740 - recall_1: 0.8970 - val_loss: 0.3322 - val_accuracy: 0.8403 - val_precision_1: 0.8810 - val_recall_1: 0.8284
Epoch 119/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3096 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8125
Epoch 119: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.8813 - precision_1: 0.8790 - recall_1: 0.8949 - val_loss: 0.3303 - val_accuracy: 0.8487 - val_precision_1: 0.8828 - val_recall_1: 0.8433
Epoch 120/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5150 - accuracy: 0.7500 - precision_1: 0.8235 - recall_1: 0.7368
Epoch 120: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8834 - precision_1: 0.8825 - recall_1: 0.8949 - val_loss: 0.3293 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 121/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3115 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 121: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8845 - precision_1: 0.8797 - recall_1: 0.9010 - val_loss: 0.3298 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 122/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2183 - accuracy: 0.8750 - precision_1: 0.8947 - recall_1: 0.8947
Epoch 122: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8782 - precision_1: 0.8752 - recall_1: 0.8929 - val_loss: 0.3292 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 123/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1782 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9000
Epoch 123: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.8813 - precision_1: 0.8745 - recall_1: 0.9010 - val_loss: 0.3312 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 124/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3247 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 124: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.8813 - precision_1: 0.8775 - recall_1: 0.8970 - val_loss: 0.3308 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 125/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5146 - accuracy: 0.8125 - precision_1: 0.8095 - recall_1: 0.8947
Epoch 125: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8813 - precision_1: 0.8790 - recall_1: 0.8949 - val_loss: 0.3291 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 126/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2093 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 126: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8824 - precision_1: 0.8777 - recall_1: 0.8990 - val_loss: 0.3288 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 127/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2330 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 127: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8771 - precision_1: 0.8720 - recall_1: 0.8949 - val_loss: 0.3281 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 128/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2484 - accuracy: 0.8750 - precision_1: 0.7500 - recall_1: 0.9000
Epoch 128: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.8803 - precision_1: 0.8743 - recall_1: 0.8990 - val_loss: 0.3288 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 129/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2773 - accuracy: 0.9062 - precision_1: 0.9500 - recall_1: 0.9048
Epoch 129: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8771 - precision_1: 0.8720 - recall_1: 0.8949 - val_loss: 0.3286 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 130/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3901 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 130: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.8782 - precision_1: 0.8752 - recall_1: 0.8929 - val_loss: 0.3281 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 131/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2515 - accuracy: 0.9062 - precision_1: 0.8889 - recall_1: 0.9412
Epoch 131: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8803 - precision_1: 0.8728 - recall_1: 0.9010 - val_loss: 0.3289 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 132/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2278 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9286
Epoch 132: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.8782 - precision_1: 0.8723 - recall_1: 0.8970 - val_loss: 0.3308 - val_accuracy: 0.8487 - val_precision_1: 0.8828 - val_recall_1: 0.8433
Epoch 133/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1670 - accuracy: 0.9375 - precision_1: 0.9412 - recall_1: 0.9412
Epoch 133: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8813 - precision_1: 0.8790 - recall_1: 0.8949 - val_loss: 0.3302 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 134/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4105 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 134: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8824 - precision_1: 0.8807 - recall_1: 0.8949 - val_loss: 0.3293 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 135/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1942 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9474
Epoch 135: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8761 - precision_1: 0.8689 - recall_1: 0.8970 - val_loss: 0.3298 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 136/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2585 - accuracy: 0.8750 - precision_1: 0.8696 - recall_1: 0.9524
Epoch 136: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8782 - precision_1: 0.8738 - recall_1: 0.8949 - val_loss: 0.3300 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 137/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2108 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9444
Epoch 137: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8803 - precision_1: 0.8787 - recall_1: 0.8929 - val_loss: 0.3292 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 138/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4588 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 138: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8792 - precision_1: 0.8755 - recall_1: 0.8949 - val_loss: 0.3282 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 139/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2528 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 139: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8834 - precision_1: 0.8794 - recall_1: 0.8990 - val_loss: 0.3291 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 140/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2826 - accuracy: 0.9062 - precision_1: 0.9545 - recall_1: 0.9130
Epoch 140: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8803 - precision_1: 0.8757 - recall_1: 0.8970 - val_loss: 0.3297 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 141/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1263 - accuracy: 0.9688 - precision_1: 0.9412 - recall_1: 1.0000
Epoch 141: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8824 - precision_1: 0.8822 - recall_1: 0.8929 - val_loss: 0.3281 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 142/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2724 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 142: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8771 - precision_1: 0.8720 - recall_1: 0.8949 - val_loss: 0.3292 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 143/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2355 - accuracy: 0.8750 - precision_1: 0.9048 - recall_1: 0.9048
Epoch 143: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8824 - precision_1: 0.8807 - recall_1: 0.8949 - val_loss: 0.3288 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 144/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2390 - accuracy: 0.8750 - precision_1: 0.7857 - recall_1: 0.9167
Epoch 144: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.8845 - precision_1: 0.8827 - recall_1: 0.8970 - val_loss: 0.3274 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 145/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2653 - accuracy: 0.9062 - precision_1: 0.8500 - recall_1: 1.0000
Epoch 145: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2836 - accuracy: 0.8813 - precision_1: 0.8745 - recall_1: 0.9010 - val_loss: 0.3293 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 146/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2877 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 146: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8834 - precision_1: 0.8825 - recall_1: 0.8949 - val_loss: 0.3291 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 147/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2896 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 147: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.8813 - precision_1: 0.8805 - recall_1: 0.8929 - val_loss: 0.3279 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 148/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3207 - accuracy: 0.9062 - precision_1: 0.9231 - recall_1: 0.8571
Epoch 148: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.8792 - precision_1: 0.8770 - recall_1: 0.8929 - val_loss: 0.3286 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 149/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3486 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 149: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8813 - precision_1: 0.8805 - recall_1: 0.8929 - val_loss: 0.3269 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 150/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2637 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 150: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8845 - precision_1: 0.8812 - recall_1: 0.8990 - val_loss: 0.3284 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 151/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3366 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 151: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.8824 - precision_1: 0.8792 - recall_1: 0.8970 - val_loss: 0.3276 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 152/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1141 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9375
Epoch 152: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8834 - precision_1: 0.8825 - recall_1: 0.8949 - val_loss: 0.3272 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 153/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1771 - accuracy: 0.9375 - precision_1: 0.8667 - recall_1: 1.0000
Epoch 153: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8834 - precision_1: 0.8810 - recall_1: 0.8970 - val_loss: 0.3278 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 154/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2734 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.9474
Epoch 154: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8834 - precision_1: 0.8810 - recall_1: 0.8970 - val_loss: 0.3264 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 155/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1791 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9375
Epoch 155: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8824 - precision_1: 0.8792 - recall_1: 0.8970 - val_loss: 0.3272 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 156/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1765 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 156: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8834 - precision_1: 0.8810 - recall_1: 0.8970 - val_loss: 0.3274 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 157/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2657 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8333
Epoch 157: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8845 - precision_1: 0.8812 - recall_1: 0.8990 - val_loss: 0.3280 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 158/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3629 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 158: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8824 - precision_1: 0.8792 - recall_1: 0.8970 - val_loss: 0.3285 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 159/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4032 - accuracy: 0.7812 - precision_1: 0.6667 - recall_1: 0.8333
Epoch 159: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8855 - precision_1: 0.8829 - recall_1: 0.8990 - val_loss: 0.3291 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 160/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1954 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 160: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8845 - precision_1: 0.8842 - recall_1: 0.8949 - val_loss: 0.3281 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 161/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2709 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 161: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8876 - precision_1: 0.8880 - recall_1: 0.8970 - val_loss: 0.3282 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 162/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3046 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 162: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8876 - precision_1: 0.8880 - recall_1: 0.8970 - val_loss: 0.3277 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 163/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2554 - accuracy: 0.9375 - precision_1: 0.9375 - recall_1: 0.9375
Epoch 163: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8866 - precision_1: 0.8862 - recall_1: 0.8970 - val_loss: 0.3283 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 164/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1590 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9375
Epoch 164: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8866 - precision_1: 0.8862 - recall_1: 0.8970 - val_loss: 0.3276 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 165/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2913 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 165: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8866 - precision_1: 0.8878 - recall_1: 0.8949 - val_loss: 0.3278 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 166/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3707 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.9375
Epoch 166: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8855 - precision_1: 0.8860 - recall_1: 0.8949 - val_loss: 0.3273 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 167/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1544 - accuracy: 0.9688 - precision_1: 0.9500 - recall_1: 1.0000
Epoch 167: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8855 - precision_1: 0.8845 - recall_1: 0.8970 - val_loss: 0.3283 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 168/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1982 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 168: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8866 - precision_1: 0.8862 - recall_1: 0.8970 - val_loss: 0.3278 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 169/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3981 - accuracy: 0.7500 - precision_1: 0.7000 - recall_1: 0.8750
Epoch 169: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8866 - precision_1: 0.8862 - recall_1: 0.8970 - val_loss: 0.3298 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 170/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1937 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 170: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8897 - precision_1: 0.8931 - recall_1: 0.8949 - val_loss: 0.3282 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 171/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5109 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.8421
Epoch 171: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8866 - precision_1: 0.8862 - recall_1: 0.8970 - val_loss: 0.3270 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 172/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1866 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9375
Epoch 172: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8876 - precision_1: 0.8880 - recall_1: 0.8970 - val_loss: 0.3281 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 173/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6147 - accuracy: 0.7812 - precision_1: 0.5833 - recall_1: 0.7778
Epoch 173: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8887 - precision_1: 0.8913 - recall_1: 0.8949 - val_loss: 0.3284 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 174/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2524 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 174: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8887 - precision_1: 0.8913 - recall_1: 0.8949 - val_loss: 0.3273 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 174: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Model-8x1">Model 8x1<a class="anchor-link" href="#Model-8x1">¶</a></h2><ul>
<li>val_accuracy: 0.8193</li>
<li>val_loss: 0.3666</li>
<li>val_precision: 0.8346</li>
<li>val_recall: 0.8409</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [99]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">eightx1_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"8x1_model"</span><span class="p">)</span>
<span class="n">eightx1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">eightx1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">eightx1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">eightx1_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">eightx1_history</span> <span class="o">=</span> <span class="n">eightx1_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
 1/30 [&gt;.............................] - ETA: 14s - loss: 0.9400 - accuracy: 0.4062 - precision_1: 0.8456 - recall_1: 0.7718
Epoch 1: val_loss did not improve from 0.29000
30/30 [==============================] - 1s 10ms/step - loss: 0.8114 - accuracy: 0.4643 - precision_1: 0.6844 - recall_1: 0.2448 - val_loss: 0.7879 - val_accuracy: 0.4790 - val_precision_1: 0.6471 - val_recall_1: 0.1642
Epoch 2/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6934 - accuracy: 0.5938 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00
Epoch 2: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.7202 - accuracy: 0.5242 - precision_1: 0.6296 - recall_1: 0.2061 - val_loss: 0.7047 - val_accuracy: 0.5714 - val_precision_1: 0.8077 - val_recall_1: 0.3134
Epoch 3/256
30/30 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.6345 - precision_1: 0.7905 - recall_1: 0.4040
Epoch 3: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.6345 - precision_1: 0.7905 - recall_1: 0.4040 - val_loss: 0.6348 - val_accuracy: 0.6807 - val_precision_1: 0.8919 - val_recall_1: 0.4925
Epoch 4/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5859 - accuracy: 0.6875 - precision_1: 0.9231 - recall_1: 0.5714
Epoch 4: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7048 - precision_1: 0.8323 - recall_1: 0.5414 - val_loss: 0.5782 - val_accuracy: 0.7437 - val_precision_1: 0.9011 - val_recall_1: 0.6119
Epoch 5/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5364 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 5: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7584 - precision_1: 0.8496 - recall_1: 0.6505 - val_loss: 0.5309 - val_accuracy: 0.7857 - val_precision_1: 0.9192 - val_recall_1: 0.6791
Epoch 6/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5927 - accuracy: 0.7188 - precision_1: 0.8571 - recall_1: 0.6316
Epoch 6: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7899 - precision_1: 0.8520 - recall_1: 0.7212 - val_loss: 0.4929 - val_accuracy: 0.7983 - val_precision_1: 0.9057 - val_recall_1: 0.7164
Epoch 7/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4513 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 7: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8130 - precision_1: 0.8594 - recall_1: 0.7657 - val_loss: 0.4626 - val_accuracy: 0.8193 - val_precision_1: 0.9099 - val_recall_1: 0.7537
Epoch 8/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3822 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8235
Epoch 8: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8277 - precision_1: 0.8621 - recall_1: 0.7960 - val_loss: 0.4404 - val_accuracy: 0.8193 - val_precision_1: 0.8889 - val_recall_1: 0.7761
Epoch 9/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4140 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.7500
Epoch 9: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8288 - precision_1: 0.8578 - recall_1: 0.8040 - val_loss: 0.4224 - val_accuracy: 0.8235 - val_precision_1: 0.8898 - val_recall_1: 0.7836
Epoch 10/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4170 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 10: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8319 - precision_1: 0.8587 - recall_1: 0.8101 - val_loss: 0.4086 - val_accuracy: 0.8235 - val_precision_1: 0.8833 - val_recall_1: 0.7910
Epoch 11/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4602 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 11: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8361 - precision_1: 0.8568 - recall_1: 0.8222 - val_loss: 0.3983 - val_accuracy: 0.8277 - val_precision_1: 0.8843 - val_recall_1: 0.7985
Epoch 12/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4146 - accuracy: 0.8125 - precision_1: 0.8667 - recall_1: 0.7647
Epoch 12: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8361 - precision_1: 0.8539 - recall_1: 0.8263 - val_loss: 0.3907 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 13/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3483 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8750
Epoch 13: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8372 - precision_1: 0.8542 - recall_1: 0.8283 - val_loss: 0.3849 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 14/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3246 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 14: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8414 - precision_1: 0.8539 - recall_1: 0.8384 - val_loss: 0.3806 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 15/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3758 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 15: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8424 - precision_1: 0.8542 - recall_1: 0.8404 - val_loss: 0.3773 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 16/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5357 - accuracy: 0.7188 - precision_1: 0.7000 - recall_1: 0.8235
Epoch 16: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8424 - precision_1: 0.8542 - recall_1: 0.8404 - val_loss: 0.3742 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 17/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4701 - accuracy: 0.7500 - precision_1: 0.8333 - recall_1: 0.6250
Epoch 17: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8435 - precision_1: 0.8531 - recall_1: 0.8444 - val_loss: 0.3720 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 18/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2862 - accuracy: 0.9062 - precision_1: 0.9286 - recall_1: 0.8667
Epoch 18: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8435 - precision_1: 0.8531 - recall_1: 0.8444 - val_loss: 0.3699 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 19/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3479 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 19: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8456 - precision_1: 0.8508 - recall_1: 0.8525 - val_loss: 0.3688 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 20/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3178 - accuracy: 0.9062 - precision_1: 0.8696 - recall_1: 1.0000
Epoch 20: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8424 - precision_1: 0.8485 - recall_1: 0.8485 - val_loss: 0.3673 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 21/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3591 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 21: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8456 - precision_1: 0.8522 - recall_1: 0.8505 - val_loss: 0.3658 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 22/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5493 - accuracy: 0.6875 - precision_1: 0.6429 - recall_1: 0.6429
Epoch 22: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8435 - precision_1: 0.8488 - recall_1: 0.8505 - val_loss: 0.3647 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 23/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2805 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8125
Epoch 23: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8403 - precision_1: 0.8437 - recall_1: 0.8505 - val_loss: 0.3640 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 24/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4269 - accuracy: 0.7812 - precision_1: 0.7895 - recall_1: 0.8333
Epoch 24: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8424 - precision_1: 0.8457 - recall_1: 0.8525 - val_loss: 0.3628 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 25/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3520 - accuracy: 0.8438 - precision_1: 0.7500 - recall_1: 0.9231
Epoch 25: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8435 - precision_1: 0.8460 - recall_1: 0.8545 - val_loss: 0.3619 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 26/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3440 - accuracy: 0.9062 - precision_1: 0.8571 - recall_1: 0.9231
Epoch 26: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8424 - precision_1: 0.8457 - recall_1: 0.8525 - val_loss: 0.3614 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 27/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4564 - accuracy: 0.8438 - precision_1: 0.9000 - recall_1: 0.8571
Epoch 27: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8435 - precision_1: 0.8460 - recall_1: 0.8545 - val_loss: 0.3608 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 28/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5098 - accuracy: 0.7500 - precision_1: 0.8333 - recall_1: 0.6250
Epoch 28: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8435 - precision_1: 0.8460 - recall_1: 0.8545 - val_loss: 0.3602 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 29/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3113 - accuracy: 0.8438 - precision_1: 0.9375 - recall_1: 0.7895
Epoch 29: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8435 - precision_1: 0.8460 - recall_1: 0.8545 - val_loss: 0.3592 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 30/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4480 - accuracy: 0.7500 - precision_1: 0.7692 - recall_1: 0.6667
Epoch 30: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8456 - precision_1: 0.8480 - recall_1: 0.8566 - val_loss: 0.3589 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 31/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2093 - accuracy: 0.9062 - precision_1: 0.8333 - recall_1: 1.0000
Epoch 31: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8456 - precision_1: 0.8508 - recall_1: 0.8525 - val_loss: 0.3577 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 32/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2174 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9048
Epoch 32: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8435 - precision_1: 0.8460 - recall_1: 0.8545 - val_loss: 0.3574 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 33/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3435 - accuracy: 0.9375 - precision_1: 0.9000 - recall_1: 1.0000
Epoch 33: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8445 - precision_1: 0.8477 - recall_1: 0.8545 - val_loss: 0.3568 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 34/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3432 - accuracy: 0.8125 - precision_1: 0.8095 - recall_1: 0.8947
Epoch 34: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8487 - precision_1: 0.8517 - recall_1: 0.8586 - val_loss: 0.3563 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 35/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5756 - accuracy: 0.7500 - precision_1: 0.8750 - recall_1: 0.7000
Epoch 35: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8456 - precision_1: 0.8466 - recall_1: 0.8586 - val_loss: 0.3559 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 36/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5146 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 36: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8487 - precision_1: 0.8531 - recall_1: 0.8566 - val_loss: 0.3553 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 37/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3982 - accuracy: 0.8438 - precision_1: 0.9286 - recall_1: 0.7647
Epoch 37: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8498 - precision_1: 0.8520 - recall_1: 0.8606 - val_loss: 0.3550 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 38/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3696 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 38: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8508 - precision_1: 0.8551 - recall_1: 0.8586 - val_loss: 0.3546 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 39/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4529 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 39: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8508 - precision_1: 0.8566 - recall_1: 0.8566 - val_loss: 0.3538 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 40/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3892 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7059
Epoch 40: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8519 - precision_1: 0.8554 - recall_1: 0.8606 - val_loss: 0.3537 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 41/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2567 - accuracy: 0.9375 - precision_1: 0.9286 - recall_1: 0.9286
Epoch 41: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8519 - precision_1: 0.8583 - recall_1: 0.8566 - val_loss: 0.3527 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 42/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 42: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8540 - precision_1: 0.8589 - recall_1: 0.8606 - val_loss: 0.3521 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 43/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4320 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 43: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8519 - precision_1: 0.8569 - recall_1: 0.8586 - val_loss: 0.3515 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 44/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3531 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 44: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8550 - precision_1: 0.8606 - recall_1: 0.8606 - val_loss: 0.3510 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 45/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4950 - accuracy: 0.7188 - precision_1: 0.6000 - recall_1: 0.7500
Epoch 45: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8529 - precision_1: 0.8600 - recall_1: 0.8566 - val_loss: 0.3508 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 46/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4217 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 46: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8550 - precision_1: 0.8577 - recall_1: 0.8646 - val_loss: 0.3504 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 47/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2489 - accuracy: 0.9375 - precision_1: 0.9375 - recall_1: 0.9375
Epoch 47: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8582 - precision_1: 0.8629 - recall_1: 0.8646 - val_loss: 0.3496 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 48/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2633 - accuracy: 0.9062 - precision_1: 0.9500 - recall_1: 0.9048
Epoch 48: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8592 - precision_1: 0.8617 - recall_1: 0.8687 - val_loss: 0.3490 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 49/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3741 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 49: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8571 - precision_1: 0.8597 - recall_1: 0.8667 - val_loss: 0.3487 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 50/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3318 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 50: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8603 - precision_1: 0.8649 - recall_1: 0.8667 - val_loss: 0.3481 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 51/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2476 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8667
Epoch 51: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8571 - precision_1: 0.8597 - recall_1: 0.8667 - val_loss: 0.3483 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 52/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3874 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 52: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8592 - precision_1: 0.8617 - recall_1: 0.8687 - val_loss: 0.3479 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 53/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3012 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 53: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8582 - precision_1: 0.8600 - recall_1: 0.8687 - val_loss: 0.3478 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 54/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4602 - accuracy: 0.7812 - precision_1: 0.8750 - recall_1: 0.7368
Epoch 54: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8592 - precision_1: 0.8603 - recall_1: 0.8707 - val_loss: 0.3483 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 55/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4516 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 55: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8592 - precision_1: 0.8617 - recall_1: 0.8687 - val_loss: 0.3474 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 56/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3279 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 56: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8571 - precision_1: 0.8597 - recall_1: 0.8667 - val_loss: 0.3469 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 57/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1604 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 57: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3466 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 58/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1995 - accuracy: 0.9062 - precision_1: 0.8462 - recall_1: 0.9167
Epoch 58: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8592 - precision_1: 0.8603 - recall_1: 0.8707 - val_loss: 0.3468 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 59/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1639 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 59: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8603 - precision_1: 0.8606 - recall_1: 0.8727 - val_loss: 0.3461 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 60/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 60: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8592 - precision_1: 0.8603 - recall_1: 0.8707 - val_loss: 0.3460 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 61/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3666 - accuracy: 0.8438 - precision_1: 0.6667 - recall_1: 1.0000
Epoch 61: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8634 - precision_1: 0.8643 - recall_1: 0.8747 - val_loss: 0.3456 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 62/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4919 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.6667
Epoch 62: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3457 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 63/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4082 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 63: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3448 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 64/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3162 - accuracy: 0.8750 - precision_1: 0.9474 - recall_1: 0.8571
Epoch 64: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8603 - precision_1: 0.8591 - recall_1: 0.8747 - val_loss: 0.3454 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 65/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3224 - accuracy: 0.8438 - precision_1: 0.7500 - recall_1: 0.9231
Epoch 65: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8603 - precision_1: 0.8591 - recall_1: 0.8747 - val_loss: 0.3444 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 66/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3195 - accuracy: 0.9062 - precision_1: 0.9091 - recall_1: 0.9524
Epoch 66: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8603 - precision_1: 0.8591 - recall_1: 0.8747 - val_loss: 0.3446 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 67/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2085 - accuracy: 0.9688 - precision_1: 0.9231 - recall_1: 1.0000
Epoch 67: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3441 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 68/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2959 - accuracy: 0.9062 - precision_1: 0.9500 - recall_1: 0.9048
Epoch 68: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3435 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 69/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2865 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 69: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3433 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 70/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2361 - accuracy: 0.9062 - precision_1: 0.9333 - recall_1: 0.8750
Epoch 70: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8613 - precision_1: 0.8594 - recall_1: 0.8768 - val_loss: 0.3433 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 71/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2598 - accuracy: 0.9062 - precision_1: 0.8235 - recall_1: 1.0000
Epoch 71: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8603 - precision_1: 0.8606 - recall_1: 0.8727 - val_loss: 0.3431 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 72/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4319 - accuracy: 0.8125 - precision_1: 0.7143 - recall_1: 0.8333
Epoch 72: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8613 - precision_1: 0.8623 - recall_1: 0.8727 - val_loss: 0.3427 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 73/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3485 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 73: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8613 - precision_1: 0.8623 - recall_1: 0.8727 - val_loss: 0.3424 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 74/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4325 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 74: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3425 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 75/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2448 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 75: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8624 - precision_1: 0.8611 - recall_1: 0.8768 - val_loss: 0.3428 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 76/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4033 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 76: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8603 - precision_1: 0.8620 - recall_1: 0.8707 - val_loss: 0.3432 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 77/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4054 - accuracy: 0.8125 - precision_1: 0.7273 - recall_1: 0.7273
Epoch 77: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3425 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 78/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2313 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 78: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8592 - precision_1: 0.8603 - recall_1: 0.8707 - val_loss: 0.3421 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 79/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3815 - accuracy: 0.8438 - precision_1: 0.9000 - recall_1: 0.6923
Epoch 79: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8603 - precision_1: 0.8591 - recall_1: 0.8747 - val_loss: 0.3421 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 80/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2605 - accuracy: 0.8438 - precision_1: 0.9444 - recall_1: 0.8095
Epoch 80: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8613 - precision_1: 0.8608 - recall_1: 0.8747 - val_loss: 0.3426 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 81/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4497 - accuracy: 0.8125 - precision_1: 0.8889 - recall_1: 0.6154
Epoch 81: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3423 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 82/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2549 - accuracy: 0.9062 - precision_1: 0.8500 - recall_1: 1.0000
Epoch 82: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8634 - precision_1: 0.8672 - recall_1: 0.8707 - val_loss: 0.3415 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 83/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3776 - accuracy: 0.8125 - precision_1: 0.8095 - recall_1: 0.8947
Epoch 83: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8645 - precision_1: 0.8690 - recall_1: 0.8707 - val_loss: 0.3412 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 84/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3435 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.7000
Epoch 84: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8645 - precision_1: 0.8690 - recall_1: 0.8707 - val_loss: 0.3407 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 85/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2115 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 85: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8645 - precision_1: 0.8690 - recall_1: 0.8707 - val_loss: 0.3403 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 86/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4516 - accuracy: 0.8125 - precision_1: 0.8750 - recall_1: 0.7778
Epoch 86: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8592 - precision_1: 0.8617 - recall_1: 0.8687 - val_loss: 0.3412 - val_accuracy: 0.8529 - val_precision_1: 0.8722 - val_recall_1: 0.8657
Epoch 87/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2716 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 87: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8624 - precision_1: 0.8669 - recall_1: 0.8687 - val_loss: 0.3409 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 88/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3431 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 88: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8624 - precision_1: 0.8669 - recall_1: 0.8687 - val_loss: 0.3406 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 89/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2312 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 89: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8613 - precision_1: 0.8652 - recall_1: 0.8687 - val_loss: 0.3397 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 90/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2739 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 90: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8624 - precision_1: 0.8669 - recall_1: 0.8687 - val_loss: 0.3396 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 91/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3740 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 91: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8624 - precision_1: 0.8669 - recall_1: 0.8687 - val_loss: 0.3396 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 92/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6941 - accuracy: 0.7188 - precision_1: 0.5714 - recall_1: 0.7273
Epoch 92: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8634 - precision_1: 0.8687 - recall_1: 0.8687 - val_loss: 0.3394 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 93/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2534 - accuracy: 0.9062 - precision_1: 0.9500 - recall_1: 0.9048
Epoch 93: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8634 - precision_1: 0.8687 - recall_1: 0.8687 - val_loss: 0.3389 - val_accuracy: 0.8487 - val_precision_1: 0.8657 - val_recall_1: 0.8657
Epoch 94/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4465 - accuracy: 0.7500 - precision_1: 0.6875 - recall_1: 0.7857
Epoch 94: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8613 - precision_1: 0.8652 - recall_1: 0.8687 - val_loss: 0.3390 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 95/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4106 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 95: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8624 - precision_1: 0.8669 - recall_1: 0.8687 - val_loss: 0.3397 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 96/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3891 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.9000
Epoch 96: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8634 - precision_1: 0.8687 - recall_1: 0.8687 - val_loss: 0.3390 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 97/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2236 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9091
Epoch 97: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8645 - precision_1: 0.8690 - recall_1: 0.8707 - val_loss: 0.3390 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 98/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3626 - accuracy: 0.8125 - precision_1: 0.7333 - recall_1: 0.8462
Epoch 98: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8645 - precision_1: 0.8704 - recall_1: 0.8687 - val_loss: 0.3390 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 99/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2479 - accuracy: 0.9062 - precision_1: 0.9000 - recall_1: 0.9474
Epoch 99: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8666 - precision_1: 0.8710 - recall_1: 0.8727 - val_loss: 0.3389 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 100/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2434 - accuracy: 0.8750 - precision_1: 0.9048 - recall_1: 0.9048
Epoch 100: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8666 - precision_1: 0.8710 - recall_1: 0.8727 - val_loss: 0.3386 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 101/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4705 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 101: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8655 - precision_1: 0.8692 - recall_1: 0.8727 - val_loss: 0.3394 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 102/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3008 - accuracy: 0.9062 - precision_1: 0.8571 - recall_1: 0.9231
Epoch 102: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8655 - precision_1: 0.8692 - recall_1: 0.8727 - val_loss: 0.3400 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 103/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2601 - accuracy: 0.8750 - precision_1: 0.9412 - recall_1: 0.8421
Epoch 103: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8655 - precision_1: 0.8707 - recall_1: 0.8707 - val_loss: 0.3392 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 104/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4727 - accuracy: 0.7812 - precision_1: 0.8421 - recall_1: 0.8000
Epoch 104: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8634 - precision_1: 0.8672 - recall_1: 0.8707 - val_loss: 0.3399 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 105/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4389 - accuracy: 0.8125 - precision_1: 0.8667 - recall_1: 0.7647
Epoch 105: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8666 - precision_1: 0.8710 - recall_1: 0.8727 - val_loss: 0.3395 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 106/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3255 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 106: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8666 - precision_1: 0.8710 - recall_1: 0.8727 - val_loss: 0.3388 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 107/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2594 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8125
Epoch 107: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8666 - precision_1: 0.8710 - recall_1: 0.8727 - val_loss: 0.3386 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 108/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2268 - accuracy: 0.9375 - precision_1: 0.8750 - recall_1: 1.0000
Epoch 108: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3394 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 109/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2876 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7895
Epoch 109: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3402 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 110/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2061 - accuracy: 0.9062 - precision_1: 0.8500 - recall_1: 1.0000
Epoch 110: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3397 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 111/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3985 - accuracy: 0.8750 - precision_1: 0.8696 - recall_1: 0.9524
Epoch 111: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8666 - precision_1: 0.8710 - recall_1: 0.8727 - val_loss: 0.3393 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 112/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3880 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 112: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8655 - precision_1: 0.8692 - recall_1: 0.8727 - val_loss: 0.3389 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 113/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4220 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 113: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8655 - precision_1: 0.8692 - recall_1: 0.8727 - val_loss: 0.3390 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 114/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4025 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 114: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3390 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 115/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2665 - accuracy: 0.9375 - precision_1: 0.9048 - recall_1: 1.0000
Epoch 115: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3387 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 116/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1864 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9524
Epoch 116: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3381 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 117/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5505 - accuracy: 0.8125 - precision_1: 0.7059 - recall_1: 0.9231
Epoch 117: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8624 - precision_1: 0.8640 - recall_1: 0.8727 - val_loss: 0.3379 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 118/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3756 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 118: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8613 - precision_1: 0.8623 - recall_1: 0.8727 - val_loss: 0.3389 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 119/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4138 - accuracy: 0.7812 - precision_1: 1.0000 - recall_1: 0.6500
Epoch 119: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3381 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 120/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2603 - accuracy: 0.8750 - precision_1: 0.9091 - recall_1: 0.7692
Epoch 120: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3377 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 121/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2904 - accuracy: 0.9062 - precision_1: 0.9333 - recall_1: 0.8750
Epoch 121: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8613 - precision_1: 0.8637 - recall_1: 0.8707 - val_loss: 0.3376 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 122/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2957 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 122: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3377 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 123/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1977 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 0.9231
Epoch 123: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3382 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 124/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3614 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 124: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8613 - precision_1: 0.8652 - recall_1: 0.8687 - val_loss: 0.3379 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 125/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2352 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 125: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8613 - precision_1: 0.8652 - recall_1: 0.8687 - val_loss: 0.3382 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 126/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2474 - accuracy: 0.8750 - precision_1: 0.9500 - recall_1: 0.8636
Epoch 126: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3382 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 127/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2565 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 127: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3377 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 128/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5652 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 128: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3378 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 129/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1983 - accuracy: 0.9688 - precision_1: 0.9286 - recall_1: 1.0000
Epoch 129: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3378 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 130/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5062 - accuracy: 0.8125 - precision_1: 0.8824 - recall_1: 0.7895
Epoch 130: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8613 - precision_1: 0.8623 - recall_1: 0.8727 - val_loss: 0.3388 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 131/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4739 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 131: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3383 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 132/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1570 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9474
Epoch 132: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8613 - precision_1: 0.8652 - recall_1: 0.8687 - val_loss: 0.3380 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 133/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3431 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 133: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3368 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 134/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3621 - accuracy: 0.7812 - precision_1: 0.8095 - recall_1: 0.8500
Epoch 134: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3368 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 135/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2387 - accuracy: 0.9375 - precision_1: 0.8947 - recall_1: 1.0000
Epoch 135: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8645 - precision_1: 0.8660 - recall_1: 0.8747 - val_loss: 0.3370 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 136/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3416 - accuracy: 0.8750 - precision_1: 0.7273 - recall_1: 0.8889
Epoch 136: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.8645 - precision_1: 0.8645 - recall_1: 0.8768 - val_loss: 0.3371 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 137/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4314 - accuracy: 0.8750 - precision_1: 0.8947 - recall_1: 0.8947
Epoch 137: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8645 - precision_1: 0.8660 - recall_1: 0.8747 - val_loss: 0.3372 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 138/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8750 - precision_1: 0.9167 - recall_1: 0.7857
Epoch 138: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8645 - precision_1: 0.8675 - recall_1: 0.8727 - val_loss: 0.3368 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 139/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2503 - accuracy: 0.9688 - precision_1: 0.9091 - recall_1: 1.0000
Epoch 139: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3370 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 140/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3640 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 140: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8655 - precision_1: 0.8663 - recall_1: 0.8768 - val_loss: 0.3372 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 141/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 141: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8645 - precision_1: 0.8660 - recall_1: 0.8747 - val_loss: 0.3369 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 142/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1560 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 142: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8676 - precision_1: 0.8683 - recall_1: 0.8788 - val_loss: 0.3364 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 143/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2847 - accuracy: 0.9062 - precision_1: 0.8462 - recall_1: 0.9167
Epoch 143: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8655 - precision_1: 0.8648 - recall_1: 0.8788 - val_loss: 0.3367 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 144/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2361 - accuracy: 0.8438 - precision_1: 0.9375 - recall_1: 0.7895
Epoch 144: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8666 - precision_1: 0.8665 - recall_1: 0.8788 - val_loss: 0.3372 - val_accuracy: 0.8445 - val_precision_1: 0.8647 - val_recall_1: 0.8582
Epoch 145/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4010 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 145: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8676 - precision_1: 0.8683 - recall_1: 0.8788 - val_loss: 0.3378 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 146/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 146: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8666 - precision_1: 0.8651 - recall_1: 0.8808 - val_loss: 0.3378 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 147/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 147: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3386 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 148/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 148: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8666 - precision_1: 0.8680 - recall_1: 0.8768 - val_loss: 0.3389 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 149/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2938 - accuracy: 0.9375 - precision_1: 0.9375 - recall_1: 0.9375
Epoch 149: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8645 - precision_1: 0.8690 - recall_1: 0.8707 - val_loss: 0.3381 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 150/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3089 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 150: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8645 - precision_1: 0.8675 - recall_1: 0.8727 - val_loss: 0.3374 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 151/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4671 - accuracy: 0.8125 - precision_1: 0.8500 - recall_1: 0.8500
Epoch 151: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8666 - precision_1: 0.8680 - recall_1: 0.8768 - val_loss: 0.3375 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 152/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2892 - accuracy: 0.8438 - precision_1: 0.7500 - recall_1: 0.9231
Epoch 152: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8655 - precision_1: 0.8677 - recall_1: 0.8747 - val_loss: 0.3371 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 153/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3200 - accuracy: 0.9062 - precision_1: 0.8421 - recall_1: 1.0000
Epoch 153: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8666 - precision_1: 0.8695 - recall_1: 0.8747 - val_loss: 0.3373 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 154/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2589 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 154: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8655 - precision_1: 0.8677 - recall_1: 0.8747 - val_loss: 0.3375 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 155/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1658 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9231
Epoch 155: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8666 - precision_1: 0.8680 - recall_1: 0.8768 - val_loss: 0.3381 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 156/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3855 - accuracy: 0.9062 - precision_1: 0.9000 - recall_1: 0.8182
Epoch 156: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8697 - precision_1: 0.8732 - recall_1: 0.8768 - val_loss: 0.3377 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 157/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1469 - accuracy: 0.9375 - precision_1: 0.9333 - recall_1: 0.9333
Epoch 157: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8666 - precision_1: 0.8680 - recall_1: 0.8768 - val_loss: 0.3377 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 158/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2317 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.9545
Epoch 158: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8687 - precision_1: 0.8715 - recall_1: 0.8768 - val_loss: 0.3381 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 159/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2092 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8667
Epoch 159: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8697 - precision_1: 0.8717 - recall_1: 0.8788 - val_loss: 0.3378 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 160/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2876 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 160: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8676 - precision_1: 0.8697 - recall_1: 0.8768 - val_loss: 0.3378 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 161/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2307 - accuracy: 0.9062 - precision_1: 0.8571 - recall_1: 0.9231
Epoch 161: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8687 - precision_1: 0.8715 - recall_1: 0.8768 - val_loss: 0.3379 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 162/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1600 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9231
Epoch 162: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8687 - precision_1: 0.8715 - recall_1: 0.8768 - val_loss: 0.3380 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 162: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Model-4x1">Model 4x1<a class="anchor-link" href="#Model-4x1">¶</a></h2><ul>
<li>val_accuracy: 0.8361</li>
<li>val_loss: 0.4390</li>
<li>val_precision: 0.8298</li>
<li>val_recall: 0.8864</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [100]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">fourx1_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"4x1_model"</span><span class="p">)</span>
<span class="n">fourx1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">fourx1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">fourx1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">fourx1_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">fourx1_history</span> <span class="o">=</span> <span class="n">fourx1_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
 1/30 [&gt;.............................] - ETA: 14s - loss: 0.5657 - accuracy: 0.6250 - precision_1: 0.8675 - recall_1: 0.8344
Epoch 1: val_loss did not improve from 0.29000
30/30 [==============================] - 1s 9ms/step - loss: 0.6140 - accuracy: 0.6817 - precision_1: 0.6936 - recall_1: 0.8315 - val_loss: 0.6035 - val_accuracy: 0.7185 - val_precision_1: 0.7219 - val_recall_1: 0.8134
Epoch 2/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6263 - accuracy: 0.6875 - precision_1: 0.6190 - recall_1: 0.8667
Epoch 2: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7321 - precision_1: 0.7055 - recall_1: 0.8323 - val_loss: 0.5701 - val_accuracy: 0.7479 - val_precision_1: 0.7606 - val_recall_1: 0.8060
Epoch 3/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5365 - accuracy: 0.7812 - precision_1: 0.7619 - recall_1: 0.8889
Epoch 3: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7500 - precision_1: 0.7282 - recall_1: 0.8283 - val_loss: 0.5436 - val_accuracy: 0.7647 - val_precision_1: 0.7868 - val_recall_1: 0.7985
Epoch 4/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6385 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.8421
Epoch 4: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7700 - precision_1: 0.7546 - recall_1: 0.8263 - val_loss: 0.5215 - val_accuracy: 0.7731 - val_precision_1: 0.7985 - val_recall_1: 0.7985
Epoch 5/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5560 - accuracy: 0.7500 - precision_1: 0.7059 - recall_1: 0.8000
Epoch 5: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7773 - precision_1: 0.7675 - recall_1: 0.8202 - val_loss: 0.5031 - val_accuracy: 0.7773 - val_precision_1: 0.8092 - val_recall_1: 0.7910
Epoch 6/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4967 - accuracy: 0.8125 - precision_1: 0.7692 - recall_1: 0.7692
Epoch 6: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7889 - precision_1: 0.7860 - recall_1: 0.8162 - val_loss: 0.4871 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 7/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5441 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 7: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7931 - precision_1: 0.7956 - recall_1: 0.8101 - val_loss: 0.4737 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 8/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3505 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 8: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7994 - precision_1: 0.8052 - recall_1: 0.8101 - val_loss: 0.4620 - val_accuracy: 0.8109 - val_precision_1: 0.8560 - val_recall_1: 0.7985
Epoch 9/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3766 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 9: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8067 - precision_1: 0.8129 - recall_1: 0.8162 - val_loss: 0.4522 - val_accuracy: 0.8109 - val_precision_1: 0.8560 - val_recall_1: 0.7985
Epoch 10/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2997 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.8000
Epoch 10: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8162 - precision_1: 0.8213 - recall_1: 0.8263 - val_loss: 0.4431 - val_accuracy: 0.8109 - val_precision_1: 0.8560 - val_recall_1: 0.7985
Epoch 11/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7755 - accuracy: 0.5938 - precision_1: 0.5263 - recall_1: 0.7143
Epoch 11: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.8214 - precision_1: 0.8283 - recall_1: 0.8283 - val_loss: 0.4349 - val_accuracy: 0.8109 - val_precision_1: 0.8560 - val_recall_1: 0.7985
Epoch 12/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5984 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.8333
Epoch 12: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8193 - precision_1: 0.8289 - recall_1: 0.8222 - val_loss: 0.4269 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 13/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4584 - accuracy: 0.7812 - precision_1: 0.7333 - recall_1: 0.7857
Epoch 13: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8225 - precision_1: 0.8300 - recall_1: 0.8283 - val_loss: 0.4199 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 14/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3734 - accuracy: 0.8438 - precision_1: 0.9091 - recall_1: 0.8696
Epoch 14: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8235 - precision_1: 0.8303 - recall_1: 0.8303 - val_loss: 0.4142 - val_accuracy: 0.8109 - val_precision_1: 0.8504 - val_recall_1: 0.8060
Epoch 15/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3610 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 15: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8246 - precision_1: 0.8306 - recall_1: 0.8323 - val_loss: 0.4084 - val_accuracy: 0.8151 - val_precision_1: 0.8571 - val_recall_1: 0.8060
Epoch 16/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5914 - accuracy: 0.7500 - precision_1: 0.6429 - recall_1: 0.7500
Epoch 16: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8288 - precision_1: 0.8374 - recall_1: 0.8323 - val_loss: 0.4030 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 17/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4492 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.7500
Epoch 17: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8267 - precision_1: 0.8367 - recall_1: 0.8283 - val_loss: 0.3987 - val_accuracy: 0.8151 - val_precision_1: 0.8689 - val_recall_1: 0.7910
Epoch 18/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3726 - accuracy: 0.7812 - precision_1: 0.6429 - recall_1: 0.8182
Epoch 18: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8298 - precision_1: 0.8419 - recall_1: 0.8283 - val_loss: 0.3947 - val_accuracy: 0.8151 - val_precision_1: 0.8689 - val_recall_1: 0.7910
Epoch 19/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2258 - accuracy: 0.9375 - precision_1: 0.9333 - recall_1: 0.9333
Epoch 19: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8288 - precision_1: 0.8402 - recall_1: 0.8283 - val_loss: 0.3904 - val_accuracy: 0.8151 - val_precision_1: 0.8689 - val_recall_1: 0.7910
Epoch 20/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5445 - accuracy: 0.7188 - precision_1: 0.6364 - recall_1: 0.9333
Epoch 20: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8298 - precision_1: 0.8391 - recall_1: 0.8323 - val_loss: 0.3869 - val_accuracy: 0.8109 - val_precision_1: 0.8618 - val_recall_1: 0.7910
Epoch 21/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1994 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9000
Epoch 21: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8319 - precision_1: 0.8370 - recall_1: 0.8404 - val_loss: 0.3839 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 22/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5055 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.6000
Epoch 22: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8319 - precision_1: 0.8384 - recall_1: 0.8384 - val_loss: 0.3812 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 23/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4309 - accuracy: 0.7812 - precision_1: 0.5833 - recall_1: 0.7778
Epoch 23: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8319 - precision_1: 0.8384 - recall_1: 0.8384 - val_loss: 0.3782 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 24/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3606 - accuracy: 0.9062 - precision_1: 0.9286 - recall_1: 0.8667
Epoch 24: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8340 - precision_1: 0.8390 - recall_1: 0.8424 - val_loss: 0.3758 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 25/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3651 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 25: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8351 - precision_1: 0.8394 - recall_1: 0.8444 - val_loss: 0.3738 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 26/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2872 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 26: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3721 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 27/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2938 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 27: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3706 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 28/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2779 - accuracy: 0.8438 - precision_1: 0.7143 - recall_1: 0.9091
Epoch 28: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3688 - val_accuracy: 0.8193 - val_precision_1: 0.8699 - val_recall_1: 0.7985
Epoch 29/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3633 - accuracy: 0.8125 - precision_1: 0.8182 - recall_1: 0.6923
Epoch 29: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8340 - precision_1: 0.8404 - recall_1: 0.8404 - val_loss: 0.3673 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 30/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3469 - accuracy: 0.8438 - precision_1: 0.8636 - recall_1: 0.9048
Epoch 30: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8361 - precision_1: 0.8424 - recall_1: 0.8424 - val_loss: 0.3659 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 31/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3448 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 31: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8361 - precision_1: 0.8424 - recall_1: 0.8424 - val_loss: 0.3645 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 32/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4565 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8889
Epoch 32: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3633 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 33/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3824 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 33: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8382 - precision_1: 0.8431 - recall_1: 0.8465 - val_loss: 0.3624 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 34/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 34: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8393 - precision_1: 0.8462 - recall_1: 0.8444 - val_loss: 0.3614 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 35/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2913 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.7143
Epoch 35: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8393 - precision_1: 0.8476 - recall_1: 0.8424 - val_loss: 0.3603 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 36/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4471 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 36: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8424 - precision_1: 0.8485 - recall_1: 0.8485 - val_loss: 0.3596 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 37/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4237 - accuracy: 0.7812 - precision_1: 0.8750 - recall_1: 0.7368
Epoch 37: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8424 - precision_1: 0.8499 - recall_1: 0.8465 - val_loss: 0.3588 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 38/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3534 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 38: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8456 - precision_1: 0.8537 - recall_1: 0.8485 - val_loss: 0.3581 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 39/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2977 - accuracy: 0.8750 - precision_1: 0.9375 - recall_1: 0.8333
Epoch 39: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8445 - precision_1: 0.8519 - recall_1: 0.8485 - val_loss: 0.3575 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 40/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3472 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 40: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8414 - precision_1: 0.8496 - recall_1: 0.8444 - val_loss: 0.3570 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 41/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3988 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 41: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3609 - accuracy: 0.8424 - precision_1: 0.8513 - recall_1: 0.8444 - val_loss: 0.3565 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 42/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3193 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.7857
Epoch 42: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8424 - precision_1: 0.8513 - recall_1: 0.8444 - val_loss: 0.3561 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 43/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2850 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 43: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8435 - precision_1: 0.8531 - recall_1: 0.8444 - val_loss: 0.3557 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 44/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5287 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 44: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8435 - precision_1: 0.8516 - recall_1: 0.8465 - val_loss: 0.3552 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 45/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3549 - accuracy: 0.8125 - precision_1: 0.9412 - recall_1: 0.7619
Epoch 45: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8456 - precision_1: 0.8537 - recall_1: 0.8485 - val_loss: 0.3553 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 46/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3963 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 46: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8456 - precision_1: 0.8537 - recall_1: 0.8485 - val_loss: 0.3552 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 47/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3013 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.8182
Epoch 47: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8456 - precision_1: 0.8537 - recall_1: 0.8485 - val_loss: 0.3547 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 48/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5945 - accuracy: 0.7188 - precision_1: 0.6667 - recall_1: 0.8000
Epoch 48: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8477 - precision_1: 0.8543 - recall_1: 0.8525 - val_loss: 0.3542 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 49/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 49: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8466 - precision_1: 0.8540 - recall_1: 0.8505 - val_loss: 0.3540 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 50/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4068 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 50: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8477 - precision_1: 0.8543 - recall_1: 0.8525 - val_loss: 0.3535 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 51/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4203 - accuracy: 0.8438 - precision_1: 0.9231 - recall_1: 0.7500
Epoch 51: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8498 - precision_1: 0.8548 - recall_1: 0.8566 - val_loss: 0.3531 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 52/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2186 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9474
Epoch 52: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8487 - precision_1: 0.8545 - recall_1: 0.8545 - val_loss: 0.3530 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 53/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1576 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 53: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8466 - precision_1: 0.8540 - recall_1: 0.8505 - val_loss: 0.3527 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 54/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4298 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 54: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8498 - precision_1: 0.8520 - recall_1: 0.8606 - val_loss: 0.3526 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 55/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.9062 - precision_1: 0.9091 - recall_1: 0.9524
Epoch 55: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8487 - precision_1: 0.8517 - recall_1: 0.8586 - val_loss: 0.3525 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 56/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3404 - accuracy: 0.8125 - precision_1: 0.8182 - recall_1: 0.9000
Epoch 56: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8508 - precision_1: 0.8537 - recall_1: 0.8606 - val_loss: 0.3529 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 57/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5709 - accuracy: 0.7500 - precision_1: 0.6471 - recall_1: 0.8462
Epoch 57: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8487 - precision_1: 0.8517 - recall_1: 0.8586 - val_loss: 0.3526 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 58/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2219 - accuracy: 0.9062 - precision_1: 0.8500 - recall_1: 1.0000
Epoch 58: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8487 - precision_1: 0.8517 - recall_1: 0.8586 - val_loss: 0.3521 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 59/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2563 - accuracy: 0.9062 - precision_1: 0.9000 - recall_1: 0.9474
Epoch 59: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8498 - precision_1: 0.8520 - recall_1: 0.8606 - val_loss: 0.3514 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 60/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3966 - accuracy: 0.8438 - precision_1: 0.8500 - recall_1: 0.8947
Epoch 60: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8466 - precision_1: 0.8525 - recall_1: 0.8525 - val_loss: 0.3511 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 61/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3740 - accuracy: 0.8125 - precision_1: 0.9375 - recall_1: 0.7500
Epoch 61: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8498 - precision_1: 0.8534 - recall_1: 0.8586 - val_loss: 0.3508 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 62/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2924 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 62: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8477 - precision_1: 0.8514 - recall_1: 0.8566 - val_loss: 0.3505 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 63/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2726 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 63: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8487 - precision_1: 0.8531 - recall_1: 0.8566 - val_loss: 0.3505 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 64/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3669 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 64: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8477 - precision_1: 0.8528 - recall_1: 0.8545 - val_loss: 0.3502 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 65/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125
Epoch 65: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8487 - precision_1: 0.8531 - recall_1: 0.8566 - val_loss: 0.3502 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 66/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3393 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 66: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8466 - precision_1: 0.8511 - recall_1: 0.8545 - val_loss: 0.3500 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 67/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4101 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.9375
Epoch 67: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8487 - precision_1: 0.8531 - recall_1: 0.8566 - val_loss: 0.3498 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 68/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2261 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8824
Epoch 68: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8487 - precision_1: 0.8531 - recall_1: 0.8566 - val_loss: 0.3498 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 69/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3867 - accuracy: 0.8438 - precision_1: 0.9444 - recall_1: 0.8095
Epoch 69: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8508 - precision_1: 0.8566 - recall_1: 0.8566 - val_loss: 0.3496 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 70/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3040 - accuracy: 0.8125 - precision_1: 0.7647 - recall_1: 0.8667
Epoch 70: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8456 - precision_1: 0.8522 - recall_1: 0.8505 - val_loss: 0.3495 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 71/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2514 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 71: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8487 - precision_1: 0.8545 - recall_1: 0.8545 - val_loss: 0.3493 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 72/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4424 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 72: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8519 - precision_1: 0.8583 - recall_1: 0.8566 - val_loss: 0.3491 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 73/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4200 - accuracy: 0.8750 - precision_1: 0.8000 - recall_1: 1.0000
Epoch 73: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8529 - precision_1: 0.8600 - recall_1: 0.8566 - val_loss: 0.3491 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 74/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2353 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 74: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8540 - precision_1: 0.8618 - recall_1: 0.8566 - val_loss: 0.3490 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 75/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2476 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8571
Epoch 75: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8519 - precision_1: 0.8583 - recall_1: 0.8566 - val_loss: 0.3489 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 76/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2068 - accuracy: 0.9688 - precision_1: 0.9474 - recall_1: 1.0000
Epoch 76: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8571 - precision_1: 0.8671 - recall_1: 0.8566 - val_loss: 0.3486 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 77/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4795 - accuracy: 0.8125 - precision_1: 0.8750 - recall_1: 0.7778
Epoch 77: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8561 - precision_1: 0.8668 - recall_1: 0.8545 - val_loss: 0.3488 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 78/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3783 - accuracy: 0.8438 - precision_1: 0.9412 - recall_1: 0.8000
Epoch 78: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8561 - precision_1: 0.8668 - recall_1: 0.8545 - val_loss: 0.3489 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 79/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3488 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 79: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8561 - precision_1: 0.8668 - recall_1: 0.8545 - val_loss: 0.3488 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 80/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2833 - accuracy: 0.9375 - precision_1: 0.9167 - recall_1: 0.9167
Epoch 80: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8550 - precision_1: 0.8650 - recall_1: 0.8545 - val_loss: 0.3486 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 81/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4625 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 81: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8550 - precision_1: 0.8650 - recall_1: 0.8545 - val_loss: 0.3484 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 82/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3729 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 82: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8550 - precision_1: 0.8665 - recall_1: 0.8525 - val_loss: 0.3481 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 83/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3660 - accuracy: 0.8438 - precision_1: 1.0000 - recall_1: 0.7222
Epoch 83: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8561 - precision_1: 0.8668 - recall_1: 0.8545 - val_loss: 0.3479 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 84/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3551 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.7273
Epoch 84: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8571 - precision_1: 0.8671 - recall_1: 0.8566 - val_loss: 0.3476 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 85/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3781 - accuracy: 0.8438 - precision_1: 0.7368 - recall_1: 1.0000
Epoch 85: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8550 - precision_1: 0.8650 - recall_1: 0.8545 - val_loss: 0.3474 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 86/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3441 - accuracy: 0.8438 - precision_1: 0.7333 - recall_1: 0.9167
Epoch 86: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8582 - precision_1: 0.8673 - recall_1: 0.8586 - val_loss: 0.3475 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 87/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4908 - accuracy: 0.7188 - precision_1: 0.6429 - recall_1: 0.6923
Epoch 87: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8561 - precision_1: 0.8638 - recall_1: 0.8586 - val_loss: 0.3478 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 88/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4670 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 88: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8571 - precision_1: 0.8671 - recall_1: 0.8566 - val_loss: 0.3479 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 89/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4083 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 89: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8603 - precision_1: 0.8694 - recall_1: 0.8606 - val_loss: 0.3481 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 90/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2396 - accuracy: 0.9062 - precision_1: 0.9286 - recall_1: 0.8667
Epoch 90: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8582 - precision_1: 0.8673 - recall_1: 0.8586 - val_loss: 0.3484 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 91/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3677 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 91: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8561 - precision_1: 0.8653 - recall_1: 0.8566 - val_loss: 0.3484 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 92/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2462 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 92: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8582 - precision_1: 0.8689 - recall_1: 0.8566 - val_loss: 0.3482 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 93/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3711 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.7500
Epoch 93: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8571 - precision_1: 0.8656 - recall_1: 0.8586 - val_loss: 0.3481 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 94/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3614 - accuracy: 0.8750 - precision_1: 0.7647 - recall_1: 1.0000
Epoch 94: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8561 - precision_1: 0.8653 - recall_1: 0.8566 - val_loss: 0.3483 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 95/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2949 - accuracy: 0.9062 - precision_1: 0.9333 - recall_1: 0.8750
Epoch 95: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8561 - precision_1: 0.8638 - recall_1: 0.8586 - val_loss: 0.3484 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 96/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2767 - accuracy: 0.8750 - precision_1: 0.9524 - recall_1: 0.8696
Epoch 96: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8550 - precision_1: 0.8635 - recall_1: 0.8566 - val_loss: 0.3484 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 97/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2850 - accuracy: 0.8125 - precision_1: 0.6923 - recall_1: 0.8182
Epoch 97: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8571 - precision_1: 0.8656 - recall_1: 0.8586 - val_loss: 0.3483 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 98/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3494 - accuracy: 0.9062 - precision_1: 0.9333 - recall_1: 0.8750
Epoch 98: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8571 - precision_1: 0.8641 - recall_1: 0.8606 - val_loss: 0.3482 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 99/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4166 - accuracy: 0.7812 - precision_1: 0.6923 - recall_1: 0.7500
Epoch 99: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8571 - precision_1: 0.8656 - recall_1: 0.8586 - val_loss: 0.3484 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 100/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3243 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 100: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8571 - precision_1: 0.8656 - recall_1: 0.8586 - val_loss: 0.3484 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 101/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3432 - accuracy: 0.9062 - precision_1: 0.9048 - recall_1: 0.9500
Epoch 101: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8582 - precision_1: 0.8659 - recall_1: 0.8606 - val_loss: 0.3482 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 102/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2619 - accuracy: 0.8438 - precision_1: 0.9048 - recall_1: 0.8636
Epoch 102: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8550 - precision_1: 0.8635 - recall_1: 0.8566 - val_loss: 0.3483 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 103/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3181 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.9000
Epoch 103: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8540 - precision_1: 0.8633 - recall_1: 0.8545 - val_loss: 0.3480 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 104/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1561 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9500
Epoch 104: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8582 - precision_1: 0.8659 - recall_1: 0.8606 - val_loss: 0.3485 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 105/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2009 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8182
Epoch 105: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8571 - precision_1: 0.8656 - recall_1: 0.8586 - val_loss: 0.3485 - val_accuracy: 0.8277 - val_precision_1: 0.8550 - val_recall_1: 0.8358
Epoch 105: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Model-2x1">Model 2x1<a class="anchor-link" href="#Model-2x1">¶</a></h2><ul>
<li>val_accuracy: 0.8277</li>
<li>val_loss: 0.4333</li>
<li>val_precision: 0.8273</li>
<li>val_recall: 0.8712</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [101]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">twox1_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"2x1_model"</span><span class="p">)</span>
<span class="n">twox1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">twox1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">twox1_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">twox1_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">twox1_history</span> <span class="o">=</span> <span class="n">twox1_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
 1/30 [&gt;.............................] - ETA: 14s - loss: 0.6981 - accuracy: 0.6250 - precision_1: 0.8435 - recall_1: 0.8052
Epoch 1: val_loss did not improve from 0.29000
30/30 [==============================] - 1s 10ms/step - loss: 0.7083 - accuracy: 0.4968 - precision_1: 0.5744 - recall_1: 0.6693 - val_loss: 0.7046 - val_accuracy: 0.5546 - val_precision_1: 0.5897 - val_recall_1: 0.6866
Epoch 2/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6150 - accuracy: 0.5625 - precision_1: 0.5455 - recall_1: 0.7500
Epoch 2: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5158 - precision_1: 0.5277 - recall_1: 0.6545 - val_loss: 0.6814 - val_accuracy: 0.5714 - val_precision_1: 0.6013 - val_recall_1: 0.7090
Epoch 3/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6327 - accuracy: 0.6250 - precision_1: 0.5000 - recall_1: 0.9167
Epoch 3: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5578 - precision_1: 0.5584 - recall_1: 0.7152 - val_loss: 0.6621 - val_accuracy: 0.6050 - val_precision_1: 0.6250 - val_recall_1: 0.7463
Epoch 4/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7050 - accuracy: 0.5000 - precision_1: 0.4348 - recall_1: 0.7692
Epoch 4: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.5819 - precision_1: 0.5752 - recall_1: 0.7495 - val_loss: 0.6447 - val_accuracy: 0.6471 - val_precision_1: 0.6562 - val_recall_1: 0.7836
Epoch 5/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7963 - accuracy: 0.4688 - precision_1: 0.5000 - recall_1: 0.5882
Epoch 5: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6229 - precision_1: 0.6185 - recall_1: 0.7172 - val_loss: 0.6281 - val_accuracy: 0.6387 - val_precision_1: 0.7222 - val_recall_1: 0.5821
Epoch 6/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5278 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.7143
Epoch 6: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.7122 - precision_1: 0.7742 - recall_1: 0.6303 - val_loss: 0.6130 - val_accuracy: 0.6429 - val_precision_1: 0.7248 - val_recall_1: 0.5896
Epoch 7/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5358 - accuracy: 0.7812 - precision_1: 0.7143 - recall_1: 0.7692
Epoch 7: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7258 - precision_1: 0.7826 - recall_1: 0.6545 - val_loss: 0.5993 - val_accuracy: 0.6597 - val_precision_1: 0.7431 - val_recall_1: 0.6045
Epoch 8/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6522 - accuracy: 0.7188 - precision_1: 0.7000 - recall_1: 0.5385
Epoch 8: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7447 - precision_1: 0.8014 - recall_1: 0.6768 - val_loss: 0.5873 - val_accuracy: 0.6765 - val_precision_1: 0.7615 - val_recall_1: 0.6194
Epoch 9/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4881 - accuracy: 0.6562 - precision_1: 0.9333 - recall_1: 0.5833
Epoch 9: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7563 - precision_1: 0.8124 - recall_1: 0.6909 - val_loss: 0.5758 - val_accuracy: 0.6807 - val_precision_1: 0.7636 - val_recall_1: 0.6269
Epoch 10/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5380 - accuracy: 0.6875 - precision_1: 0.9000 - recall_1: 0.5000
Epoch 10: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7658 - precision_1: 0.8223 - recall_1: 0.7010 - val_loss: 0.5655 - val_accuracy: 0.6849 - val_precision_1: 0.7658 - val_recall_1: 0.6343
Epoch 11/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5110 - accuracy: 0.8438 - precision_1: 0.9286 - recall_1: 0.7647
Epoch 11: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7710 - precision_1: 0.8259 - recall_1: 0.7091 - val_loss: 0.5555 - val_accuracy: 0.6933 - val_precision_1: 0.7699 - val_recall_1: 0.6493
Epoch 12/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6242 - accuracy: 0.5625 - precision_1: 0.6429 - recall_1: 0.5000
Epoch 12: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7752 - precision_1: 0.8230 - recall_1: 0.7232 - val_loss: 0.5458 - val_accuracy: 0.7017 - val_precision_1: 0.7739 - val_recall_1: 0.6642
Epoch 13/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5629 - accuracy: 0.7812 - precision_1: 0.9091 - recall_1: 0.6250
Epoch 13: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7763 - precision_1: 0.8205 - recall_1: 0.7293 - val_loss: 0.5362 - val_accuracy: 0.7185 - val_precision_1: 0.7815 - val_recall_1: 0.6940
Epoch 14/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4864 - accuracy: 0.7500 - precision_1: 0.8235 - recall_1: 0.7368
Epoch 14: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7773 - precision_1: 0.8209 - recall_1: 0.7313 - val_loss: 0.5271 - val_accuracy: 0.7227 - val_precision_1: 0.7833 - val_recall_1: 0.7015
Epoch 15/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5700 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 15: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7836 - precision_1: 0.8247 - recall_1: 0.7414 - val_loss: 0.5183 - val_accuracy: 0.7353 - val_precision_1: 0.7934 - val_recall_1: 0.7164
Epoch 16/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5378 - accuracy: 0.7812 - precision_1: 0.9286 - recall_1: 0.6842
Epoch 16: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7899 - precision_1: 0.8300 - recall_1: 0.7495 - val_loss: 0.5104 - val_accuracy: 0.7353 - val_precision_1: 0.7934 - val_recall_1: 0.7164
Epoch 17/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5725 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.5455
Epoch 17: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7962 - precision_1: 0.8322 - recall_1: 0.7616 - val_loss: 0.5027 - val_accuracy: 0.7395 - val_precision_1: 0.7951 - val_recall_1: 0.7239
Epoch 18/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4362 - accuracy: 0.8125 - precision_1: 0.9286 - recall_1: 0.7222
Epoch 18: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8015 - precision_1: 0.8312 - recall_1: 0.7758 - val_loss: 0.4957 - val_accuracy: 0.7395 - val_precision_1: 0.7951 - val_recall_1: 0.7239
Epoch 19/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5150 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 19: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.8025 - precision_1: 0.8315 - recall_1: 0.7778 - val_loss: 0.4888 - val_accuracy: 0.7395 - val_precision_1: 0.7951 - val_recall_1: 0.7239
Epoch 20/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4237 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 20: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8067 - precision_1: 0.8359 - recall_1: 0.7818 - val_loss: 0.4828 - val_accuracy: 0.7395 - val_precision_1: 0.7951 - val_recall_1: 0.7239
Epoch 21/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5074 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8000
Epoch 21: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8088 - precision_1: 0.8380 - recall_1: 0.7838 - val_loss: 0.4770 - val_accuracy: 0.7479 - val_precision_1: 0.7984 - val_recall_1: 0.7388
Epoch 22/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4106 - accuracy: 0.7812 - precision_1: 0.9231 - recall_1: 0.6667
Epoch 22: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.8088 - precision_1: 0.8380 - recall_1: 0.7838 - val_loss: 0.4712 - val_accuracy: 0.7479 - val_precision_1: 0.7984 - val_recall_1: 0.7388
Epoch 23/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5388 - accuracy: 0.7500 - precision_1: 0.9167 - recall_1: 0.6111
Epoch 23: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.8078 - precision_1: 0.8377 - recall_1: 0.7818 - val_loss: 0.4664 - val_accuracy: 0.7521 - val_precision_1: 0.8049 - val_recall_1: 0.7388
Epoch 24/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5150 - accuracy: 0.7188 - precision_1: 0.8333 - recall_1: 0.7143
Epoch 24: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8099 - precision_1: 0.8384 - recall_1: 0.7859 - val_loss: 0.4616 - val_accuracy: 0.7563 - val_precision_1: 0.8065 - val_recall_1: 0.7463
Epoch 25/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4705 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 25: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8109 - precision_1: 0.8402 - recall_1: 0.7859 - val_loss: 0.4569 - val_accuracy: 0.7563 - val_precision_1: 0.8065 - val_recall_1: 0.7463
Epoch 26/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5949 - accuracy: 0.6562 - precision_1: 0.7000 - recall_1: 0.4667
Epoch 26: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8130 - precision_1: 0.8409 - recall_1: 0.7899 - val_loss: 0.4530 - val_accuracy: 0.7563 - val_precision_1: 0.8065 - val_recall_1: 0.7463
Epoch 27/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3412 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 27: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8162 - precision_1: 0.8433 - recall_1: 0.7939 - val_loss: 0.4493 - val_accuracy: 0.7605 - val_precision_1: 0.8130 - val_recall_1: 0.7463
Epoch 28/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3178 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 28: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8204 - precision_1: 0.8476 - recall_1: 0.7980 - val_loss: 0.4458 - val_accuracy: 0.7689 - val_precision_1: 0.8264 - val_recall_1: 0.7463
Epoch 29/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4506 - accuracy: 0.8125 - precision_1: 0.9000 - recall_1: 0.8182
Epoch 29: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8204 - precision_1: 0.8476 - recall_1: 0.7980 - val_loss: 0.4423 - val_accuracy: 0.7689 - val_precision_1: 0.8264 - val_recall_1: 0.7463
Epoch 30/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4770 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 30: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8214 - precision_1: 0.8495 - recall_1: 0.7980 - val_loss: 0.4393 - val_accuracy: 0.7689 - val_precision_1: 0.8264 - val_recall_1: 0.7463
Epoch 31/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5331 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.6923
Epoch 31: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8225 - precision_1: 0.8498 - recall_1: 0.8000 - val_loss: 0.4365 - val_accuracy: 0.7815 - val_precision_1: 0.8306 - val_recall_1: 0.7687
Epoch 32/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4774 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 32: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8225 - precision_1: 0.8498 - recall_1: 0.8000 - val_loss: 0.4336 - val_accuracy: 0.7815 - val_precision_1: 0.8306 - val_recall_1: 0.7687
Epoch 33/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5194 - accuracy: 0.7188 - precision_1: 0.7692 - recall_1: 0.6250
Epoch 33: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8204 - precision_1: 0.8462 - recall_1: 0.8000 - val_loss: 0.4310 - val_accuracy: 0.7857 - val_precision_1: 0.8320 - val_recall_1: 0.7761
Epoch 34/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3203 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 34: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8214 - precision_1: 0.8465 - recall_1: 0.8020 - val_loss: 0.4282 - val_accuracy: 0.7857 - val_precision_1: 0.8320 - val_recall_1: 0.7761
Epoch 35/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6172 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 35: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8225 - precision_1: 0.8468 - recall_1: 0.8040 - val_loss: 0.4257 - val_accuracy: 0.7857 - val_precision_1: 0.8320 - val_recall_1: 0.7761
Epoch 36/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9062 - precision_1: 0.9048 - recall_1: 0.9500
Epoch 36: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8225 - precision_1: 0.8468 - recall_1: 0.8040 - val_loss: 0.4231 - val_accuracy: 0.7857 - val_precision_1: 0.8320 - val_recall_1: 0.7761
Epoch 37/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5379 - accuracy: 0.7188 - precision_1: 0.9091 - recall_1: 0.5556
Epoch 37: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8214 - precision_1: 0.8450 - recall_1: 0.8040 - val_loss: 0.4208 - val_accuracy: 0.7857 - val_precision_1: 0.8320 - val_recall_1: 0.7761
Epoch 38/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4478 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 38: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8235 - precision_1: 0.8457 - recall_1: 0.8081 - val_loss: 0.4184 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 39/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3442 - accuracy: 0.8750 - precision_1: 0.9130 - recall_1: 0.9130
Epoch 39: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8256 - precision_1: 0.8478 - recall_1: 0.8101 - val_loss: 0.4161 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 40/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4435 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 40: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8235 - precision_1: 0.8442 - recall_1: 0.8101 - val_loss: 0.4140 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 41/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3658 - accuracy: 0.8438 - precision_1: 0.8182 - recall_1: 0.7500
Epoch 41: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8235 - precision_1: 0.8442 - recall_1: 0.8101 - val_loss: 0.4119 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 42/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4622 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 42: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8235 - precision_1: 0.8442 - recall_1: 0.8101 - val_loss: 0.4102 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 43/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3803 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 43: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8246 - precision_1: 0.8445 - recall_1: 0.8121 - val_loss: 0.4083 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 44/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2796 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 44: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8235 - precision_1: 0.8428 - recall_1: 0.8121 - val_loss: 0.4063 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 45/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3975 - accuracy: 0.9062 - precision_1: 0.8889 - recall_1: 0.9412
Epoch 45: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8235 - precision_1: 0.8428 - recall_1: 0.8121 - val_loss: 0.4048 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 46/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3726 - accuracy: 0.8438 - precision_1: 0.7222 - recall_1: 1.0000
Epoch 46: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8235 - precision_1: 0.8428 - recall_1: 0.8121 - val_loss: 0.4036 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 47/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4957 - accuracy: 0.8438 - precision_1: 0.8182 - recall_1: 0.7500
Epoch 47: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8235 - precision_1: 0.8428 - recall_1: 0.8121 - val_loss: 0.4023 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 48/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3894 - accuracy: 0.8125 - precision_1: 0.9000 - recall_1: 0.8182
Epoch 48: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8235 - precision_1: 0.8428 - recall_1: 0.8121 - val_loss: 0.4009 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 49/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3170 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 49: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8214 - precision_1: 0.8392 - recall_1: 0.8121 - val_loss: 0.3996 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 50/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1949 - accuracy: 0.9375 - precision_1: 0.8667 - recall_1: 1.0000
Epoch 50: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8235 - precision_1: 0.8399 - recall_1: 0.8162 - val_loss: 0.3985 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 51/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3005 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.7692
Epoch 51: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8235 - precision_1: 0.8413 - recall_1: 0.8141 - val_loss: 0.3973 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 52/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3385 - accuracy: 0.7812 - precision_1: 0.8667 - recall_1: 0.7222
Epoch 52: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8256 - precision_1: 0.8420 - recall_1: 0.8182 - val_loss: 0.3963 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 53/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6465 - accuracy: 0.7188 - precision_1: 0.8000 - recall_1: 0.7619
Epoch 53: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8256 - precision_1: 0.8420 - recall_1: 0.8182 - val_loss: 0.3952 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 54/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2860 - accuracy: 0.8438 - precision_1: 0.7333 - recall_1: 0.9167
Epoch 54: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8256 - precision_1: 0.8449 - recall_1: 0.8141 - val_loss: 0.3942 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 55/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3680 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.8571
Epoch 55: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8267 - precision_1: 0.8438 - recall_1: 0.8182 - val_loss: 0.3933 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 56/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5401 - accuracy: 0.8438 - precision_1: 0.7333 - recall_1: 0.9167
Epoch 56: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8235 - precision_1: 0.8413 - recall_1: 0.8141 - val_loss: 0.3924 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 57/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4949 - accuracy: 0.7812 - precision_1: 0.8182 - recall_1: 0.8571
Epoch 57: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8246 - precision_1: 0.8417 - recall_1: 0.8162 - val_loss: 0.3918 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 58/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4721 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 58: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8256 - precision_1: 0.8434 - recall_1: 0.8162 - val_loss: 0.3911 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 59/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4370 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500
Epoch 59: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8267 - precision_1: 0.8438 - recall_1: 0.8182 - val_loss: 0.3905 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 60/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4029 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 60: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8267 - precision_1: 0.8438 - recall_1: 0.8182 - val_loss: 0.3898 - val_accuracy: 0.8151 - val_precision_1: 0.8571 - val_recall_1: 0.8060
Epoch 61/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4925 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 61: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8277 - precision_1: 0.8441 - recall_1: 0.8202 - val_loss: 0.3894 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 62/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4797 - accuracy: 0.7500 - precision_1: 0.8182 - recall_1: 0.6000
Epoch 62: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8288 - precision_1: 0.8458 - recall_1: 0.8202 - val_loss: 0.3888 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 63/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3750 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 63: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8288 - precision_1: 0.8458 - recall_1: 0.8202 - val_loss: 0.3882 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 64/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4403 - accuracy: 0.7812 - precision_1: 0.8182 - recall_1: 0.8571
Epoch 64: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8298 - precision_1: 0.8462 - recall_1: 0.8222 - val_loss: 0.3875 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 65/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 65: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8309 - precision_1: 0.8465 - recall_1: 0.8242 - val_loss: 0.3869 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 66/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4908 - accuracy: 0.8125 - precision_1: 0.8889 - recall_1: 0.8000
Epoch 66: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8319 - precision_1: 0.8468 - recall_1: 0.8263 - val_loss: 0.3864 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 67/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3624 - accuracy: 0.8438 - precision_1: 0.9231 - recall_1: 0.7500
Epoch 67: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8319 - precision_1: 0.8468 - recall_1: 0.8263 - val_loss: 0.3859 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 68/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3894 - accuracy: 0.8438 - precision_1: 0.9000 - recall_1: 0.8571
Epoch 68: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8330 - precision_1: 0.8485 - recall_1: 0.8263 - val_loss: 0.3854 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 69/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5187 - accuracy: 0.7500 - precision_1: 0.7895 - recall_1: 0.7895
Epoch 69: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8340 - precision_1: 0.8489 - recall_1: 0.8283 - val_loss: 0.3850 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 70/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2965 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 70: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8340 - precision_1: 0.8489 - recall_1: 0.8283 - val_loss: 0.3846 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 71/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4253 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 71: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8361 - precision_1: 0.8495 - recall_1: 0.8323 - val_loss: 0.3844 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 72/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5017 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 72: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8361 - precision_1: 0.8495 - recall_1: 0.8323 - val_loss: 0.3840 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 73/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5038 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 73: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8351 - precision_1: 0.8477 - recall_1: 0.8323 - val_loss: 0.3837 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 74/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 74: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8351 - precision_1: 0.8477 - recall_1: 0.8323 - val_loss: 0.3833 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 75/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2992 - accuracy: 0.8438 - precision_1: 0.9091 - recall_1: 0.8696
Epoch 75: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8340 - precision_1: 0.8460 - recall_1: 0.8323 - val_loss: 0.3829 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 76/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2361 - accuracy: 0.9375 - precision_1: 0.8462 - recall_1: 1.0000
Epoch 76: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8340 - precision_1: 0.8460 - recall_1: 0.8323 - val_loss: 0.3827 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 77/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.8571
Epoch 77: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8330 - precision_1: 0.8443 - recall_1: 0.8323 - val_loss: 0.3824 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 78/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3313 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 78: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8340 - precision_1: 0.8446 - recall_1: 0.8343 - val_loss: 0.3820 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 79/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6355 - accuracy: 0.7188 - precision_1: 0.9091 - recall_1: 0.5556
Epoch 79: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8309 - precision_1: 0.8408 - recall_1: 0.8323 - val_loss: 0.3819 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 80/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4477 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.9375
Epoch 80: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3816 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 81/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2420 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 81: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3814 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 82/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2384 - accuracy: 0.9062 - precision_1: 0.9091 - recall_1: 0.8333
Epoch 82: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3812 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 83/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3713 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 83: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3809 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 84/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 84: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3806 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 85/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3574 - accuracy: 0.8438 - precision_1: 0.7368 - recall_1: 1.0000
Epoch 85: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3803 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 86/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3565 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 86: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3802 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 87/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3454 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 87: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3801 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 88/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1826 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9333
Epoch 88: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8340 - precision_1: 0.8432 - recall_1: 0.8364 - val_loss: 0.3799 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 89/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2798 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 89: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3949 - accuracy: 0.8340 - precision_1: 0.8432 - recall_1: 0.8364 - val_loss: 0.3798 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 90/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2735 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 90: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8319 - precision_1: 0.8398 - recall_1: 0.8364 - val_loss: 0.3796 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 91/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6014 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 91: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8330 - precision_1: 0.8415 - recall_1: 0.8364 - val_loss: 0.3795 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 92/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4008 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 92: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8319 - precision_1: 0.8398 - recall_1: 0.8364 - val_loss: 0.3793 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 93/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.9062 - precision_1: 0.9474 - recall_1: 0.9000
Epoch 93: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8330 - precision_1: 0.8401 - recall_1: 0.8384 - val_loss: 0.3791 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 94/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3516 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.8571
Epoch 94: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8319 - precision_1: 0.8398 - recall_1: 0.8364 - val_loss: 0.3789 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 95/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3878 - accuracy: 0.8125 - precision_1: 0.7727 - recall_1: 0.9444
Epoch 95: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8319 - precision_1: 0.8398 - recall_1: 0.8364 - val_loss: 0.3786 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 96/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2649 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 96: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8330 - precision_1: 0.8401 - recall_1: 0.8384 - val_loss: 0.3784 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 97/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3588 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.9000
Epoch 97: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8330 - precision_1: 0.8401 - recall_1: 0.8384 - val_loss: 0.3781 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 98/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3835 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 98: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3777 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 99/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4579 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.9474
Epoch 99: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3774 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 100/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3690 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 100: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8351 - precision_1: 0.8407 - recall_1: 0.8424 - val_loss: 0.3773 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 101/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1566 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9286
Epoch 101: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8372 - precision_1: 0.8427 - recall_1: 0.8444 - val_loss: 0.3769 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 102/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4247 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 102: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8361 - precision_1: 0.8424 - recall_1: 0.8424 - val_loss: 0.3765 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 103/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8438 - precision_1: 0.8696 - recall_1: 0.9091
Epoch 103: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8372 - precision_1: 0.8427 - recall_1: 0.8444 - val_loss: 0.3764 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 104/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4876 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 104: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8372 - precision_1: 0.8427 - recall_1: 0.8444 - val_loss: 0.3762 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 105/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2658 - accuracy: 0.9375 - precision_1: 0.9091 - recall_1: 1.0000
Epoch 105: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8361 - precision_1: 0.8424 - recall_1: 0.8424 - val_loss: 0.3758 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 106/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3346 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 106: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8372 - precision_1: 0.8427 - recall_1: 0.8444 - val_loss: 0.3757 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 107/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5344 - accuracy: 0.7812 - precision_1: 0.7333 - recall_1: 0.7857
Epoch 107: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8393 - precision_1: 0.8448 - recall_1: 0.8465 - val_loss: 0.3756 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 108/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4368 - accuracy: 0.8438 - precision_1: 0.7273 - recall_1: 0.8000
Epoch 108: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8372 - precision_1: 0.8441 - recall_1: 0.8424 - val_loss: 0.3755 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 109/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4045 - accuracy: 0.8438 - precision_1: 0.9286 - recall_1: 0.7647
Epoch 109: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3751 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 110/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3356 - accuracy: 0.8438 - precision_1: 0.9412 - recall_1: 0.8000
Epoch 110: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8414 - precision_1: 0.8454 - recall_1: 0.8505 - val_loss: 0.3750 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 111/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4701 - accuracy: 0.7500 - precision_1: 0.7778 - recall_1: 0.7778
Epoch 111: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8403 - precision_1: 0.8451 - recall_1: 0.8485 - val_loss: 0.3746 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 112/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4364 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 112: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8414 - precision_1: 0.8454 - recall_1: 0.8505 - val_loss: 0.3743 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 113/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2808 - accuracy: 0.9375 - precision_1: 0.9333 - recall_1: 0.9333
Epoch 113: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8403 - precision_1: 0.8451 - recall_1: 0.8485 - val_loss: 0.3739 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 114/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4712 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.7692
Epoch 114: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8414 - precision_1: 0.8454 - recall_1: 0.8505 - val_loss: 0.3735 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 115/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3579 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 115: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8403 - precision_1: 0.8451 - recall_1: 0.8485 - val_loss: 0.3733 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 116/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2888 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 116: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8382 - precision_1: 0.8444 - recall_1: 0.8444 - val_loss: 0.3732 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 117/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4172 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 1.0000
Epoch 117: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8372 - precision_1: 0.8441 - recall_1: 0.8424 - val_loss: 0.3731 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 118/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3836 - accuracy: 0.8438 - precision_1: 0.9474 - recall_1: 0.8182
Epoch 118: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8393 - precision_1: 0.8434 - recall_1: 0.8485 - val_loss: 0.3729 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 119/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5854 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 119: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.8382 - precision_1: 0.8444 - recall_1: 0.8444 - val_loss: 0.3726 - val_accuracy: 0.8403 - val_precision_1: 0.8810 - val_recall_1: 0.8284
Epoch 120/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2590 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8333
Epoch 120: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8351 - precision_1: 0.8394 - recall_1: 0.8444 - val_loss: 0.3725 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 121/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4732 - accuracy: 0.7500 - precision_1: 0.7273 - recall_1: 0.8889
Epoch 121: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8361 - precision_1: 0.8397 - recall_1: 0.8465 - val_loss: 0.3725 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 122/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4340 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 122: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8382 - precision_1: 0.8431 - recall_1: 0.8465 - val_loss: 0.3722 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 123/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4312 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 123: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8361 - precision_1: 0.8397 - recall_1: 0.8465 - val_loss: 0.3720 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 124/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4284 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 124: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8361 - precision_1: 0.8397 - recall_1: 0.8465 - val_loss: 0.3716 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 125/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2556 - accuracy: 0.9062 - precision_1: 0.9500 - recall_1: 0.9048
Epoch 125: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3714 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 126/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7181 - accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875
Epoch 126: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3712 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 127/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3187 - accuracy: 0.9062 - precision_1: 0.9091 - recall_1: 0.8333
Epoch 127: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3711 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 128/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3710 - accuracy: 0.8125 - precision_1: 0.7895 - recall_1: 0.8824
Epoch 128: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3711 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 129/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2964 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8696
Epoch 129: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3710 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 130/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3295 - accuracy: 0.9375 - precision_1: 0.9500 - recall_1: 0.9500
Epoch 130: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3709 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 131/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3964 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.7500
Epoch 131: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3783 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3707 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 132/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4028 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 132: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3705 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 133/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4405 - accuracy: 0.8750 - precision_1: 0.7500 - recall_1: 0.9000
Epoch 133: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3702 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 134/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9524
Epoch 134: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3702 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 135/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2595 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 135: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3703 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 136/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 136: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3702 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 137/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5920 - accuracy: 0.7188 - precision_1: 0.7647 - recall_1: 0.7222
Epoch 137: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3770 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3702 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 138/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5300 - accuracy: 0.7500 - precision_1: 0.6667 - recall_1: 0.8571
Epoch 138: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3701 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 139/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4836 - accuracy: 0.8125 - precision_1: 0.7647 - recall_1: 0.8667
Epoch 139: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3700 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 140/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2609 - accuracy: 0.9375 - precision_1: 0.9000 - recall_1: 1.0000
Epoch 140: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3699 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 141/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5556 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.6667
Epoch 141: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3698 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 142/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3608 - accuracy: 0.9062 - precision_1: 0.8421 - recall_1: 1.0000
Epoch 142: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3759 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3695 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 143/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3561 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 143: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8372 - precision_1: 0.8414 - recall_1: 0.8465 - val_loss: 0.3696 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 144/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5329 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 144: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3694 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 145/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4619 - accuracy: 0.7812 - precision_1: 0.8421 - recall_1: 0.8000
Epoch 145: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8393 - precision_1: 0.8434 - recall_1: 0.8485 - val_loss: 0.3695 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 146/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5232 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 146: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8382 - precision_1: 0.8431 - recall_1: 0.8465 - val_loss: 0.3694 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 147/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4440 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 147: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3693 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 148/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4070 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 148: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8361 - precision_1: 0.8410 - recall_1: 0.8444 - val_loss: 0.3693 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 149/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4243 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 149: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8361 - precision_1: 0.8424 - recall_1: 0.8424 - val_loss: 0.3694 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 150/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2887 - accuracy: 0.8750 - precision_1: 0.8947 - recall_1: 0.8947
Epoch 150: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8372 - precision_1: 0.8441 - recall_1: 0.8424 - val_loss: 0.3692 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 151/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3934 - accuracy: 0.8125 - precision_1: 0.7727 - recall_1: 0.9444
Epoch 151: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8382 - precision_1: 0.8431 - recall_1: 0.8465 - val_loss: 0.3692 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 152/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3017 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7895
Epoch 152: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8403 - precision_1: 0.8451 - recall_1: 0.8485 - val_loss: 0.3691 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 153/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4467 - accuracy: 0.8125 - precision_1: 0.6923 - recall_1: 0.8182
Epoch 153: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8393 - precision_1: 0.8462 - recall_1: 0.8444 - val_loss: 0.3689 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 154/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4174 - accuracy: 0.8125 - precision_1: 0.8667 - recall_1: 0.7647
Epoch 154: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8414 - precision_1: 0.8468 - recall_1: 0.8485 - val_loss: 0.3687 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 155/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4085 - accuracy: 0.7812 - precision_1: 0.8947 - recall_1: 0.7727
Epoch 155: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3686 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 156/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3523 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 156: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8393 - precision_1: 0.8462 - recall_1: 0.8444 - val_loss: 0.3685 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 157/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3967 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.7143
Epoch 157: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3683 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 158/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3930 - accuracy: 0.7812 - precision_1: 0.7368 - recall_1: 0.8750
Epoch 158: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3682 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 159/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5256 - accuracy: 0.7188 - precision_1: 0.6429 - recall_1: 0.6923
Epoch 159: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3682 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 160/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2342 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8889
Epoch 160: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3681 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 161/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3400 - accuracy: 0.8438 - precision_1: 0.9091 - recall_1: 0.7143
Epoch 161: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8372 - precision_1: 0.8455 - recall_1: 0.8404 - val_loss: 0.3681 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 162/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3089 - accuracy: 0.8750 - precision_1: 0.9474 - recall_1: 0.8571
Epoch 162: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3681 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 163/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5549 - accuracy: 0.6875 - precision_1: 0.7647 - recall_1: 0.6842
Epoch 163: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8372 - precision_1: 0.8441 - recall_1: 0.8424 - val_loss: 0.3683 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 164/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4164 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.8571
Epoch 164: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3683 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 165/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2439 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8947
Epoch 165: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3683 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 166/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5515 - accuracy: 0.6875 - precision_1: 0.6154 - recall_1: 0.6154
Epoch 166: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8393 - precision_1: 0.8476 - recall_1: 0.8424 - val_loss: 0.3684 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 167/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4222 - accuracy: 0.8438 - precision_1: 0.9091 - recall_1: 0.8696
Epoch 167: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8382 - precision_1: 0.8458 - recall_1: 0.8424 - val_loss: 0.3683 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 168/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3991 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 168: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8393 - precision_1: 0.8476 - recall_1: 0.8424 - val_loss: 0.3684 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 169/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1338 - accuracy: 0.9688 - precision_1: 0.9474 - recall_1: 1.0000
Epoch 169: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8393 - precision_1: 0.8476 - recall_1: 0.8424 - val_loss: 0.3684 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 170/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3773 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 170: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8403 - precision_1: 0.8479 - recall_1: 0.8444 - val_loss: 0.3683 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 171/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3074 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 171: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8414 - precision_1: 0.8510 - recall_1: 0.8424 - val_loss: 0.3683 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 172/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3139 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 172: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8393 - precision_1: 0.8490 - recall_1: 0.8404 - val_loss: 0.3682 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 173/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3487 - accuracy: 0.8750 - precision_1: 0.9375 - recall_1: 0.8333
Epoch 173: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8403 - precision_1: 0.8507 - recall_1: 0.8404 - val_loss: 0.3682 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 174/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6102 - accuracy: 0.7812 - precision_1: 0.6923 - recall_1: 0.7500
Epoch 174: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8403 - precision_1: 0.8507 - recall_1: 0.8404 - val_loss: 0.3680 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 175/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4698 - accuracy: 0.7812 - precision_1: 0.7778 - recall_1: 0.8235
Epoch 175: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8414 - precision_1: 0.8525 - recall_1: 0.8404 - val_loss: 0.3680 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 176/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4548 - accuracy: 0.8125 - precision_1: 0.9375 - recall_1: 0.7500
Epoch 176: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8424 - precision_1: 0.8542 - recall_1: 0.8404 - val_loss: 0.3680 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 177/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4422 - accuracy: 0.7812 - precision_1: 0.7000 - recall_1: 0.9333
Epoch 177: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8403 - precision_1: 0.8507 - recall_1: 0.8404 - val_loss: 0.3684 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 178/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3486 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 178: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8435 - precision_1: 0.8545 - recall_1: 0.8424 - val_loss: 0.3686 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 179/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2695 - accuracy: 0.8750 - precision_1: 0.9091 - recall_1: 0.7692
Epoch 179: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8403 - precision_1: 0.8507 - recall_1: 0.8404 - val_loss: 0.3689 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 180/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5674 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.6667
Epoch 180: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8435 - precision_1: 0.8545 - recall_1: 0.8424 - val_loss: 0.3689 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 181/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3587 - accuracy: 0.8438 - precision_1: 0.7692 - recall_1: 0.8333
Epoch 181: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8435 - precision_1: 0.8545 - recall_1: 0.8424 - val_loss: 0.3691 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 182/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5325 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 182: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8435 - precision_1: 0.8560 - recall_1: 0.8404 - val_loss: 0.3692 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 183/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3191 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 183: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8424 - precision_1: 0.8557 - recall_1: 0.8384 - val_loss: 0.3692 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 184/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3238 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 184: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8445 - precision_1: 0.8577 - recall_1: 0.8404 - val_loss: 0.3692 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 185/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2725 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 185: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8424 - precision_1: 0.8528 - recall_1: 0.8424 - val_loss: 0.3693 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 186/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4470 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 186: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8435 - precision_1: 0.8574 - recall_1: 0.8384 - val_loss: 0.3695 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 187/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5947 - accuracy: 0.7812 - precision_1: 0.7619 - recall_1: 0.8889
Epoch 187: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8456 - precision_1: 0.8595 - recall_1: 0.8404 - val_loss: 0.3696 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 188/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2180 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 188: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8456 - precision_1: 0.8595 - recall_1: 0.8404 - val_loss: 0.3698 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 189/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2757 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 189: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8424 - precision_1: 0.8542 - recall_1: 0.8404 - val_loss: 0.3698 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 190/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2797 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 190: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8445 - precision_1: 0.8577 - recall_1: 0.8404 - val_loss: 0.3700 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 191/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4064 - accuracy: 0.8125 - precision_1: 1.0000 - recall_1: 0.6667
Epoch 191: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8414 - precision_1: 0.8525 - recall_1: 0.8404 - val_loss: 0.3703 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 192/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4804 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.7500
Epoch 192: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8445 - precision_1: 0.8577 - recall_1: 0.8404 - val_loss: 0.3705 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 193/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4707 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.6000
Epoch 193: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8445 - precision_1: 0.8577 - recall_1: 0.8404 - val_loss: 0.3707 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 194/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4422 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 194: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8445 - precision_1: 0.8577 - recall_1: 0.8404 - val_loss: 0.3709 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 195/256
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4478 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 195: val_loss did not improve from 0.29000
30/30 [==============================] - 0s 3ms/step - loss: 0.3636 - accuracy: 0.8466 - precision_1: 0.8613 - recall_1: 0.8404 - val_loss: 0.3711 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 195: early stopping
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [102]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">twox1_history</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[102]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>{'verbose': 1, 'epochs': 256, 'steps': 30}</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Plot-learning-curves">Plot learning curves<a class="anchor-link" href="#Plot-learning-curves">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [103]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">plot_learning_curves</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'training data'</span><span class="p">,</span> <span class="s1">'validation data'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [104]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="s2">"baseline regression model"</span><span class="p">)</span>
<span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">all_eights_history</span><span class="p">,</span> <span class="s2">"8-8-8-1"</span><span class="p">)</span>
<span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">three_layer_history</span><span class="p">,</span> <span class="s2">"16-8-1 model"</span><span class="p">)</span>
<span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">eightx1_history</span><span class="p">,</span> <span class="s2">"8-1 model"</span><span class="p">)</span>
<span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">eightxfourxone_history</span><span class="p">,</span> <span class="s2">"8-4-1"</span><span class="p">)</span>
<span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">fourx1_history</span><span class="p">,</span> <span class="s2">"4-1 model"</span><span class="p">)</span>
<span class="n">plot_learning_curves</span><span class="p">(</span><span class="n">twox1_history</span><span class="p">,</span> <span class="s2">"2-1 model"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB9m0lEQVR4nO3dd3hTZcMG8DtJ23TvPaAFyoYCBUpBhooylCUKIgo4QBEURRwoCqIv+IoiDgT1A/FFBBwsRUA2sgq07FEoq4Uu2tJNM8/3x9OkDR20kCYd9++6epGcnHPynKb03H2mTJIkCURERET1hNzaBSAiIiIyJ4YbIiIiqlcYboiIiKheYbghIiKieoXhhoiIiOoVhhsiIiKqVxhuiIiIqF5huCEiIqJ6heGGiIiI6hWGGyIiIqpXGG6IqMZduHABTz75JIKDg+Ho6IiWLVti9uzZKCwsvOOxRUVFmDt3Llq3bg1HR0cEBQXhiSeewOnTp6v8/tu2bcP9998Pb29vuLu7o2vXrli+fHmVj//Pf/6DwYMHw8/PDzKZDLNmzarysURkeTbWLgAR1W9JSUno2rUr3NzcMHnyZHh6euLAgQOYOXMmYmNjsX79+kqPHz16NDZs2IDx48ejU6dOSE5OxsKFCxEdHY2TJ0+icePGlR6/YcMGDB06FNHR0Zg1axZkMhl+/fVXjBkzBhkZGXj99dfveA0zZsyAv78/OnbsiC1btlTr+onICiQiohr0n//8RwIgnTp1ymT7mDFjJABSVlZWhcdeu3ZNAiBNmzbNZPuOHTskANL8+fPv+P4PPfSQFBgYKBUVFRm3aTQaqWnTplL79u2rdA2XL1+WJEmSbty4IQGQZs6cWaXjiMg6WHNDRDUqNzcXAODn52eyPSAgAHK5HHZ2dhUem5eXV+GxAODg4FCl9/fw8IBSqTRus7Gxgbe3d9UuAEBoaGiV9yUi62OfGyKqUX369AEAPP/88zh27BiSkpKwevVqLFq0CK+++iqcnJwqPLZp06YIDg7G559/jj///BPXrl3DoUOH8NJLLyEsLAxPPvlkld7/9OnTeP/995GQkICLFy/io48+wpEjR/DWW2+Z6zKJqDaxdtUREdV/H330keTg4CABMH699957VTo2JiZGatq0qcmxkZGRUkpKSpWOz8/Pl0aMGCHJZDLj8Y6OjtK6deuqfR1sliKqG9gsRUQ1LjQ0FL169cLw4cPh5eWFjRs3Ys6cOfD398fkyZMrPdbDwwMdOnTAE088gW7duiEhIQFz587FE088ga1bt8Le3r7S45VKJZo3b47HH38cjz32GHQ6Hb7//ns8/fTT2Lp1K7p162bOSyWiWoDhhohq1KpVqzBhwgScP38ewcHBAIDHHnsMer0eb7/9NkaNGgWZTAa1Wm08xsHBAW5ubsjJyUHPnj3x5ptv4o033jC+3rlzZ/Tp0wc//vgjJk6ciFu3biEnJ8fkff39/QEAkydPxsGDBxEXFwe5XLTEjxgxAm3atMGUKVMQExMDAEhNTTU53s3NrUp9eoio9mGfGyKqUd9++y06duxoDDYGgwcPRmFhIY4ePYrHHnsMAQEBxq8pU6YAAP744w+kpaVh8ODBJsf27t0brq6u2LdvHwBg9erVJscbOhyr1WosWbIEjzzyiDHYAICtrS0GDBiAI0eOGEPV7cevXr26xr4nRFSzWHNDRDUqLS0NHh4eZbZrNBoAgFarxeeff46bN28aXwsMDDQeCwA6nc7kWEmSoNPpoNVqAQD9+vXD1q1by7xHZmYmtFptmeMN76/X642v3X58mzZtqnyNRFS7MNwQUY1q3rw5/vnnH5w/fx7Nmzc3bl+5ciXkcjnat29vDDPlHQuIpq3SswJv2LABBQUF6NixIwCY1NaU5uvrC3d3d6xduxazZ882DjvPz8/Hn3/+iZYtWxqbnvr27WuW6yUi62O4IaIa9eabb2LTpk3o2bMnJk+eDC8vL/z111/YtGkTXnjhhQqDDQAMGjQIbdq0wezZs3H16lVjh+JvvvkGAQEBeP755yt9b4VCgWnTpmHGjBno1q0bxowZA51OhyVLluDatWv4+eefq3QNy5cvx9WrV43LRezZswcff/wxAOCZZ5654yzJRGRZMkmSJGsXgojqt0OHDmHWrFk4evQoMjMzERYWhrFjx+Ktt96CjU3lf2PdvHkTH330ETZu3IirV6/CxcUFffv2xZw5cxAWFlal9//ll1/w5Zdf4vz581CpVGjfvj3efPNNDB8+vErH9+nTB7t37y73tZ07dxrn8iGi2oHhhoiIiOoVjpYiIiKieoXhhoiIiOoVhhsiIiKqVxhuiIiIqF5huCEiIqJ6heGGiIiI6pUGN4mfXq9HcnIyXFxcIJPJrF0cIiIiqgJJkpCXl4fAwECTteLK0+DCTXJyMkJCQqxdDCIiIroLSUlJZRbivV2DCzcuLi4AxDfH1dXVyqUhIiKiqsjNzUVISIjxPl6ZBhduDE1Rrq6uDDdERER1TFW6lLBDMREREdUrDDdERERUrzDcEBERUb3CcENERET1CsMNERER1SsMN0RERFSvMNwQERFRvcJwQ0RERPUKww0RERHVKww3REREVK9YPdwsXLgQoaGhsLe3R1RUFA4dOlThvhqNBrNnz0bTpk1hb2+PiIgIbN682YKlJSIiotrOquFm9erVmDp1KmbOnIm4uDhERESgX79+SE9PL3f/GTNm4LvvvsPXX3+NM2fO4KWXXsKwYcNw9OhRC5eciIiIaiuZJEmStd48KioKXbp0wTfffAMA0Ov1CAkJwSuvvIJ33nmnzP6BgYF47733MGnSJOO24cOHw8HBAT///HOV3jM3Nxdubm7IycnhwplERHTPJEmCSquHva3ins9VpNFV+Tw5tzRwtbep0kKS5qbW6qGQy6CQW+69q3P/tlrNjVqtRmxsLPr27VtSGLkcffv2xYEDB8o9RqVSwd7e3mSbg4MD9u7dW+H7qFQq5ObmmnwRERGZy9J9V9Dqg83YfCq1zGvZhWpcupFfpfPM+fss2szcgrl/n4VGp4ckSYhPzUNWgdq4zy21Dj8fvIohC/ch4sN/MP5/R3Cz1Ov34lxqLtLziozPM/NVOJ2cA73etA4ku1CNfgv2oNvc7fj3wg1juY4nZaNIozNLWe6VjbXeOCMjAzqdDn5+fibb/fz8cO7cuXKP6devH+bPn49evXqhadOm2L59O9asWQOdruJv5ty5c/Hhhx+atexEREQAoNXp8f2ei5Ak4Iut59GvjZ+xJiU5+xaGL9qPG3kq/DGxOyJC3Cs8z94LGfh+zyUAwHd7LmH/xUzc0uiQkJ4PXxcl/pjYHT4uSjy9JAaxV28aj9t2Nh2PfPUv5jzWDr3CfSAvVZNyPfsWdsWnQ6XRAwBaB7qia6inyT4AoNLq8J+NZ/G/A1chlwG9m/vARiHHznPp0OolBLrZY3hkMJ7rEQYPJzt8+OcZXM4oAACMWXoI97fwxaHLWchXaeFib4NH2wfi8chgdGrkbpVaJcCKzVLJyckICgrC/v37ER0dbdz+1ltvYffu3YiJiSlzzI0bNzB+/Hj8+eefkMlkaNq0Kfr27YulS5fi1q1b5b6PSqWCSqUyPs/NzUVISAibpYiIqMrUWj1+2n8FHRq5o0uop3H7znPpeHbZYePz5c93Rc9wH+Tc0uCJxftxPk3U2vRo5oUVL3RDzi0Nlu69jBv54r7UzMcZD7byxVM/xOB69i30DPfGsaRs5BVpTd6/iY8TwrycsP1cOlztbfDqg+FoHeCK99adMgaNIHcH3NfMGwqFDFczC7D/YiZuv8OHeDpgeKdgDO8UjEB3B+xLyMCnW87h1PXyWzWUNnKotCIcBbjZY1TXRpi/9TzkMuDh1v7YfDq13H2D3B3w71v3lwlS96I6zVJWq7nx9vaGQqFAWlqayfa0tDT4+/uXe4yPjw/WrVuHoqIiZGZmIjAwEO+88w6aNGlS4fsolUoolUqzlp2IiBqWpfsu45NN5yCTAa88EI4pD4ZDIZfht9gkAICjnQKFah3+79/LaBfkhgn/i8X5tHz4uCiRU6jBvoRMbD+bhsW7L+LwlZsm55791xkAQLCHAxY/HYnMfDX+b+8ltAl0RWRjD4xZcgiXbhTg0o0C2NnIsWRcF2PA+vOV+/DZlnj8EXcN17NvYfWRJJNzdw31hL+bPdRaPfYlZCAp6xYWbLuABdsuwMPRFjcLNQAAD0dbzB/RAY29HLH+WDJ0egmDOwSikacjtp1Nw+f/nMfljALM33oeADC+VxNMH9AKm06m4OClTAxoF4AuoZ6IuZSJ32Ovoamvs1mDTXVZvUNx165d8fXXXwMQHYobNWqEyZMnl9uh+HYajQatWrXCiBEjMGfOnCq9JzsUExFRVej0EhRyGTQ6PXr+dydSc0v6o0Q38cKswW3w6Nf/QqOTsPjpTpi4Ig6SBPi5KpGWq4Kz0ga/vhiN32KT8OO+K1DIZdDpJbjY2+D5+8Kg10vYfSEDx5OyIZMBK56PQvdm3mXKcT4tD48v2o88lRbfPtUJA9oFlNmnSKPDtrNpuHRD1OI42inQr40/QjwdjfvcUuvwz5lU/B57DXsTMiBJgLujLQZHBGJin6YIcHOo8HuRr9Ji+pqT+PN4MsJ9nfHnK/eZpQN1dVTn/m3VcLN69WqMHTsW3333Hbp27YoFCxbg119/xblz5+Dn54cxY8YgKCgIc+fOBQDExMTg+vXr6NChA65fv45Zs2bh8uXLiIuLg7u7e5Xek+GGiKhhyi3SQCGTwUlZeaOFWqvH5F/iEJd4E989E4lrN29hyqpj8HZW4p0BLTFz/SkUqHWwkcug1UtoE+iKja/2xIvLj2DLadEaEerliIWjO6FNoBsy8lXo/elOFKh1sFPI8b/nu6JbEy/j+yWk50Oj06NVQMX3pBt5KuTc0qCZr7NZvhfJ2beQmFWIjo3cobSpWkiRJAknruUgzMcJrva2ZilHddSJZikAGDlyJG7cuIEPPvgAqamp6NChAzZv3mzsZJyYmAi5vGRAV1FREWbMmIFLly7B2dkZAwcOxPLly6scbIiIqO6IvZqFQHeHSmsUqio1pwiPfv0vtHoJqyZ0Q0v/8m+Oer2Et34/jn/OiJDy/E9H4OVkBwAYE90Yj0cGo2Mjd0xaEYdzqXkAgCcigwEAr/VtjlPXc9E1zBOzh7SBS3EA8HZW4q3+LfH5P/GY+1h7k2ADoEqBxcdFCR8X83WxCHR3QKB79b6vMpms0k7RtYlVa26sgTU3RES13/GkbAxZuA9h3k7YNrV3ledTOZOci5jLmRjZJQSOduLvd0mS8Oyyw9gVL4Yt+7va44+Xu+NaViFiE2+ia6gnIht7IKtAjS+2ncfPBxNhI5ch1NsJCemiQ7DSRo797zwAL2cRMIo0Onz+Tzyu3byFeU9EwPkOtUF07+pMzQ0REVF5NhXPGXM5owBbz6Sif9sA7D5/A38dT8aDrXzRu7kvDl7KxN8nU9CpsQee7BKCsyl5GPHdAeSrtFgRk4hvR3dCcz8X/B57Dbvib8DORo4gdwdczihAn3k7odGV/G0f6GaP9DwVtMVzuvx3eHv0buGDxxftx5XMQjzWKdgYbADA3laB9x5pbdlvClUZa26IiKgMrU4M6ZXLZFUa9XIlowDvrTuJ+1v44rkeYfc8UubhL3Ybh1F3buyBL0d1RL8v9iBfpS0uF1B6brmHW/vhWFI20vNUkMkASQLsbOQIdLNHSk4RVFo93hnQEoMiAjFs4T6k54kOv11CPRBzOQuFajFfWkSwG17o2QSDIgIBACk5t7DuaDKeimoENwfL9zOhEnWmQ7E1MNwQEVVMpdXhtVXHjDUn9rZyLHo6Eve38K30uEkr4rDxZAoA4IGWvvj8iQh4FPdVKS0pq9AYJEI8HYxNR7fv0/PTnVDIZZDLAI1OQnM/Z5xPy0eYtxMKVFqk56ng6WSH+5p5Y9OpFGMtTAs/Fyx+JhIfrD+Ffy9kGM/ZqZE7fn0xGjYKOVJybuHU9Vz0aOYFRzsbFKi0OHgpEyGejmju53J33ziqcQw3lWC4ISIqn14vYcrqY/jzeLLJdh8XJba+3gvujmXDCiDCSO95O6GXADuFHGqdHgFu9vjmqY6IbFwy4d0vMYl4d+1J43NHOwUGtgtAr+Y+sJHL4OeqRKdGHlh+8Co+WH8aXUM9EezpgDVx1wGIfi+bpvREI09HXMksRCNPR9jZyHE8KRuvrz4GAPj5hSgEujtAr5dwLjUPtzRaADK0CnApN0hR3cFwUwmGGyKisnIKNfjsn3gsP3gVNnIZvh8TiXZB7njy+wO4eKMAwzoGYeag1thyOhWNPJ0Q3bRkxM/Hf53B/+29jPuaeWP6wJaY/MtRXM4ogI1chrf6t8AL9zXB9exb6LdgDwrVOng42kKnl5B72yy8ADCxT1OcSc7F7vM38M6AlugZ7o1HvhLrB854pBVe6Fn+pK2SJEEvwaILOZJlMdxUguGGiKhEVoEas/88jb9PpUJdPHX+/BEReKyTGN4cl3gTjy/aD70E2CpkxuafF3s1wbR+LVCk0SF67g7kq7T48dkuuL+FL/KKNJi+5iT+OiGaqR5s6Ys8lRaHLmchKswTK8d3g0wGxF69iT/iruHijQLo9JJxzSRDn5l/Xu+F5n4uWLTrIrIKVHhnQCuGlwaM4aYSDDdE1FCk5hTho41n8FArPwztGFTm9VtqHUb9cBDHkrIBiP4qL9/fFEM6mO479++z+K54UcfGXo64mlkIQKwfZKuQ4UpmIZr5OuOf13oZOxJLkoRfDiXiwz/PGEOTg60Cm1/ricZeTuWW96vtF4zT+wd7iLWJrLXwItU+HApORFQLFaq1NdrvQ6+XoNHrobRRQJIkvPn7cfx7IQN/n0yBrUKOR9qXTNuv1enxysqjOJaUDTcHWywZ2xmRjT3KDRNv9muBNkFuaOLthLZBbth8KgVv/n4C17NLFix+sVcTkxFSMpkMo6Mao0OIu7GZ6t2BLSsMNgDwygPNkJpbhF9iEjEoIpDBhu4aa26IiKopM18FlVZfrRle/4i9hjd+O44PB7fB2O6hAMQU+BeKJ4lzsbdBh2D3ux5CrddLeOF/R7D/YgbeHdgKNnK5SeddO4Ucy57tgu7NvJFTqMEbvx3HtrNpUNrIseKFKHQutdJ1VWTmq3Dyek5x2W3RqZF7hWGkSKPDtZuFaOZ755FIkiThTEouwn1dYGcjv+P+1HCwWaoSDDdEdC/WHr2G99aegl6SsG5Sj3Kn8dfo9NibkAGljRzdm3qjQKVF73k7kZGvhrezEvveuR8FKh3u/2wXcm5pjMcFuTtgeKcgvNCriXHtnuNJ2ca+KLdTyGXo08IHjb2csGzfZcz684zxNcM8MNMHtERc4k3jmkedG3sgNbcI127egp1Cjq9GdUT/tv7m/BYR1Qg2SxERFdPrJSzbfwWNPB3Rt7XfXZ9Hq9Pj/fWnsPJQknHbtN+OY+3LPZCaU4TlB68iX6WFSqPH7vPpyMhXAwAWjOyAxKxC4/OMfBU2HEvGudQ85NzSwMPRFoHuDkjMKsT17Fv4akcC9iZkYMUL3bD7/A1MXBGLyv4EdbBVYErfcHy57QIAMZndjnPp0OolRDb2wAs9m0Cj0+PN309g44lkHCkOSiGeDvj2qUi0C3a76+8JUW3Fmhsiqtdm/3kGS/ddhp1Cjh3TeiPYw7Ha55AkCe/8cRKrjyRBJgMm9GqCVYeSkHNLg0faBeDfCzfKDGt2tFOgUK2DrUIGW4UchWoduoR64PCVmwj1ckRydhHUOj1+eq4rejf3QZFGhy2nU/H+ulPILdKia6gnjl/LhkqrR9dQT/i72Zcp19WsQhwv7gwMANFNvLDihSicuJ6Dv0+m4LkeYSbHpeUWYd3R68gqVOPlPs044y7VKWyWqgTDDVHD8X//XsLHG88anw/vFIzPR0Tg54NX8e3OBKh1eijkMkx9qDlGdmlU5vh8lRY6nYQl+y7jq+0XIJcB346ORP+2/lh39DpeK544DgA6hLjjgZZiFt82ga7oGe6Dqb8eMw6HbhPoihUvRCF67g7c0ogZers1MQyLLumrcuhyFp5eEmMcYdS3lS8WPx0JG0XZ/ic6vYRvdiRgwfbzcLKzwaYpPRHiWf3wRlQXsFmKiBo0vV7Cot0XMW9LPADgichg/BZ7DWuOXkOQuz2+2pFgsv8H60+jc6gnmvo4AwCyC9V4+48Txn4qBh8NbWvsnzKkQyC2n0vHn8eTMb5nGN7q3xK2twWQz0dE4GahGgcvZeG9R1rB3dEOIzoH46cDVwEAb/dvWaYTbtcwTywY2QGvrTqGiBA3fD2qU7nBBhB9bqb0DcfgDoGwVcjuqlaKqD5izQ1RPRd7NQv+bg4IqsbInpqm00uIuZQJDyc7tAq48//DtNwi7D5/Ayj120omAzqHeiLM23RocWa+Cq//ehx7zt8AADzXIwzvP9oKL6+IM66XBADjuofiya4h+M/Gs/j3QoZx7aFDl7PKDHO2s5FjyoPhmHR/M5P3kiQJObc0FS5LYLjWrAI1fFzEitLXbhbiye8Pok8LH3w8tF2Fx+UUauBib3PPC1AS1RdslqoEww01JEeuZOHxxQcQ6GaPHdP6wN5WcVfnuZJRgM2nU9ExxB1RTcS0+0cTb+Lk9RyM7BICpU3Vzlug0uLbXQn4PfYa0nJVsFPI8dNzXU2m8r/dxRv5GL5oP7ILNeW+3rmxBx6PDMbA9gE4l5KHV1bGIS1XBaWNHB8NaYsnOgdDJpPh4o18PPzFHuj0Eh5tH4CvnuwIuVwmlgUoXm3a29nO2PG3sZcjvhnVCa0CXCCTyTgzLpGVMdxUguGGGpIJ/zuCf86IppXpA1rixd5N73hMcvYtrD16HUcTb0KSgMwCtXEGW5kMeOX+ZrBVyPHFtvPQS8CgiEB8ObLDHWsYzqXm4uUVcbh0owAAYCOXQauX4GJvg99f6o4W/i5Qa/XYfjYNO+PT0djLCb2b++Cln2Nx7eYthHo5GpuNANEf5vCVLOiLf4PZ28qh0UnQ6SU09XHCwtGdygzT/vVIEi6k5WFavxYmgWzloURMXyPmhHG0U2BYxyC8M6AlXOzZ4ZYqcW4jcD0WuH8GIOecPDWN4aYSDDd0N/R6CXpJgk6SsD8hE7/HXUNGngozB7VB60Dxc5RXpMHGEynYcDwZjTwd8fHQthX2lbhXkiSV6auh1YkOqHKZDHK5DFcyCnD/57uMw4jdHGyxa1ofLD94FeuPXYdOL0Ehl6FHM28M7RiEpKxC/B57DXsTMsoMPZbLgFYBrjidnGuy3bAG0LjuofB3s8ffJ1OQWzxvS4inI4Z1DEITH2esP3Ydv8QkQqXVw89VifcfbY1ezX3w3I+HceTqTTgrbeDtbIfMAjXyyllMsbGXI/6Y2B3ezkqT7em5RVh79Dp+i72GhOLJ8IZ1DMLHQ9vCSVn1LoWSJOG3I9egkMvQv61/tY6lBkqrAuaFA6ocYMx6oEkfa5eo3mO4qQTDTcOm0uqQX6SFV6mbZGa+Cs72NmWaVvR6CQcvZ+L32GvYfCoVhWpdmfMpbeR49cFwJKTnY9OpFBRp9MbXRnYOwSfD25U7a2vOLQ1Sc4rKLaNcBoR5OxmDUaFaC7VWD3dHO0iShCV7L+PbXRcxJroxXuvbHIVqLSb+HCf6pEDMdPt2/5Y4n5aH/x24il7NfZBSPBOul5MIEHfSNcwT/dv4w0mpgI1cjh7NvOHvZo/1x67j3TUnoZMkfDSkrRhp9OvxO57PoFdzH3wxIsL4/c8uVGPEdwdwPi3fuI+fqxID2gbgTHIuDl3JgrezHX5/qTtCvSuetl+SJJy4loN8lRbdm3px2n6qefGbgZUjxeN+c4Hol61bngaA4aYSDDe1x/XsW0jPLULEbVPO6/QSjlzJQiMvRwS4Vb8TrFanx9GkbLQLcjP2MTmXmoufD17FhmPJyC3SokOIO3o398GeCzdwNDEbrvY2GNwhEN2aeEEuk+Fcah7+iL1m0qnUwNPJDkM6BOJKRgF2xt8wea2ZrzN6hnvjp/1XoC+u0ega5gmljRzdmnjBSWmDX48k4YP1p0yC0O28nZUY0iEQWQVqbDqVApVWjx5NvWGjkGFXqfec8Ugr7L+YiR3n0is814oXolCg0mLC8lgAgJOdAjMebY3mfs64WaDBhuPJ2Hw6FT7OSjweGYzhnYLRyKviUTc3C9TQS5IxoPyw5xLmbjqLTo08MDwyGM39nKGXgAMXRTBMzSnCQ6398HhkMHo39ynTfKXW6nEqOQeSJMFOoUDrQFdj/5aUnFtwsFVU2mGXyCrWvAicWCUedxoLDP5KPE4+Bng2Aex5fzE3hptKMNzUDul5Rej3xR7cLNQg2MMBA9sFwFlpg+xCDTaeTEZargrOSht8MrwdHm0fWOXz6vQSJv8iRsU093PGwqc6Yce5dHy6JR46ffV/1F2UNng0IhCPRwYZ+3u42NtCIZdBr5fww7+XsOpwEno088LjkSGICHaDTCbDipireG/tKZNzOdop0DrA1ThDrJuDLWwVZWsYbql1KCinlsjATiHH/S19TIYpK23kWPZsV7QKcMHvsdfwyaZz0OoltPR3waYpPQEA7649iWs3b2HW4DYmfVcAUfMB4K5rPLQ6fblNcPd6XqJaSasC5jUDVMXNtCFRwPP/ABe2ASuGAx2eBoYutG4Z6yGGm0ow3FifJEl4cXmssaNreWwVMmh04kfz8chgPNcjzNi3pbLzfvjnGSzbf8W4zdAnBBCToY3rHobmfs7YcDwZhy5noUuoJ4Z0CMSF9Hz8EXcN126Kmho3B1s82j4A/dr43/UIo5WHErHu6HVIAFJzipCYVQhANDu98XALTOzdtNxOuBqdHrvib2DjiWS42NvisU5B8HZW4o+4azibkotXHghHm0BXvL/+FH4+mAi5DFj8dCQeblOyPlBc4k0sP3AVz/UI4/T6ROZmaJJS2AE6NaB0A965Cmx6Gzj0HeARCkypenMtVQ3DTSUYbixHkiT8cigRfx1Pwf0tfTC0YxB8XUS/jSmrjsFWIcOvL0YjMavQOOrFRi5D96Ze6N3cF9/svICFOy8az9cuyA1zhrUz3qw1Oj32nL+BNXHXcSWzAFqdhPi0PADA7CFtsOV0KvYlZMLORo5Zg9pgVNcQq9UgSJKEuMSb2HomHX1b+VZ7Beby6PQSlh+4giY+zujV3McMpSSiKln7EnB8JRA5DohbDkg6YOo5YNUoIPkoABnwbjJgx0kVzYnhphIMN5aRW6TB9D9OYuPJFOM2mUw0n6i1euglYOpDzfHqg+GVnifmUiZ+OnAF286kQ63Tw04hx2sPheNmgRprjyYjI19V5pj3BrbC+F5NoNNL2HI6Fc39XNDM17mcsxNRvbPjP8DptcAzawH3EPOdN/UU8MsIoDAL0BYBkIBnNwEbXgUyLwBPrgR+fQbQF4/2m7AbCOxgvvevaQWZwE+DgKb3A/3+U/3jE7YDf70ODP4aaNLb/OUDl18gKzqbkotfYhKx4Xgycm5pYCOX4ZnoxjielI24xGxjJ9oOIe6Y2OfOc65ENfFCVBMvZOar8O7ak9hyOg2fbo43vu7lZIehHYPQo5noCBzg5oAW/i4AxNT0A9sF1MyFElHtc3EHsOdT8Tjuf8AD75nnvFq1qK3JvV6yzbcNENIN8Gkhws3xlSXBBgBunKtb4eb8JiD9tPhq1A1oNah6x//7OZB9Fdj7RY2Fm+pguCGz2X42DROWxxo77oZ6OeKLkR3QsZEHACAjX4Wi4gUD/V3tqzUHjJezEoufjsSP+65g8e6L6NjIHY9HhqBPC58y6/kQUQNUlCtqUQzOrAPuf1dUGd+rvfOBtJOAgycw7i9A6QK4BIiJ+3xbAef+AuI3mR5z49y9v68lXTtc8viv14HGPQDHKjaf56UCV/eLx5f3iFogp4pnHbcEhhsyi6OJNzHplzjo9BJ6N/fB+J5NEN3Uy2TK+tsnYKsumUyG5+4Lw3P3hd1rcYmoLstPB2IWiyHYHo3Ftq3vAzlJgHsjcbPNOA+knwW8mgIx34mbdXDknc995EcgpVRnYEkPHFshHg+cB/i1Md3fp6X4V1+8PIh7IyA7EUivRrg5vwXIugR0fVEEpls3RU2Iqnj+p5aPAOEPVf18BgWZwMFvgY6jxfD0yiQVhxsbB6DgBvD3m8DjS8S2vFRg/9eAugCQyYH2I4FGUSXHnv0TxoXfJJ0Ie5Fjq19eM2K4obu28UQKVh1OhFqrx9mUXBRp9Ojd3Af/N7Yza1OIqGbo9cDvzwFX/gUubAXG7xCPY5eJ14d8CxxYKJpZTq8Vo5n2LQB8WwMvH6j83Gf/BP56rfzXWg0C2g4vu90Qbgw6PgPs/E/Va25STwGrRotwJFMAUROAP6cAZ9aX7HPyN+DNBMC2GvN+SRKwZjxwcbtYJuLF3YBNBX9gFuUC6WfE4yd+BFY9BZz6XdR8eTUFds0t+f4CQMI2MRrMUCt2eq34160RkJMonjPcUF1TpNFh9l9n8EtMosn2dkFu+HZ0JwYbIqo5R5aIMAMAqSeA7bNLbq5dJwBhPYHcZBFuYn8ECjPFa+lnRI2Ig0f55y3MEs0xgAgy/u1LXrOxFzfr8pq4vMNFKJF0gNwGiHhShJubVwB1YeUjpnQaYN3EklqfbTMBTYEINnIboMdrwNHlQH6a6LDb6tGqfpfEcRe3i8c3zgK7/ws8+EH5+16PBSCJWqcWA8RSEhd3iO9rj9eAMxvEfl1eAI6tFH1rkuOAoEjTJqkh3wD/G1wrmqYYbqhaJEnCc8sOY//FTMhkwISeTdA+2B12NnL0DPe+6zlhiKiBuHkFcA0GFMW3n1vZwI34yo4oocoDts4Uj8P7ARe2APuLZwZ2bww8WPxai/5iDpoC0xnEcT0WaNa3/HP//abY36clMHxJxbUct7NRiiafzAuAfzsREBy9RKjKOF95p+K9C0RAs3cHvJsD1w4B22aJ13q+IWpONLeAgwtF0CgdbiQJSDstmopupykAthR3pm7eHzi/WbxXy0eBoE5iu1YlgolH45L+NsFdxb9tholwc2ad2P9Wlrim/v8V13V6LXB6nQg3hiapoM6iI7F/OyD1pNWbphhuqFr+OZOG/Rcz4WCrwHfPRHJ+FSKquoOLgc1vA/e9DvSdBeh1wPd9gJuXq3eexj2AUavE0Otzf4ltQxYCyuIpH+zdgKYPitobJ18gsKMIQkmHyw83V/aJZhiZAhj6bdWDjYFhxJQhHPi0BK7uE6GtonCTekrUpgCiL09wF2BRd0BTKEZi9ZwmXmszTISb85tF0DE0TcUsBja/U3m5grsAT/4imqdO/QGse1k0T8ltgZVPAhd3imaopENi/5Di8rd8FPjzNRFS/p0vtrUaJAJpm2Ei3JxZJ8Jk3E/F5RxaUt7Uk1ZvmmK4oUrl3NLg18NJ6NHMG839nDFvi/gL6/n7whhsiKjqMi6IZhcAOLoCeOB90Zxx87K42boFV+08jp4igMjlwKNfAOp80YwS1tN0v15vilqGB98XIePCFlEzUp6Tv4p/O4wStRHVFT0JKMoBol4Uz43h5mz5++s0wPqXRXNUi0eAdk+IJq8h34gAOOhLwKZ4PbXgzqKmK/daSdNUxoWSGh63RoC8nBpzB3dg2HfitQHzRFORoXnKNVDUzADAX1NFyAREGALE97hJb7GPoQmw9VDxb7OHAFtH0Wl6zXgRZJRuQLsRJfvt+Rxw8hH9o+TW6abAcEMVOp6UjUm/xOHazVuwVcjQt5UfEtLz4e5oiwm979DznojIQK8TtQbaIvG8IF0EmzPrxPP2I+9uLSZnX2DM+vJfC44EXtgqHtsXL0FyLbbsDVenLW5aAdD28eqXAQAadxdDxA0MnYwram7bu0CMyLJ3Bx6dX9KXp+3wsp2WZTKg9RBRe3NmnegTY/heNn0AeHrNnYe7O3kBj8wXNV17F5TUTCldRZMTIPoV+bUtOab10JIA5OgFhBaHRztHoHm/4qapNWJb/7mAi5947NUUeOsSYGtfeZlqGMMNmZAkCcev5eD32CSsPpwEjU6Co50ChWodNp1KBQBM6tMMrva21i1oQQawZoL4pdJr2t2fJzcZWPsi0GIg0G1i+ftkJ4rRGYaOiebS8hHg4Y/F4/jNwL4vRfW0f1sxBHTNBMCrCfDQR+aZq4Pobt28Kv4PGG6E4f3EDa2yn0tJEs0mF/4RNRU5SYCdixhCnLBNNJOc2yj2NTRp1BTfNqK2QZUDZMSLuWkMrvwr/m+XvoHf8/sVh5uEbcBXHcu+nl08GGPgPMDFv+zrtzM0TZ1eByQeLPleDvqq6r8bWg8G2jwmAommEGjUXXyG//egmHwwsGNJbREgmqH+el10lDY0SZUuj6ETd/jDQIenTN/LysEGYLihUlJzivDa6qM4eCnLuK1/G3/8d3h7/BF3DXM3nUWIhyOeiW5sxVIW2/iGGAlwcbuoRm56f/XPIUnA+smiuvbKXtEhLqSL6T56vfgrqfQEV+ay/2sxr4V7CLDjYzFJ2B8viDbxbbOA+OJf/AEdgHZ3+RclkTmcXgNcP1LyPGaR+H/X/omKjznxq+gXUtqATwBnf3HTP7pc3FTt3YCwGp7RVmEDBHYCru4V/UtKhxtD7dHtN/B74d9e1IqocsX8NeVpNUg0R1VFcGfAu4UIZjlJYlv/udVfXmLgZ0DiAdEJecg3opalz3Rgx0eiRqg0R08ROk+vE6ucl9bsIfE56jXAowtq5R9fXFuKIEkStp1Nx9t/nEBWgRpKGzkGtPXH45Eh6NHMy7jYZHahGgq5DC7WrrU5vRb4bVzJc7cQMX+F0qV654lbDmyYXPLcKxx46V/TuSQO/58IUjYOwMjl4heWOWx5V9wsHv6P+KXydaeS1wyjQAwcPIFJMaIKnsga1rwInFgFdH5e/P848I0YUv1yTElzRGl5qcDCKKAoG+j+CtByEGDvKkKFTgPMayZeA8SN826apKpr2yyxNEDHZ8SNHRBNUp83FzU3z6y7uz+SKpKfDmRV0FFabiNGFZWuKbmTopySiQEN38u7UZglmgmdS/WZvHlF/B69ve+OpkjU1rkGln8eoOqzGJsB15aiKpEkCd/vuYQVMYlIzCoEALQOcMW3ozsh1NupzP7ujtX4j1hTCjJE2ACAbpPESInsq8A/7wODFtz5+PRzwLk/RY3MgeJfcD3fEB0cMy+ImpOACLFd0gP7ioeZ9p11dzOEViTiSRFuzqwr6YfgEgDkpZQEm47PAMnHRI3Ob+NEp8nyNH1A/GVHZC4pJ8QNr/Vg8dwwIV3T+8XQ4st7xBDm38aVHwgu7hThJSBCjKhRlPqDSGErRuMc+1k8r+kmKQNDZ9mLO4DdxetP5aeZv0nKwNnXvH+Q2LuZzgp8t8oLIx6h5e9raw/YlhNsKjpPLcKamwbstyNJePP3EwAAJzsFRnVthGn9WtTuuWq2fSjWefFtA0zYBSQdFCvZAsCUEyVTsZfn1k3g22gRIAyCuwDPbRH9AlY+Wf5xjboD4zaat9d/XhrweQsAUsmsnoO+Ai7vFn0RDLVRWZeBH+43XZDvdnbOwMT9lV87UVVlJ4n/J+o84MU9gF87YG6Q6KcxORbwbiaGMX/fu/KfS7mtaGK9fbkCQDRL/TxcdKiddqF6NRh3K/8G8Fk4jMsElBY5ToxQolqNNTdUJRuOJwMAxkQ3xjsDWsLRrpb/OEhSSSe2Xm+IX4hhvcRfXFf+FbUgPaZUfPzmd0WwcW8k5sCwUYohnHKFaBoa9BWQfNT0GBt7oMer5h/O6OInOkNf3SeCjUwh/pptMxTwaiZGKihdgID2wBM/iZtBeRIPiuGdG14Ro0ZqYds31SGSBPz5qgg2gJj/Rekqgo1CWfIXvn9bYMT/xPIHFQl/uPxgA4j/fwM/E6OKLBFsANEMM+w70eekNDsn0XRG9Uotv5tRTckqUGP/RTH657keYbUv2GjVInSUbgNOOS7mxLBxEP1SDNoMFeHm9LqKw835LcDxXwDIxOyjhsmqSosca9lJp1oPFeEGEHNKGKYqv/9d0/1aPVrxtOuZF4FFPUSNz8FvRSfF2sLZv/Ibl1YlmgUA0a/IMAEbIPoXFOWY7u/oJW5Et9MUiaHF5ZHbiOY+S4Y+zS0Rii35nrriGpSqdIjV64Hc6wAkwNbJdIr8uP+VDP8FxLwwhgUXvcNNz9/yEfF1N2QyoOv4uzv2XkSMFF9U79WyOxpZyj+nU6HTS2gT6Fpu/xqryksFFnYV7fVPry35hWoY1RD+kOmNsNVgMXV6cpwYsnp788ytm2IhOkDU1JQXbKyh9WBg01sApJIJsqrLqynQd6YYcrvlXfFVW3iFAy8fLP+GqykCFnYpGRJr6wRMOihq1ZKPlQxPLU3pCkw+bDp0tigX+KZzSUgqT+fnxGRvlpByAlj2KNCkFzDyZ8u8p7oQWNxDfA8n7LpzwFn1lJi512DkzyIU37oJ/DNDbGsxEIj/G7h2pKQP2u0LRBLVYlzhsIHaeFL0OxnYLsDKJSlHwnbxV/vlPcCBr8U2SRI1M0DZDojOvmI6dqAkAJW25T3RHOXVDHhgRg0V+i64+IsZTYO73Funyq4vipuTjX3t+QJEB23DSsO3Sz5aEmxkcrEWjqGJI/5vEWxkilLnk4lhtYYF+gwSDxYHG1nF5TiyFLhQQbOeOWnVYhFEVQ5w9i8xh5IlJGwVw43TTpbUBFYk51pJsJEXd/I98qP499xG8T32bgEMWyw+l5wk4NIu8TrDDdUhrLlpgEo3ST1SG8NN6SnSd84Bmg8AdKriJil70yYpg9ZDym+aOr8FOLYCgAwY8q3pMO/aYMB/7/0ccrnlagmq6n9DxE3x2iHRb+h2hs+45aNiSOueeaKWoMvzJXMKDfhvSdPF+knA0Z/Lzvhq2Lf9SOCx78q+z6Z3xJwsf74qOmgbZqqtCf9+DqSdKn4iiZWUu71Uc+9nYAj9gOiT1qSSOWMMqzs36g4M/hr4JlI0aRZmlZyn3ePi++TbRgQmQ7jxZbihuoPhpgH6I/Za7W2SAsRNDhAL3hWkAz8/VvJXePjDpk1SBq2Km3iS44AfBwIo7u+Qflr8Gz3JPMMoqWqCuxaHmyNAlxfKvm5chbgL4Nu6eNsh0R/kWqx4Xrr50Kd4To/b1+oxhKTbJ180ePADMbQ+6xLww4OAc6k5WRzcgUc+r9oMsRU5+xdw6DtR7qSDYltYL1HreGZd+eGmKEes55MnZvxGYAcxC/WdOq0fXw1c2gn0/0SUHRBNUudLzYl09k/RUbeipilDh/w2Q8WoJ792IsAcWyHODZQ0kYZ0Ea8ZGD4DojqA4aYBUWv1+O/mc1iyV0wsNaxjkJVLVA5VXklTxlOrgeVDizs/FmtfQWdAFz+gyf1ixuLbq+ZrW3NUQ2AIJkmHyr4mSWJ1ZsN+huaOzAQxkkWVI/qP+JYaaVPeWj16XUkQCq6gH5Wdo6ixWzZQNJNlXjB9PSAC6P1W9a7N4OZVsXSHOr9kW6vBInx80Vo0meUml50Abcu7YgVqg6t7xSikyjrYpp4StVd6jXg+rHjm34StoknPrZEY4VSYIX7+y6u9yblWHAZlopwA0GaICDA754imQN82gE9z8VpwV9GkBwAKu4rnQiGqhRhuGghJkvDi8iPYGX8DAPDCfWEY2z3UuoUqz/VYMXmeWyMgqJPoIJlyXLx2p4m2hv+fWEZB0pXaKBNDrmtbc1R9Z5hUMOsiUJBpOiInJwnITxUjmQI7is/GK1wEj4Pfin2COpnWPviWCkBatRiFdeOcuKHbOpXU/pSncTQwfqdo1jS4tAuIXXb3y2pIkpjdWp0vQkD0yyIANH1AXE9IFJAUU7Zp6sJW0bwGmVhXKPuqWIZj60zRUb68AKHTiL48hmBzfKWoXWnRv1Q/tCHArWyxpEFFTVPGJqlowLW4Obr1MLH0h6aw+DxDS/YPLlUb5t3cfEsTEFkAf1obiF8OJWJn/A3Y28rx1ZMd8XCbe6iKr0mGv+gNN0fPJiVDUe/E0bNkRlWyLgcPcUPMOC8CRIv+Ja8ZanP825WEzpCuItwYFlIMvq2ZyTVILBSozhOBybdVSTC5PQiVJ7CD+DJwa1QSbiTJdNh2RkLZuVBslGJmXvviicOOLBVNTzYOohbFq6np/q2HinBzdHmp4esSsHOueNhtoqip0euB63GitmXNi0DH29bwAURtS+oJ8T1t8YiY2ffPKUDBeyVNUq2HAUU3xfud3SDWfbrd0XJmBPZuJlaCNvQVKj1qz6upGKJ/KwvwaVH2fES1GMNNA3DtZiHmbBR9Fd7s17L2BhugVB+KWjJcm+5ecNficHPINNwY+9uU+oyDuxR3/C6ePfb2z18mEzfY60dEjY1vK9Omrerybyf6cd26KWqDvMPFdr1ezHidV85Ip87PA4/OF81h22eLbX1nlg02gOjgvmW6CA2l1y8DRFh/4H3xWC4X6xx921302TH02ynPgHlivqOkGBEENxRPPGeo5dRrRQAqzCz7nkalmqQM2gwV5fRtXdIkBYjveUhX4PzmymvGiGohhpt6TqeX8PYfJ1Cg1qFzYw+Mq41NUQaSVP6Nj+qmkC6iluH2fjdJ5QTY2wPK7TU3gGiaun5ErA/WBiVB+G5+VmzsxGrrSQdFeQzhJjNBBBtDExMgmnuSDoqaGkD0CSvKFstedJ1Q/vndgoABn5pOiAeIdZV6vSn6Ahl4NhFNqsdWiCbZ8gR1FqOYZDLgiWXA7v8COrUYLt/5ObFdYStm2T72C8pdYgAQMwMbmqQMur4oOjeXt0L1gzMBt2Axio2oDmG4qcP0xcFFLpNhzmPtoJCbzogqSRJm/3ka+xIyobSR49PH25fZxyokSfz1e7usi+IvaYVS/GVNdZshoFyPE7MRyxRikdDU4hE4pRf79GlZ0uzkEQY4eZc9n7FT8TkxdDnjfNnzVEdIFxFarh0GOo4W24xNXZ1Fh3ZAvNenYaK2pDCr1D6RZVdRLi3qRfFVFZXNQn07/7ZihfrytB5c/aZZe1cxaqw8fq0rfo2oFmO4qcN2xqfjt9hrAIBwP2e80LMJJElCYlYhijR6bD6Vip8OXIVMBnw+IgJNfMoZQm1phVnA931ER8qKBHaw3HozVHNKB5aPb1sd2ckXcC81k7RcIZpWLu+uuJnJOBz8XMmIOM8m5QehqjDU+JTuVGysDSoVmBw9Ac+mInxfj7235jAisgiGmzrMMKQbAOZtiUfHRh5YuDMBO86ZrrMz45HWeLR9BcvWW9rptZUHG8jKrx6nukeuANqPAI4sKfta+xFl117q+IxoIooYVf75So+YMiwT0Lx/+ftWhSGcpJ8RUxAoXSoOLiFdRbhJOnRvzWFEZBEMN3XIjTwVtpxORb82/kjPK8L+i5lQyGVoH+yGo4nZGL5ITE1vI5fB3dEWCrkMY6JD8fx9YVYueSmG5RHuf6/8yd0UtuImQ/XDo/PFRHql+5LIFeXPFNz+CfFVkdIjpm5eAVyDgT7T775sLv6iM25OoqiRCexUMsfS7cEluIsYgn1hiwhXwN03hxFRjWO4qSP2JWRgyqpjyMhXYcG2C2hSPLPwwHYBeGdAS/T7Yg/yVVqEeTth4VOd0DrQ1colLkf+DTEPDSD+cnf0tG55yDIMs+neq9IjpgBg8JclQ7PvVnBnEW6SioeEQxKLd7r4me5nqMkxzLnk1Yw/v0S1GMNNLSZJEo4mZePXw0lYfSQJkgTYKeTIyFchI18FAHj+vjAEuTvgp+e6IuZyJp7p1hgu9rZWLnkFzm4Qf8EHdOBsp3R3gjqJcNPxGaBZ33s/X+PuwOk1Ys4bVY7YVl5zk29rMTrKMBsxm6SIajWGm1pKpdVh7NJDOHgpy7htVNcQvN2/JT7ZdA6rDiehZ7g3OoS4AwAiG3sgsrGHlUpbRYYmqTbDrFoMqsPuf1cEkhaPmOd8HZ4CDiwUsxfv/0ZsK6+jsLHDc/Fw8IrWsiKiWoHhppb6ctsFHLyUBaWNHI+0C8CILiHo1kRMYf/J8PZ4sXdT+LvaW7mU1VC6Sar0DKlE1eHgYd5wbOcEDFko1p4yzA1TUV+a4C4l4YY1N0S1GsNNLXQ8KRuLd18EAHz5ZAf0bxtQZp+w2riad2Vil7FJimqn0B5iIrtD34lZi/0qmGPJEGjsnMUMyURUazHc1DIqrQ5v/n4cegkYFBFYbrCpc9LPAXs+FY+7vWzdshCVp+9MoChHLORZ0RxLTR8Qaz8Fda588j4isjqGm1pmTdx1nE/Lh5eTHT4c3Mbaxbl3Oq1Y0VinBsL7iVFSRLWNnRPw2HeV72NjJ5qwiKjWY7ipRfR6yTgx38Q+TeHpVItm6VXlAb88CWTEm263cwKGL6m4n8KBr4HkODGvyaAvy07cRkREZGZyaxeASuy+cAMJ6flwVtpgZJcQaxfH1D/vA1f3AgU3TL9uXgHWjAfUhWWPST8H7JwjHvf/pOyCfURERDWANTe1yNLiWpuRXUJq11w1F3cCsT+Kx48vLVnAUKcGVj4FZF0CdnwM9J9TcoxOC6x/uaQ5qqIp9YmIiMyM4aaWOJeai38vZEAuA8Z1D7V8AY6tLJl6/nan1oh/u7wAtB1u+trgr4AVjwMHvwX0WsBGKbbfvCKmtFe6AYMWsDmKiIgshuGmllgTdx0A0L+tP0I8HS375mfWA+teqnwf90ZA3w/Lbg9/COjwNHDsZzGU9nYDPgFca8minURE1CAw3NQSMZcyAQD92vhb9o0LMoGNb4jHzfsD3uFl95EpRLOS0rn8cwz4L+DRGFDlmm73bMrmKCIisjiGm1ogX6XFqWQRDLqE1sBifEW5gExefjjZ9KboGOzTChjxv5JmpepQOgO937r3chIREZkBR0vVAnFXb0KnlxDs4YBAdwfznjznOvBVR+DbaKAwy/S1MxuAU3+Impmh395dsCEiIqplGG5qgUOXRejoGmbmWhtJAv58FSjMAHISgc3TS14ryAQ2ThWP73tNLApIRERUD1g93CxcuBChoaGwt7dHVFQUDh06VOn+CxYsQIsWLeDg4ICQkBC8/vrrKCoqslBpa4Yh3ESZO9wcWwEkbAMUdqJZ6sQqIH6TeG3TWyXNUb3fNu/7EhERWZFV+9ysXr0aU6dOxeLFixEVFYUFCxagX79+iI+Ph6+vb5n9f/nlF7zzzjtYunQpunfvjvPnz2PcuHGQyWSYP3++Fa7g3hVpdDiWlA0A6BrmZb4T51wvqam5/z1Re7P/a2DNBDHyKe0Um6OIiKhesmrNzfz58zF+/Hg8++yzaN26NRYvXgxHR0csXbq03P3379+PHj164KmnnkJoaCgefvhhjBo16o61PbXZ8aRsqHV6+LgoEeplpiHghuYoVa5Y5K/7KyLgeLcQ29JOif3ue53NUUREVO9YreZGrVYjNjYW06eX9AORy+Xo27cvDhw4UO4x3bt3x88//4xDhw6ha9euuHTpEv7++28888wzFb6PSqWCSqUyPs/Nza1wX2so3d9GZq6J7ozNUUpRMyNXAHIH4LnNYp0nCYCtA9Ao2jzvR0REVItYLdxkZGRAp9PBz8/PZLufnx/OnTtX7jFPPfUUMjIycN9990GSJGi1Wrz00kt49913K3yfuXPn4sMPy5l8rpY4dKU43JhrCLhJc9S7gE+LktccPYFmfc3zPkRERLWU1TsUV8euXbswZ84cfPvtt4iLi8OaNWuwceNGfPTRRxUeM336dOTk5Bi/kpKSLFjiykmShOPF/W0iG3uY56QHvilujooEoieb55xERER1iNVqbry9vaFQKJCWlmayPS0tDf7+5c/S+/777+OZZ57BCy+8AABo164dCgoKMGHCBLz33nuQy8tmNaVSCaWydnaYvZpZiNwiLewUcjT3czHTSfeLf7u9DCg4RyMRETU8Vqu5sbOzQ2RkJLZv327cptfrsX37dkRHl98XpLCwsEyAUSgUAEQtSF1z4noOAKBVoCvsbMzwUagLSzoLh3S99/MRERHVQVb9037q1KkYO3YsOnfujK5du2LBggUoKCjAs88+CwAYM2YMgoKCMHfuXADAoEGDMH/+fHTs2BFRUVFISEjA+++/j0GDBhlDTl1yorhJqn2Qm3lOmHJMrMzt7A+4hZjnnERERHWMVcPNyJEjcePGDXzwwQdITU1Fhw4dsHnzZmMn48TERJOamhkzZkAmk2HGjBm4fv06fHx8MGjQIPznP/+x1iXcE0PNTftgM4WbpOIh8SFdAHONvCIiIqpjZFJdbM+5B7m5uXBzc0NOTg5cXV2tVg6dXkK7WVtQqNZhy2u90MLfDH1uVo0Gzv0FPPQR0OPVez8fERFRLVGd+3edGi1Vn1y6kY9CtQ4Otgo08y1nte7qkqRSNTfsb0NERA0Xw42VHL8mmqTaBrlCITdDE1L2VaAgHZDbAAER934+IiKiOorhxkpOXssGALQPdjfPCZMOi3/924vZh4mIiBoohhsruavOxHodcGUfoNOUfe0am6SIiIgAhhur0OklnEkWa1y1q84w8L9eA5YNBP69bQV0zS3g/GbxOLiLeQpJRERURzHcWEFy9i2otHrYKeRo7OVUtYMubAXi/iceH18pOhAb7PgYyE4EXAKA8IfNX2AiIqI6hOHGCq5mFgIAQjwdqtaZuCgH2FBqaPfNy0DqCfE4MQY4sFA8HvQlYG+94e1ERES1ARcfsoIrmQUAgNDKam0kCVg5Cri0C5B0gE4NeDYBPJsCCVuB02sB7+bA+pcBSEDEU0DzfhYpPxERUW3GcGMFV4vDTaVNUjnXgPObSp4r7IAh3wJ5ycXhZp3oWJyZIJqj+s+p2UITERHVEQw3VnCluFkq1Nux4p1unBP/eoUDz6wBlK6Agzugygds7EXT1IFvxD6DvgQcPGq20ERERHUE+9xYQZVqbgzhxq8N4N5IBBsAUDoD4Q+V7MfmKCIiIhMMNxam10tIzCquufGqpOYmvTjc+LYq+1rbx8W/bI4iIiIqg81SFpaep0KRRg+FXIZA90pmEjbU3Pi0KPta6yHA0MViThs2RxEREZlguLEww0ipYA8H2CoqqDiTJOBGvHjsU07NjUwGdBhVQyUkIiKq29gsZWFVHimlzhOLYHo2sVDJiIiI6geGGwszjpSqrL+NodbGqxlgY2eBUhEREdUfDDcWVrWRUmfFv+X1tyEiIqJKMdxY2JWMqtTcGDoTl9PfhoiIiCrFcGNBkiRVrebGOAy8pQVKRUREVL8w3FhQZoEaBWodZDKxaGa5TEZKMdwQERFVF8ONBRlqbQLdHKC0UZS/U+71UiOlmlqwdERERPUDw40FpeaoAAABbvYV75R2Wvzr2ZQjpYiIiO4Cw40FpecVAQB8XZUV73TtsPg3qJMFSkRERFT/MNxYUHqeqLnxdamk5ibpkPg3uIsFSkRERFT/MNxYUFruHWpu9Drgepx4HNLVQqUiIiKqXxhuLOjGnWpubpwTnYntnAHf1hYsGRERUf3BcGNB6bmGcFNBzY2hSSqoEyCvYDQVERERVYrhxoLu2KHY0Jk4mE1SREREd4vhxkJUWh1uFmoAAH4VNUsZam7Y34aIiOiuMdxYiKG/jZ1CDndH27I7FGYBmRfE46DOFiwZERFR/WJj7QI0FIZh4D4uSshkMrF+lKEZCgAyE8S/nk0BJy8rlJCIiKh+YLixEENnYh8XpRjy/WN/4NbNsjuySYqIiOieMNxYyI3izsR+rkogP00EG5kcCH+4ZCdbB+C+161UQiIiovqB4cZC0nJLzXGTmyw2ugQCT622YqmIiIjqH3YothDjMHAXJZBzTWx0DbRiiYiIiOonhhsLMa4r5aosqblxC7JiiYiIiOonhhsLMc5O7GoP5F4XG10ZboiIiMyN4cZCTJqlGG6IiIhqDMONBWh1emQWqAHc1qGYfW6IiIjMjuHGAjLy1ZAkQCGXwcvJDsgprrlxC7ZuwYiIiOohhhsLMDRJ+TgrIYceyEsRL7DmhoiIyOwYbizAOMeNqxLITwckHSBTAM5+Vi4ZERFR/cNwYwHldiZ2CQDkCiuWioiIqH5iuLGAjDzRmdjHZKQUm6SIiIhqAsONBeSrNAAAF3vbUp2JOQyciIioJjDcWEC+SgcAcFbacI4bIiKiGsZwYwH5Ki0AwElpU2qOG4YbIiKimsBwYwEFxeHGWalgnxsiIqIaxnBjAfnGcGPLmhsiIqIaxnBjAflFxc1StiiZwI8diomIiGoEw40FFKhFuPGQsgG9lhP4ERER1SCGGwsw1Ny4adLFBk7gR0REVGOqHW5CQ0Mxe/ZsJCYm1kR56iVDnxuX/Mtig2eYFUtDRERUv1U73Lz22mtYs2YNmjRpgoceegirVq2CSqWqibLVCxqdHiqtHgDglJsgNvq0tGKJiIiI6re7CjfHjh3DoUOH0KpVK7zyyisICAjA5MmTERcXVxNlrNMMw8ABwC7rvHjg08JKpSEiIqr/7rrPTadOnfDVV18hOTkZM2fOxP/93/+hS5cu6NChA5YuXQpJksxZzjrL0CRlZyOH/MY5sdG3lRVLREREVL/Z3O2BGo0Ga9euxY8//oitW7eiW7dueP7553Ht2jW8++672LZtG3755RdzlrVOKiheesHHTgtkF/dTYrMUERFRjal2uImLi8OPP/6IlStXQi6XY8yYMfjiiy/QsmXJDXvYsGHo0qWLWQtaVxkWzWxllwoUSYCjN+DkbeVSERER1V/VDjddunTBQw89hEWLFmHo0KGwtbUts09YWBiefPJJsxSwrjMsmtlCXjwzMZukiIiIalS1w82lS5fQuHHjSvdxcnLCjz/+eNeFqk8Mc9yEy66JDexMTEREVKOq3aE4PT0dMTExZbbHxMTgyJEjZilUfWIYLRWqZ38bIiIiS6h2uJk0aRKSkpLKbL9+/TomTZpklkLVJ4bRUkHa4nDDZikiIqIaVe1wc+bMGXTq1KnM9o4dO+LMmTNmKVR9kq/Swh4qeGmKF8xkzQ0REVGNqna4USqVSEtLK7M9JSUFNjZ3PbK83ipQadFMdh1ycKQUERGRJVQ73Dz88MOYPn06cnJyjNuys7Px7rvv4qGHHjJr4eqDfJUW4bLr4glrbYiIiGpctataPvvsM/Tq1QuNGzdGx44dAQDHjh2Dn58fli9fbvYC1nX5Ki3C5MU1XV5NrVsYIiKiBqDa4SYoKAgnTpzAihUrcPz4cTg4OODZZ5/FqFGjyp3zpqErUGnhglviiYOHdQtDRETUANxVJxknJydMmDDB3GWpl/KKtHA2hBuli3ULQ0RE1ADcdQ/gM2fOIDExEWq12mT74MGD77lQ9UmBWgtnWaF4Yu9m3cIQERE1AHc1Q/GwYcNw8uRJyGQy4+rfMpkMAKDT6apdiIULF2LevHlITU1FREQEvv76a3Tt2rXcffv06YPdu3eX2T5w4EBs3Lix2u9d0wpUupJmKdbcEBER1bhqj5aaMmUKwsLCkJ6eDkdHR5w+fRp79uxB586dsWvXrmoXYPXq1Zg6dSpmzpyJuLg4REREoF+/fkhPTy93/zVr1iAlJcX4derUKSgUCjzxxBPVfm9LyCvSwkXGcENERGQp1Q43Bw4cwOzZs+Ht7Q25XA65XI777rsPc+fOxauvvlrtAsyfPx/jx4/Hs88+i9atW2Px4sVwdHTE0qVLy93f09MT/v7+xq+tW7fC0dGx1oabAhX73BAREVlStcONTqeDi4u4SXt7eyM5Wax23bhxY8THx1frXGq1GrGxsejbt29JgeRy9O3bFwcOHKjSOZYsWYInn3wSTk5O5b6uUqmQm5tr8mUpWp0etzQ6OLPmhoiIyGKqHW7atm2L48ePAwCioqLw6aefYt++fZg9ezaaNGlSrXNlZGRAp9PBz8/PZLufnx9SU1PvePyhQ4dw6tQpvPDCCxXuM3fuXLi5uRm/QkJCqlXGe1GgFv2PSmpuXC323kRERA1VtcPNjBkzoNfrAQCzZ8/G5cuX0bNnT/z999/46quvzF7AyixZsgTt2rWrsPMxAONsyoav8hb9rCkFKi1k0Jfqc8NwQ0REVNOqPVqqX79+xsfNmjXDuXPnkJWVBQ8PD+OIqary9vaGQqEos1ZVWloa/P39Kz22oKAAq1atwuzZsyvdT6lUQqlUVqtc5pKv0sIZRaUKw2YpIiKimlatmhuNRgMbGxucOnXKZLunp2e1gw0A2NnZITIyEtu3bzdu0+v12L59O6Kjoys99rfffoNKpcLTTz9d7fe1lPzSnYnltoCNdUIWERFRQ1KtmhtbW1s0atToruayqcjUqVMxduxYdO7cGV27dsWCBQtQUFCAZ599FgAwZswYBAUFYe7cuSbHLVmyBEOHDoWXl5fZymJuBSqtaWfiuwiAREREVD3VbpZ677338O6772L58uXw9PS85wKMHDkSN27cwAcffIDU1FR06NABmzdvNnYyTkxMhFxuWsEUHx+PvXv34p9//rnn969J+UVauMAwOzH72xAREVmCTDJMMVxFHTt2REJCAjQaDRo3blxmCHZcXJxZC2huubm5cHNzQ05ODlxdazZw/HYkCX+uWY7/2f0X8G8HvLS3Rt+PiIiovqrO/bvaNTdDhw6923I1OPmlVwTnSCkiIiKLqHa4mTlzZk2Uo14q0+eGiIiIaly157mhqstX6eBs6HPDcENERGQR1a65kcvllQ77NudIqrouX6WBNyfwIyIisqhqh5u1a9eaPNdoNDh69Ch++uknfPjhh2YrWH1QoNIhlItmEhERWVS1w82QIUPKbHv88cfRpk0brF69Gs8//7xZClYfmHYoZrghIiKyBLP1uenWrZvJTMNk6FBs6HPDZikiIiJLMEu4uXXrFr766isEBQWZ43T1RpFGx5obIiIiC6t2s9TtC2RKkoS8vDw4Ojri559/Nmvh6jqVVl8yFJwzFBMREVlEtcPNF198YRJu5HI5fHx8EBUVBQ8PD7MWrq4r0uhKFs5kzQ0REZFFVDvcjBs3rgaKUT+ptHq4cBI/IiIii6p2n5sff/wRv/32W5ntv/32G3766SezFKq+KNLoS9XcsFmKiIjIEqodbubOnQtvb+8y2319fTFnzhyzFKq+UGs1rLkhIiKysGqHm8TERISFhZXZ3rhxYyQmJpqlUPWFQlNY8oQ1N0RERBZR7XDj6+uLEydOlNl+/PhxeHl5maVQ9YFeL0GpKwAASHJbwEZp5RIRERE1DNUON6NGjcKrr76KnTt3QqfTQafTYceOHZgyZQqefPLJmihjnVSmM3El63ERERGR+VR7tNRHH32EK1eu4MEHH4SNjThcr9djzJgx7HNTikqrgwtXBCciIrK4aocbOzs7rF69Gh9//DGOHTsGBwcHtGvXDo0bN66J8tVZRZqSCfxk7G9DRERkMdUONwbh4eEIDw83Z1nqFZW21AR+nJ2YiIjIYqrd52b48OH473//W2b7p59+iieeeMIshaoPStfcsFmKiIjIcqodbvbs2YOBAweW2T5gwADs2bPHLIWqD9jnhoiIyDqqHW7y8/NhZ2dXZrutrS1yc3PNUqj6oEjDpReIiIisodrhpl27dli9enWZ7atWrULr1q3NUqj6gItmEhERWUe1OxS///77eOyxx3Dx4kU88MADAIDt27fjl19+we+//272AtZVKi3XlSIiIrKGaoebQYMGYd26dZgzZw5+//13ODg4ICIiAjt27ICnp2dNlLFOKtLoSnUoZrghIiKylLsaCv7II4/gkUceAQDk5uZi5cqVmDZtGmJjY6HT6cxawLpKpdXD19ih2Nm6hSEiImpAqt3nxmDPnj0YO3YsAgMD8fnnn+OBBx7AwYMHzVm2Oq1Io4OjTCWe2DHcEBERWUq1am5SU1OxbNkyLFmyBLm5uRgxYgRUKhXWrVvHzsS3UWn1cIQh3DhatzBEREQNSJVrbgYNGoQWLVrgxIkTWLBgAZKTk/H111/XZNnqtCKNDo4oEk9Yc0NERGQxVa652bRpE1599VVMnDiRyy5UgUqrL2mWsmXNDRERkaVUueZm7969yMvLQ2RkJKKiovDNN98gIyOjJstWp6k0OjgYm6WcrFsYIiKiBqTK4aZbt2744YcfkJKSghdffBGrVq1CYGAg9Ho9tm7diry8vJosZ52j0ujgZGyWYrghIiKylGqPlnJycsJzzz2HvXv34uTJk3jjjTfwySefwNfXF4MHD66JMtZJWvUtyGWSeMJmKSIiIou566HgANCiRQt8+umnuHbtGlauXGmuMtUP6oKSx6y5ISIisph7CjcGCoUCQ4cOxYYNG8xxunpBKg43WrkSkCusXBoiIqKGwyzhhsqSacTsxDqFg5VLQkRE1LAw3NQQmUbU3Ohs2N+GiIjIkhhuaogx3LAzMRERkUUx3NQQhVasCC4x3BAREVkUw00NUWhFnxvJhiOliIiILInhpobY6ETNDRfNJCIisiyGmxpSEm5Yc0NERGRJDDc1xE4vwo2M4YaIiMiiGG5qiF1xzY1cyXBDRERkSQw3NUCvl6CUxKKZcqWzlUtDRETUsDDc1ACVVg9HqAAACnvW3BAREVkSw00NUGl1cJSJmhsbexcrl4aIiKhhYbipAUUaPRwMNTfsc0NERGRRDDc1QKXVwak43IAzFBMREVkUw00NKNLo4VDcLAU7digmIiKyJIabGqDS6owdijlDMRERkWUx3NSAIo0ejjJDuGGfGyIiIktiuKkBRRodHFHcLGXLcENERGRJDDc1oPQ8N2yWIiIisiyGmxpQpFbDXqYRT9ihmIiIyKIYbmqArqig5AmHghMREVkUw00N0BXlAQD0kAM2SiuXhoiIqGFhuKkBerWouVHJHQCZzMqlISIialgYbmqAXiXCjVpub+WSEBERNTwMNzVAKq650SgcrFwSIiKihofhpiYU19xo5Qw3RERElsZwUwNkmkIAgNaG4YaIiMjSGG5qgEwjam50NpydmIiIyNIYbmqATCtqbvSsuSEiIrI4hpsaIC9ultJzAj8iIiKLY7ipATbFNTcSm6WIiIgsjuGmBih0twAAEhfNJCIisjiGmxpgUxxuuGgmERGR5THc1ABbnWiWkrHmhoiIyOKsHm4WLlyI0NBQ2NvbIyoqCocOHap0/+zsbEyaNAkBAQFQKpVo3rw5/v77bwuVtmps9UUAALkd+9wQERFZmo0133z16tWYOnUqFi9ejKioKCxYsAD9+vVDfHw8fH19y+yvVqvx0EMPwdfXF7///juCgoJw9epVuLu7W77wlVDqRbOU3J7NUkRERJZm1XAzf/58jB8/Hs8++ywAYPHixdi4cSOWLl2Kd955p8z+S5cuRVZWFvbv3w9bW1sAQGhoqCWLXCXK4pobhZLhhoiIyNKs1iylVqsRGxuLvn37lhRGLkffvn1x4MCBco/ZsGEDoqOjMWnSJPj5+aFt27aYM2cOdDqdpYpdJUoUhxvW3BAREVmc1WpuMjIyoNPp4OfnZ7Ldz88P586dK/eYS5cuYceOHRg9ejT+/vtvJCQk4OWXX4ZGo8HMmTPLPUalUkGlUhmf5+bmmu8iKuAgFQEywMaefW6IiIgszeodiqtDr9fD19cX33//PSIjIzFy5Ei89957WLx4cYXHzJ07F25ubsavkJCQGi2jJElwKK65sWHNDRERkcVZLdx4e3tDoVAgLS3NZHtaWhr8/f3LPSYgIADNmzeHQqEwbmvVqhVSU1OhVqvLPWb69OnIyckxfiUlJZnvIsqh1UtwgKgpsrV3qdH3IiIiorKsFm7s7OwQGRmJ7du3G7fp9Xps374d0dHR5R7To0cPJCQkQK/XG7edP38eAQEBsLOzK/cYpVIJV1dXk6+apNHq4FgcbhQObJYiIiKyNKs2S02dOhU//PADfvrpJ5w9exYTJ05EQUGBcfTUmDFjMH36dOP+EydORFZWFqZMmYLz589j48aNmDNnDiZNmmStSyhDo1LBRibCly2bpYiIiCzOqkPBR44ciRs3buCDDz5AamoqOnTogM2bNxs7GScmJkIuL8lfISEh2LJlC15//XW0b98eQUFBmDJlCt5++21rXUIZmqJ842MbJWtuiIiILE0mSZJk7UJYUm5uLtzc3JCTk1MjTVSpSQnwXxIJtWQDuw8zzX5+IiKihqg69+86NVqqLtCpCgAAt6C0ckmIiIgaJoYbM9MXh5siGcMNERGRNTDcmJmuqDjcwN7KJSEiImqYGG7MTK8uBACoWHNDRERkFQw3ZqZXi5oblYw1N0RERNbAcGNmEsMNERGRVTHcmJmkvgUAUMvZLEVERGQNDDdmZqi5UcsdrFwSIiKihonhxsxkGtGhWCNnsxQREZE1MNyYG8MNERGRVTHcmJmh5karYLMUERGRNTDcmJlcKzoUaxhuiIiIrILhxswM4UavYLMUERGRNTDcmJlcK5qldDasuSEiIrIGhhszUxTX3OhsHK1cEiIiooaJ4cbMFLoiAICeNTdERERWwXBjZjY6UXMjseaGiIjIKhhuzMwQbvS2rLkhIiKyBoYbM7MpbpaS2CxFRERkFQw3ZmarL26WsnWyckmIiIgaJoYbc5Ik2OlFzY3Mjn1uiIiIrIHhxpx0asihF4/t2CxFRERkDQw35qQuMD6U2bLmhoiIyBoYbsypeNFMtaSAja3SyoUhIiJqmBhuzEkjOhPfghJ2Cn5riYiIrIF3YHMqbpYqhD1sbWRWLgwREVHDxHBjTsXNUrckO9iy5oaIiMgqeAc2J0O4gZLhhoiIyEp4BzYntQg3hexzQ0REZDW8A5uTsVmKNTdERETWwjuwOZk0S7FDMRERkTUw3JhTqWYpWxt+a4mIiKyBd2BzKjVain1uiIiIrIN3YHMyNkvZs88NERGRlfAObE6lm6XY54aIiMgqGG7MSSNmKOYkfkRERNbDO7A5lV5bih2KiYiIrIJ3YDOSSq8txZobIiIiq+Ad2Iz06lKjpVhzQ0REZBW8A5uTmpP4ERERWRvDjRlJpcONnN9aIiIia+Ad2JyKR0upZPaQy1lzQ0REZA0MN2YkKx4tpZHbW7kkREREDRfDjRnJimco1ioYboiIiKyF4cZcJAkyrSHcOFi5MERERA0Xw4256NSQSXoADDdERETWxHBjLsUT+AGAjuGGiIjIahhuzKW4v41aUkBuY2vlwhARETVcDDfmUmpdKS69QEREZD28C5tLcbMUF80kIiKyLt6FzaW4WapQYs0NERGRNfEubC7+7fBv71V4XfMy15UiIiKyIhtrF6DeULrghls7HJf06MmaGyKqp/R6PdRqtbWLQfWUnZ0d5GZYm5Hhxow0OjHPjR3DDRHVQ2q1GpcvX4Zer7d2UaieksvlCAsLg52d3T2dh+HGjNQ6CQDY54aI6h1JkpCSkgKFQoGQkBCz/HVNVJper0dycjJSUlLQqFEjyGR338WD4caMNFrx14wtR0sRUT2j1WpRWFiIwMBAODo6Wrs4VE/5+PggOTkZWq0WtrZ3P2cc78JmZGiWYodiIqpvdDodANxzcwFRZQw/X4aft7vFcGNG7HNDRPXdvTQVEN2JuX6+eBc2I/a5ISKq30JDQ7FgwYIq779r1y7IZDJkZ2fXWJkqsmzZMri7u1v8fWsD3oXNqKRZit9WIqLaoE+fPnjttdfMdr7Dhw9jwoQJVd6/e/fuSElJgZubm9nKUJOqG95qK3YoNqOSDsWstiUiqiskSYJOp4ONzZ1viT4+PtU6t52dHfz9/e+2aHSXWMVgRuxzQ0RUe4wbNw67d+/Gl19+CZlMBplMhitXrhibijZt2oTIyEgolUrs3bsXFy9exJAhQ+Dn5wdnZ2d06dIF27ZtMznn7TUbMpkM//d//4dhw4bB0dER4eHh2LBhg/H125ulDE1FW7ZsQatWreDs7Iz+/fsjJSXFeIxWq8Wrr74Kd3d3eHl54e2338bYsWMxdOjQSq932bJlaNSoERwdHTFs2DBkZmaavH6n6+vTpw+uXr2K119/3fj9AoDMzEyMGjUKQUFBcHR0RLt27bBy5crqfBQWx7uwGbHPDRE1FJIkoVCttcqXJElVKuOXX36J6OhojB8/HikpKUhJSUFISIjx9XfeeQeffPIJzp49i/bt2yM/Px8DBw7E9u3bcfToUfTv3x+DBg1CYmJipe/z4YcfYsSIEThx4gQGDhyI0aNHIysrq8L9CwsL8dlnn2H58uXYs2cPEhMTMW3aNOPr//3vf7FixQr8+OOP2LdvH3Jzc7Fu3bpKyxATE4Pnn38ekydPxrFjx3D//ffj448/NtnnTte3Zs0aBAcHY/bs2cbvFwAUFRUhMjISGzduxKlTpzBhwgQ888wzOHToUKVlsiY2S5kR+9wQUUNxS6ND6w+2WOW9z8zuB0e7O9++3NzcYGdnB0dHx3KbhmbPno2HHnrI+NzT0xMRERHG5x999BHWrl2LDRs2YPLkyRW+z7hx4zBq1CgAwJw5c/DVV1/h0KFD6N+/f7n7azQaLF68GE2bNgUATJ48GbNnzza+/vXXX2P69OkYNmwYAOCbb77B33//Xem1fvnll+jfvz/eeustAEDz5s2xf/9+bN682bhPREREpdfn6ekJhUIBFxcXk+9XUFCQSfh65ZVXsGXLFvz666/o2rVrpeWyFt6FzcjYLMVJ/IiIar3OnTubPM/Pz8e0adPQqlUruLu7w9nZGWfPnr1jzU379u2Nj52cnODq6or09PQK93d0dDQGGwAICAgw7p+Tk4O0tDST0KBQKBAZGVlpGc6ePYuoqCiTbdHR0Wa5Pp1Oh48++gjt2rWDp6cnnJ2dsWXLljseZ02suTGjkj437FBMRPWbg60CZ2b3s9p7m4OTk5PJ82nTpmHr1q347LPP0KxZMzg4OODxxx+/40Kht8+kK5PJKl1/q7z9q9rUdi/u9vrmzZuHL7/8EgsWLEC7du3g5OSE1157rVYvoMpwY0ZqLfvcEFHDIJPJqtQ0ZG12dnZVnu123759GDdunLE5KD8/H1euXKnB0pXl5uYGPz8/HD58GL169QIgak7i4uLQoUOHCo9r1aoVYmJiTLYdPHjQ5HlVrq+879e+ffswZMgQPP300wDEGlDnz59H69at7+YSLYJ3YTNinxsiotolNDQUMTExuHLlCjIyMiqtUQkPD8eaNWtw7NgxHD9+HE899ZRVVkB/5ZVXMHfuXKxfvx7x8fGYMmUKbt68Wensva+++io2b96Mzz77DBcuXMA333xj0t8GqNr1hYaGYs+ePbh+/ToyMjKMx23duhX79+/H2bNn8eKLLyItLc38F25GvAubkTHcsM8NEVGtMG3aNCgUCrRu3Ro+Pj6V9hOZP38+PDw80L17dwwaNAj9+vVDp06dLFha4e2338aoUaMwZswYREdHw9nZGf369YO9vX2Fx3Tr1g0//PADvvzyS0REROCff/7BjBkzTPapyvXNnj0bV65cQdOmTY1z+syYMQOdOnVCv3790KdPH/j7+99xWLq1ySRLNPTdwcKFCzFv3jykpqYiIiICX3/9dYU9sJctW4Znn33WZJtSqURRUVGV3is3Nxdubm7IycmBq6vrPZe9tCcW78fhKzex+OlO6N82wKznJiKypqKiIly+fBlhYWGV3mTJ/PR6PVq1aoURI0bgo48+snZxalRlP2fVuX9bvcF09erVmDp1KhYvXoyoqCgsWLAA/fr1Q3x8PHx9fcs9xtXVFfHx8cbntWUhN85zQ0RE9+rq1av4559/0Lt3b6hUKnzzzTe4fPkynnrqKWsXrc6w+l14/vz5GD9+PJ599lm0bt0aixcvhqOjI5YuXVrhMTKZDP7+/sYvPz8/C5a4YsblFxhuiIjoLsnlcixbtgxdunRBjx49cPLkSWzbtg2tWrWydtHqDKvW3KjVasTGxmL69OnGbXK5HH379sWBAwcqPC4/Px+NGzeGXq9Hp06dMGfOHLRp08YSRa4UOxQTEdG9CgkJwb59+6xdjDrNqnfhjIwM6HS6MjUvfn5+SE1NLfeYFi1aYOnSpVi/fj1+/vln6PV6dO/eHdeuXSt3f5VKhdzcXJOvmlIyiV/taCYjIiJqiOpcFUN0dDTGjBmDDh06oHfv3lizZg18fHzw3Xfflbv/3Llz4ebmZvwqva6IuWnY54aIiMjqrHoX9vb2hkKhKDNePi0trcpLxNva2qJjx45ISEgo9/Xp06cjJyfH+JWUlHTP5a6Ims1SREREVmfVu7CdnR0iIyOxfft24za9Xo/t27eXWROjIjqdDidPnkRAQPlDr5VKJVxdXU2+aoqaHYqJiIiszupDwadOnYqxY8eic+fO6Nq1KxYsWICCggLjXDZjxoxBUFAQ5s6dC0BMMNStWzc0a9YM2dnZmDdvHq5evYoXXnjBmpcBoPTaUgw3RERE1mL1cDNy5EjcuHEDH3zwAVJTU9GhQwds3rzZ2Mk4MTERcnlJWLh58ybGjx+P1NRUeHh4IDIyEvv3768Va1yUzFDMDsVERETWUiuqGCZPnoyrV69CpVIhJibGZNn2Xbt2YdmyZcbnX3zxhXHf1NRUbNy4ER07drRCqU1JksQOxURE9VBoaCgWLFhgfC6TybBu3boK979y5QpkMhmOHTt2T+9rrvPcjXHjxtX6JRYqw7uwmRiCDcBwQ0RUn6WkpGDAgAFmPWd5YSIkJAQpKSlo27atWd+rJlgziJXH6s1S9YWhSQpgnxsiovqsqqN575VCobDYe9U3vAubSelwY6tgnxsiImv7/vvvERgYCL1eb7J9yJAheO655wAAFy9exJAhQ+Dn5wdnZ2d06dIF27Ztq/S8tzdLHTp0CB07doS9vT06d+6Mo0ePmuyv0+nw/PPPIywsDA4ODmjRogW+/PJL4+uzZs3CTz/9hPXr10Mmk0Emk2HXrl3l1obs3r0bXbt2hVKpREBAAN555x1otVrj63369MGrr76Kt956C56envD398esWbMqvR6dToepU6fC3d0dXl5eeOutt3D7mtqbN2/GfffdZ9zn0UcfxcWLF42vh4WFAQA6duwImUyGPn36AAAOHz6Mhx56CN7e3nBzc0Pv3r0RFxdXaXnMgeHGTAxz3MhkgELOcENE9ZwkAeoC63zdduOtyBNPPIHMzEzs3LnTuC0rKwubN2/G6NGjAYjlfAYOHIjt27fj6NGj6N+/PwYNGoTExMQqvUd+fj4effRRtG7dGrGxsZg1axamTZtmso9er0dwcDB+++03nDlzBh988AHeffdd/PrrrwCAadOmYcSIEejfvz9SUlKQkpKC7t27l3mv69evY+DAgejSpQuOHz+ORYsWYcmSJfj4449N9vvpp5/g5OSEmJgYfPrpp5g9eza2bt1a4TV8/vnnWLZsGZYuXYq9e/ciKysLa9euNdmnoKAAU6dOxZEjR7B9+3bI5XIMGzbMGBwPHToEANi2bRtSUlKwZs0aAEBeXh7Gjh2LvXv34uDBgwgPD8fAgQORl5dXpe/v3WKzlJmU7kxcW1YpJyKqMZpCYE6gdd773WTAzumOu3l4eGDAgAH45Zdf8OCDDwIAfv/9d3h7e+P+++8HAERERCAiIsJ4zEcffYS1a9diw4YNmDx58h3f45dffoFer8eSJUtgb2+PNm3a4Nq1a5g4caJxH1tbW3z44YfG52FhYThw4AB+/fVXjBgxAs7OznBwcIBKpaq0Gerbb79FSEgIvvnmG8hkMrRs2RLJycl4++238cEHHxhHFrdv3x4zZ84EAISHh+Obb77B9u3b8dBDD5V73gULFmD69Ol47LHHAACLFy/Gli1bTPYZPny4yfOlS5fCx8cHZ86cQdu2beHj4wMA8PLyMrmGBx54wOS477//Hu7u7ti9ezceffTRCq/1XrHmxkwMK4Kzvw0RUe0xevRo/PHHH1CpVACAFStW4MknnzQGgfz8fEybNg2tWrWCu7s7nJ2dcfbs2SrX3Jw9exbt27eHvb29cVt5k9AuXLgQkZGR8PHxgbOzM77//vsqv0fp94qOjjb5A7pHjx7Iz883WV+xffv2JscFBAQgPT293HPm5OQgJSXFZJSyjY0NOnfubLLfhQsXMGrUKDRp0gSurq4IDQ0FgDteQ1paGsaPH4/w8HC4ubnB1dUV+fn51b726mLNjZmUrAjOWhsiagBsHUUNirXeu4oGDRoESZKwceNGdOnSBf/++y+++OIL4+vTpk3D1q1b8dlnn6FZs2ZwcHDA448/DrVabbbirlq1CtOmTcPnn3+O6OhouLi4YN68eYiJiTHbe5Rma2tr8lwmk5Xpd1RdgwYNQuPGjfHDDz8Y+zG1bdv2jt+nsWPHIjMzE19++SUaN24MpVKJ6Ohos35/y8NwYyZcV4qIGhSZrEpNQ9Zmb2+Pxx57DCtWrEBCQgJatGiBTp06GV/ft28fxo0bh2HDhgEQNTlXrlyp8vlbtWqF5cuXo6ioyFh7c/DgQZN99u3bh+7du+Pll182bivdGRcQyxHpdLo7vtcff/wBSZKMtTf79u2Di4sLgoODq1zm0tzc3BAQEICYmBj06tULAKDVahEbG2v8PmVmZiI+Ph4//PADevbsCQDYu3dvmfIDKHMN+/btw7fffouBAwcCAJKSkpCRkXFXZa0O3onNhBP4ERHVTqNHj8bGjRuxdOlSY0dig/DwcKxZswbHjh3D8ePH8dRTT1WrluOpp56CTCbD+PHjcebMGfz999/47LPPyrzHkSNHsGXLFpw/fx7vv/8+Dh8+bLJPaGgoTpw4gfj4eGRkZECj0ZR5r5dffhlJSUl45ZVXcO7cOaxfvx4zZ87E1KlTTWbyr64pU6bgk08+wbp163Du3Dm8/PLLyM7ONr7u4eEBLy8vfP/990hISMCOHTswdepUk3P4+vrCwcEBmzdvRlpaGnJycozXvnz5cpw9exYxMTEYPXo0HBwc7rqsVcU7sZnoJQmOdgo42imsXRQiIirlgQcegKenJ+Lj4/HUU0+ZvDZ//nx4eHige/fuGDRoEPr162dSs3Mnzs7O+PPPP3Hy5El07NgR7733Hv773/+a7PPiiy/isccew8iRIxEVFYXMzEyTWhwAGD9+PFq0aIHOnTvDx8cH+/btK/NeQUFB+Pvvv3Ho0CFERETgpZdewvPPP48ZM2ZU47tR1htvvIFnnnkGY8eONTabGWqyAEAul2PVqlWIjY1F27Zt8frrr2PevHkm57CxscFXX32F7777DoGBgRgyZAgAYMmSJbh58yY6deqEZ555Bq+++ip8fX3vqbxVIZNuH8xez+Xm5sLNzQ05OTk1ukI4EVF9UlRUhMuXLyMsLMyk8yyROVX2c1ad+zdrboiIiKheYbghIiKieoXhhoiIiOoVhhsiIiKqVxhuiIiIqF5huCEioiprYANsycLM9fPFcENERHekUIg5vGp62nxq2Aw/X4aft7vF5ReIiOiObGxs4OjoiBs3bsDW1vaeZsQlKo9er8eNGzfg6OgIG5t7iycMN0REdEcymQwBAQG4fPkyrl69au3iUD0ll8vRqFEjk5XP7wbDDRERVYmdnR3Cw8PZNEU1xs7Oziy1ggw3RERUZXK5nMsvUK3HRlMiIiKqVxhuiIiIqF5huCEiIqJ6pcH1uTFMEJSbm2vlkhAREVFVGe7bVZnor8GFm7y8PABASEiIlUtCRERE1ZWXlwc3N7dK95FJDWwubb1ej+TkZLi4uNzzOPrb5ebmIiQkBElJSXB1dTXruWsDXl/dxuur23h9dRuv795JkoS8vDwEBgbecbh4g6u5kcvlCA4OrtH3cHV1rZc/vAa8vrqN11e38frqNl7fvblTjY0BOxQTERFRvcJwQ0RERPUKw40ZKZVKzJw5E0ql0tpFqRG8vrqN11e38frqNl6fZTW4DsVERERUv7HmhoiIiOoVhhsiIiKqVxhuiIiIqF5huCEiIqJ6heHGTBYuXIjQ0FDY29sjKioKhw4dsnaR7srcuXPRpUsXuLi4wNfXF0OHDkV8fLzJPn369IFMJjP5eumll6xU4uqZNWtWmbK3bNnS+HpRUREmTZoELy8vODs7Y/jw4UhLS7NiiasnNDS0zPXJZDJMmjQJQN387Pbs2YNBgwYhMDAQMpkM69atM3ldkiR88MEHCAgIgIODA/r27YsLFy6Y7JOVlYXRo0fD1dUV7u7ueP7555Gfn2/Bq6hYZden0Wjw9ttvo127dnByckJgYCDGjBmD5ORkk3OU97l/8sknFr6S8t3p8xs3blyZsvfv399kn7r6+QEo9/+jTCbDvHnzjPvU1s+vKveDqvzOTExMxCOPPAJHR0f4+vrizTffhFarrdGyM9yYwerVqzF16lTMnDkTcXFxiIiIQL9+/ZCenm7tolXb7t27MWnSJBw8eBBbt26FRqPBww8/jIKCApP9xo8fj5SUFOPXp59+aqUSV1+bNm1Myr53717ja6+//jr+/PNP/Pbbb9i9ezeSk5Px2GOPWbG01XP48GGTa9u6dSsA4IknnjDuU9c+u4KCAkRERGDhwoXlvv7pp5/iq6++wuLFixETEwMnJyf069cPRUVFxn1Gjx6N06dPY+vWrfjrr7+wZ88eTJgwwVKXUKnKrq+wsBBxcXF4//33ERcXhzVr1iA+Ph6DBw8us+/s2bNNPtdXXnnFEsW/ozt9fgDQv39/k7KvXLnS5PW6+vkBMLmulJQULF26FDKZDMOHDzfZrzZ+flW5H9zpd6ZOp8MjjzwCtVqN/fv346effsKyZcvwwQcf1GzhJbpnXbt2lSZNmmR8rtPppMDAQGnu3LlWLJV5pKenSwCk3bt3G7f17t1bmjJlivUKdQ9mzpwpRURElPtadna2ZGtrK/3222/GbWfPnpUASAcOHLBQCc1rypQpUtOmTSW9Xi9JUt3+7CRJkgBIa9euNT7X6/WSv7+/NG/ePOO27OxsSalUSitXrpQkSZLOnDkjAZAOHz5s3GfTpk2STCaTrl+/brGyV8Xt11eeQ4cOSQCkq1evGrc1btxY+uKLL2q2cGZQ3vWNHTtWGjJkSIXH1LfPb8iQIdIDDzxgsq2ufH633w+q8jvz77//luRyuZSammrcZ9GiRZKrq6ukUqlqrKysublHarUasbGx6Nu3r3GbXC5H3759ceDAASuWzDxycnIAAJ6enibbV6xYAW9vb7Rt2xbTp09HYWGhNYp3Vy5cuIDAwEA0adIEo0ePRmJiIgAgNjYWGo3G5LNs2bIlGjVqVCc/S7VajZ9//hnPPfecySKxdfmzu93ly5eRmppq8pm5ubkhKirK+JkdOHAA7u7u6Ny5s3Gfvn37Qi6XIyYmxuJlvlc5OTmQyWRwd3c32f7JJ5/Ay8sLHTt2xLx582q82t+cdu3aBV9fX7Ro0QITJ05EZmam8bX69PmlpaVh48aNeP7558u8Vhc+v9vvB1X5nXngwAG0a9cOfn5+xn369euH3NxcnD59usbK2uAWzjS3jIwM6HQ6kw8OAPz8/HDu3Dkrlco89Ho9XnvtNfTo0QNt27Y1bn/qqafQuHFjBAYG4sSJE3j77bcRHx+PNWvWWLG0VRMVFYVly5ahRYsWSElJwYcffoiePXvi1KlTSE1NhZ2dXZmbhp+fH1JTU61T4Huwbt06ZGdnY9y4ccZtdfmzK4/hcynv/5/htdTUVPj6+pq8bmNjA09Pzzr3uRYVFeHtt9/GqFGjTBYnfPXVV9GpUyd4enpi//79mD59OlJSUjB//nwrlrZq+vfvj8ceewxhYWG4ePEi3n33XQwYMAAHDhyAQqGoV5/fTz/9BBcXlzJN3XXh8yvvflCV35mpqanl/v80vFZTGG6oQpMmTcKpU6dM+qQAMGnrbteuHQICAvDggw/i4sWLaNq0qaWLWS0DBgwwPm7fvj2ioqLQuHFj/Prrr3BwcLBiycxvyZIlGDBgAAIDA43b6vJn19BpNBqMGDECkiRh0aJFJq9NnTrV+Lh9+/aws7PDiy++iLlz59aa6fAr8uSTTxoft2vXDu3bt0fTpk2xa9cuPPjgg1YsmfktXboUo0ePhr29vcn2uvD5VXQ/qK3YLHWPvL29oVAoyvQOT0tLg7+/v5VKde8mT56Mv/76Czt37kRwcHCl+0ZFRQEAEhISLFE0s3J3d0fz5s2RkJAAf39/qNVqZGdnm+xTFz/Lq1evYtu2bXjhhRcq3a8uf3YAjJ9LZf///P39y3Tu12q1yMrKqjOfqyHYXL16FVu3bjWptSlPVFQUtFotrly5YpkCmlGTJk3g7e1t/JmsD58fAPz777+Ij4+/4/9JoPZ9fhXdD6ryO9Pf37/c/5+G12oKw809srOzQ2RkJLZv327cptfrsX37dkRHR1uxZHdHkiRMnjwZa9euxY4dOxAWFnbHY44dOwYACAgIqOHSmV9+fj4uXryIgIAAREZGwtbW1uSzjI+PR2JiYp37LH/88Uf4+vrikUceqXS/uvzZAUBYWBj8/f1NPrPc3FzExMQYP7Po6GhkZ2cjNjbWuM+OHTug1+uN4a42MwSbCxcuYNu2bfDy8rrjMceOHYNcLi/TnFMXXLt2DZmZmcafybr++RksWbIEkZGRiIiIuOO+teXzu9P9oCq/M6Ojo3Hy5EmTgGoI6K1bt67RwtM9WrVqlaRUKqVly5ZJZ86ckSZMmCC5u7ub9A6vKyZOnCi5ublJu3btklJSUoxfhYWFkiRJUkJCgjR79mzpyJEj0uXLl6X169dLTZo0kXr16mXlklfNG2+8Ie3atUu6fPmytG/fPqlv376St7e3lJ6eLkmSJL300ktSo0aNpB07dkhHjhyRoqOjpejoaCuXunp0Op3UqFEj6e233zbZXlc/u7y8POno0aPS0aNHJQDS/PnzpaNHjxpHC33yySeSu7u7tH79eunEiRPSkCFDpLCwMOnWrVvGc/Tv31/q2LGjFBMTI+3du1cKDw+XRo0aZa1LMlHZ9anVamnw4MFScHCwdOzYMZP/k4aRJvv375e++OIL6dixY9LFixeln3/+WfLx8ZHGjBlj5SsTKru+vLw8adq0adKBAweky5cvS9u2bZM6deokhYeHS0VFRcZz1NXPzyAnJ0dydHSUFi1aVOb42vz53el+IEl3/p2p1Wqltm3bSg8//LB07NgxafPmzZKPj480ffr0Gi07w42ZfP3111KjRo0kOzs7qWvXrtLBgwetXaS7AqDcrx9//FGSJElKTEyUevXqJXl6ekpKpVJq1qyZ9Oabb0o5OTnWLXgVjRw5UgoICJDs7OykoKAgaeTIkVJCQoLx9Vu3bkkvv/yy5OHhITk6OkrDhg2TUlJSrFji6tuyZYsEQIqPjzfZXlc/u507d5b7Mzl27FhJksRw8Pfff1/y8/OTlEql9OCDD5a59szMTGnUqFGSs7Oz5OrqKj377LNSXl6eFa6mrMqu7/LlyxX+n9y5c6ckSZIUGxsrRUVFSW5ubpK9vb3UqlUrac6cOSbhwJoqu77CwkLp4Ycflnx8fCRbW1upcePG0vjx48v8YVhXPz+D7777TnJwcJCys7PLHF+bP7873Q8kqWq/M69cuSINGDBAcnBwkLy9vaU33nhD0mg0NVp2WfEFEBEREdUL7HNDRERE9QrDDREREdUrDDdERERUrzDcEBERUb3CcENERET1CsMNERER1SsMN0RERFSvMNwQUYMkk8mwbt06axeDiGoAww0RWdy4ceMgk8nKfPXv39/aRSOiesDG2gUgooapf//++PHHH022KZVKK5WGiOoT1twQkVUolUr4+/ubfHl4eAAQTUaLFi3CgAED4ODggCZNmuD33383Of7kyZN44IEH4ODgAC8vL0yYMAH5+fkm+yxduhRt2rSBUqlEQEAAJk+ebPJ6RkYGhg0bBkdHR4SHh2PDhg3G127evInRo0fDx8cHDg4OCA8PLxPGiKh2Yrgholrp/fffx/Dhw3H8+HGMHj0aTz75JM6ePQsAKCgoQL9+/eDh4YHDhw/jt99+w7Zt20zCy6JFizBp0iRMmDABJ0+exIYNG9CsWTOT9/jwww8xYsQInDhxAgMHDsTo0aORlZVlfP8zZ85g06ZNOHv2LBYtWgRvb2/LfQOI6O7V6LKcRETlGDt2rKRQKCQnJyeTr//85z+SJInViF966SWTY6KioqSJEydKkiRJ33//veTh4SHl5+cbX9+4caMkl8uNK0oHBgZK7733XoVlACDNmDHD+Dw/P18CIG3atEmSJEkaNGiQ9Oyzz5rngonIotjnhois4v7778eiRYtMtnl6ehofR0dHm7wWHR2NY8eOAQDOnj2LiIgIODk5GV/v0aMH9Ho94uPjIZPJkJycjAcffLDSMrRv39742MnJCa6urkhPTwcATJw4EcOHD0dcXBwefvhhDB06FN27d7+rayUiy2K4ISKrcHJyKtNMZC4ODg5V2s/W1tbkuUwmg16vBwAMGDAAV69exd9//42tW7fiwQcfxKRJk/DZZ5+ZvbxEZF7sc0NEtdLBgwfLPG/VqhUAoFWrVjh+/DgKCgqMr+/btw9yuRwtWrSAi4sLQkNDsX379nsqg4+PD8aOHYuff/4ZCxYswPfff39P5yMiy2DNDRFZhUqlQmpqqsk2GxsbY6fd3377DZ07d8Z9992HFStW4NChQ1iyZAkAYPTo0Zg5cybGjh2LWbNm4caNG3jllVfwzDPPwM/PDwAwa9YsvPTSS/D19cWAAQOQl5eHffv24ZVXXqlS+T744ANERkaiTZs2UKlU+Ouvv4zhiohqN4YbIrKKzZs3IyAgwGRbixYtcO7cOQBiJNOqVavw8ssvIyAgACtXrkTr1q0BAI6OjtiyZQumTJmCLl26wNHREcOHD8f8+fON5xo7diyKiorwxRdfYNq0afD29sbjjz9e5fLZ2dlh+vTpuHLlChwcHNCzZ0+sWrXKDFdORDVNJkmSZO1CEBGVJpPJsHbtWgwdOtTaRSGiOoh9boiIiKheYbghIiKieoV9boio1mFrORHdC9bcEBERUb3CcENERET1CsMNERER1SsMN0RERFSvMNwQERFRvcJwQ0RERPUKww0RERHVKww3REREVK8w3BAREVG98v+F8ujDnVjQTgAAAABJRU5ErkJggg==
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Plot-loss-of-best-model">Plot loss of best model<a class="anchor-link" href="#Plot-loss-of-best-model">¶</a></h2><ul>
<li>8-8-8-1</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [142]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eightx1_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eightx1_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training loss vs Validation loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'training data'</span><span class="p">,</span> <span class="s1">'validation data'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [105]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training loss vs Validation loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'training data'</span><span class="p">,</span> <span class="s1">'validation data'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Load-best-model-from-checkpoint-file-for-manual-predictions-(GRAD-student-only-work)">Load best model from checkpoint file for manual predictions (GRAD student only work)<a class="anchor-link" href="#Load-best-model-from-checkpoint-file-for-manual-predictions-(GRAD-student-only-work)">¶</a></h2><ul>
<li>Requirement: <strong>build your own function/method that serves as a prediction model</strong></li>
<li>Verify predictions are the same</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [143]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">keras.saving</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">'model.keras'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [144]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># double check it is the 16-8-1 model</span>
<span class="n">best_model</span><span class="o">.</span><span class="n">name</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[144]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'all_eights_model'</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [108]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># check the summary</span>
<span class="n">best_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Model: "all_eights_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_97 (Dense)            (None, 8)                 96        
                                                                 
 dense_98 (Dense)            (None, 8)                 72        
                                                                 
 dense_99 (Dense)            (None, 8)                 72        
                                                                 
 dense_100 (Dense)           (None, 1)                 9         
                                                                 
=================================================================
Total params: 249 (996.00 Byte)
Trainable params: 249 (996.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [109]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># gives us the shape of the weights (11,16) for the weight kernel and (16,) for the bias</span>
<span class="c1"># which makes sense since the layer is 16 neurons and input is 11 features</span>
<span class="n">best_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[109]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>[&lt;tf.Variable 'dense_97/kernel:0' shape=(11, 8) dtype=float32, numpy=
 array([[-0.49,  0.44,  0.15, -0.20, -0.37, -0.13, -0.31, -0.30],
        [-0.53, -0.22, -0.32,  0.64, -0.35, -0.30,  0.47,  0.04],
        [ 0.43,  0.45,  0.97,  0.21, -0.77,  0.18,  0.49, -0.02],
        [ 0.00, -0.38, -0.09, -0.32,  0.10, -0.18, -0.11,  0.48],
        [-0.49, -0.13, -0.81, -0.39, -0.08, -0.03, -0.28,  0.30],
        [-0.97,  0.31,  0.14, -0.35,  0.74, -0.13,  0.34, -0.02],
        [-0.06,  0.55,  0.07,  0.44,  0.02,  0.31,  0.12, -0.06],
        [ 0.02,  0.02, -0.24,  0.44,  0.24, -0.39, -0.48, -0.65],
        [ 0.17, -0.37, -0.20, -0.25, -0.06, -0.28,  0.49,  0.17],
        [ 0.01,  0.38, -0.38, -0.00,  0.21,  0.11,  0.85,  0.41],
        [-0.92, -0.32,  0.39,  0.68, -0.38, -0.59, -0.32,  0.64]],
       dtype=float32)&gt;,
 &lt;tf.Variable 'dense_97/bias:0' shape=(8,) dtype=float32, numpy=
 array([ 0.17, -0.18,  0.03, -0.04, -0.07,  0.48,  0.01, -0.07],
       dtype=float32)&gt;]</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [110]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">activations</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [111]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Testing cell to see what various methods do</span>
<span class="nb">len</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[111]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>8</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [112]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Taken from Keras docs: output = activation(dot(input, kernel) + bias)</span>
<span class="c1"># used in hidden layers</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># used in output layer</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">my_prediction_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
  <span class="c1"># this will be mutated between layers and end up as output</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">data</span>

  <span class="c1"># iterate over the layers</span>
  <span class="k">for</span> <span class="n">keras_layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="c1"># transpose the weights and bias of current layer</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">keras_layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
    <span class="n">bias_list</span> <span class="o">=</span> <span class="n">keras_layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>

    <span class="n">temporary_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)):</span>
      <span class="n">neuron_outputs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list to store neuron outputs</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)):</span>
        <span class="n">pre_activation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">weights</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">+</span> <span class="n">bias_list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

        <span class="c1"># apply activatoin functions</span>
        <span class="k">if</span> <span class="n">keras_layer</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="n">activations</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">:</span>
          <span class="n">activated_output</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">pre_activation</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">keras_layer</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="n">activations</span><span class="o">.</span><span class="n">relu</span><span class="p">:</span>
          <span class="n">activated_output</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">pre_activation</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">activated_output</span> <span class="o">=</span> <span class="n">pre_activation</span> <span class="c1"># just linear without activation</span>

        <span class="n">neuron_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activated_output</span><span class="p">)</span>

      <span class="n">temporary_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neuron_outputs</span><span class="p">)</span>
    <span class="c1"># input for the next layer</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">temporary_values</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Test-the-manual-prediction-function">Test the manual prediction function<a class="anchor-link" href="#Test-the-manual-prediction-function">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [113]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># manually using the weights and bias from the model to predict</span>
<span class="n">my_prediction_function</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">XVALID</span><span class="p">)[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[113]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>array([[ 0.87],
       [ 0.40],
       [ 0.93],
       [ 0.87],
       [ 0.96]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [114]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># actual model predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">XVALID</span><span class="p">)</span>
<span class="n">predictions</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>8/8 [==============================] - 0s 1ms/step
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[114]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>array([[ 0.87,  0.40,  0.93,  0.87,  0.96]], dtype=float32)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [115]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># actual values from dataset</span>
<span class="n">true_values</span> <span class="o">=</span> <span class="n">YVALID</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">true_values</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[115]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>array([ 1.00,  1.00,  1.00,  1.00,  1.00])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [116]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">XVALID</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[116]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(238, 11)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Phase-4---Feature-importance-and-reduction">Phase 4 - Feature importance and reduction<a class="anchor-link" href="#Phase-4---Feature-importance-and-reduction">¶</a></h1><ul>
<li>train models where each model only receives one feature at a time</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [154]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1">#</span>
<span class="nb">print</span><span class="p">(</span><span class="n">XTRAIN</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">XVALID</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">YVALID</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>(952, 11) (952,)
(238, 11) (238,)
all_eights_model
(952,)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [155]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1">#['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol', 'fasting blood sugar',</span>
<span class="c1"># 'resting ecg', 'max heart rate', 'exercise angina', 'oldpeak', 'ST slope', 'target']</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="model-checkpoint-callback">model checkpoint callback<a class="anchor-link" href="#model-checkpoint-callback">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [156]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">model_checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span> <span class="o">=</span> <span class="s1">'feature_model.keras'</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">)</span>
<span class="n">early_stopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'min'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Age-model---8x8x8x1">Age model - 8x8x8x1<a class="anchor-link" href="#Age-model---8x8x8x1">¶</a></h2><ul>
<li>val_accuracy: 0.6471</li>
<li>val_loss: 0.6520</li>
<li>val_precision: 0.6567</li>
<li>val_recall: 0.6984</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [157]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">age_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"age_model"</span><span class="p">)</span>
<span class="n">age_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">age_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">age_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">age_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">age_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">age_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">age_history</span> <span class="o">=</span> <span class="n">age_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 21s - loss: 0.6878 - accuracy: 0.5000 - precision_1: 1.0000 - recall_1: 0.8933
Epoch 1: val_loss improved from inf to 0.68598, saving model to feature_model.keras
30/30 [==============================] - 1s 13ms/step - loss: 0.6805 - accuracy: 0.6345 - precision_1: 0.7330 - recall_1: 0.7027 - val_loss: 0.6860 - val_accuracy: 0.6176 - val_precision_1: 0.6748 - val_recall_1: 0.6194
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6757 - accuracy: 0.3750 - precision_1: 0.2941 - recall_1: 0.3846
Epoch 2: val_loss improved from 0.68598 to 0.68426, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.6429 - precision_1: 0.6674 - recall_1: 0.6242 - val_loss: 0.6843 - val_accuracy: 0.6176 - val_precision_1: 0.6748 - val_recall_1: 0.6194
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6699 - accuracy: 0.6875 - precision_1: 0.8462 - recall_1: 0.5789
Epoch 3: val_loss improved from 0.68426 to 0.68289, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.6429 - precision_1: 0.6674 - recall_1: 0.6242 - val_loss: 0.6829 - val_accuracy: 0.6176 - val_precision_1: 0.6748 - val_recall_1: 0.6194
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6871 - accuracy: 0.5312 - precision_1: 0.6667 - recall_1: 0.5000
Epoch 4: val_loss improved from 0.68289 to 0.68165, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.6429 - precision_1: 0.6674 - recall_1: 0.6242 - val_loss: 0.6817 - val_accuracy: 0.6176 - val_precision_1: 0.6748 - val_recall_1: 0.6194
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6846 - accuracy: 0.5000 - precision_1: 0.3333 - recall_1: 0.6000
Epoch 5: val_loss improved from 0.68165 to 0.67979, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.6429 - precision_1: 0.6674 - recall_1: 0.6242 - val_loss: 0.6798 - val_accuracy: 0.6176 - val_precision_1: 0.6748 - val_recall_1: 0.6194
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6737 - accuracy: 0.6250 - precision_1: 0.6667 - recall_1: 0.6667
Epoch 6: val_loss improved from 0.67979 to 0.67781, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.6366 - precision_1: 0.6575 - recall_1: 0.6283 - val_loss: 0.6778 - val_accuracy: 0.6176 - val_precision_1: 0.6748 - val_recall_1: 0.6194
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7446 - accuracy: 0.5312 - precision_1: 0.6471 - recall_1: 0.5500
Epoch 7: val_loss improved from 0.67781 to 0.67520, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6408 - precision_1: 0.6577 - recall_1: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6357 - accuracy: 0.6875 - precision_1: 0.7059 - recall_1: 0.7059
Epoch 8: val_loss improved from 0.67520 to 0.67339, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6734 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6785 - accuracy: 0.5625 - precision_1: 0.6000 - recall_1: 0.3750
Epoch 9: val_loss improved from 0.67339 to 0.67154, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6715 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6430 - accuracy: 0.6562 - precision_1: 0.6842 - recall_1: 0.7222
Epoch 10: val_loss improved from 0.67154 to 0.67088, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6709 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6403 - accuracy: 0.6250 - precision_1: 0.6957 - recall_1: 0.7619
Epoch 11: val_loss improved from 0.67088 to 0.67001, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6700 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6861 - accuracy: 0.5625 - precision_1: 0.5500 - recall_1: 0.6875
Epoch 12: val_loss improved from 0.67001 to 0.66966, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6697 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6356 - accuracy: 0.6250 - precision_1: 0.5556 - recall_1: 0.7143
Epoch 13: val_loss improved from 0.66966 to 0.66900, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6690 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6336 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.4615
Epoch 14: val_loss improved from 0.66900 to 0.66809, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6681 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6359 - accuracy: 0.5938 - precision_1: 0.6250 - recall_1: 0.5882
Epoch 15: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6683 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6081 - accuracy: 0.7812 - precision_1: 0.8500 - recall_1: 0.8095
Epoch 16: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6686 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6526 - accuracy: 0.6250 - precision_1: 0.7368 - recall_1: 0.6667
Epoch 17: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6690 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6311 - accuracy: 0.6250 - precision_1: 0.7895 - recall_1: 0.6522
Epoch 18: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6687 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6947 - accuracy: 0.5938 - precision_1: 0.5333 - recall_1: 0.5714
Epoch 19: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6689 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7357 - accuracy: 0.5000 - precision_1: 0.6429 - recall_1: 0.4500
Epoch 20: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6686 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7094 - accuracy: 0.4688 - precision_1: 0.5263 - recall_1: 0.5556
Epoch 21: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6691 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6259 - accuracy: 0.6875 - precision_1: 0.5333 - recall_1: 0.7273
Epoch 22: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6689 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7054 - accuracy: 0.6250 - precision_1: 0.7000 - recall_1: 0.7000
Epoch 23: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6692 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7008 - accuracy: 0.5000 - precision_1: 0.3571 - recall_1: 0.4167
Epoch 24: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6689 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6769 - accuracy: 0.5938 - precision_1: 0.7647 - recall_1: 0.5909
Epoch 25: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6694 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7669 - accuracy: 0.4688 - precision_1: 0.4375 - recall_1: 0.4667
Epoch 26: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6701 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6612 - accuracy: 0.6250 - precision_1: 0.6842 - recall_1: 0.6842
Epoch 27: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6697 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6603 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.5385
Epoch 28: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6702 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5855 - accuracy: 0.7500 - precision_1: 0.8333 - recall_1: 0.7500
Epoch 29: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6355 - precision_1: 0.6429 - recall_1: 0.6727 - val_loss: 0.6692 - val_accuracy: 0.6092 - val_precision_1: 0.6519 - val_recall_1: 0.6567
Epoch 29: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Sex">Sex<a class="anchor-link" href="#Sex">¶</a></h2><ul>
<li>val_accuracy: 0.6849</li>
<li>val_loss: 0.6165</li>
<li>val_precision: 0.6441</li>
<li>val_recall: 0.9048</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [158]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">sex_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"sex_model"</span><span class="p">)</span>
<span class="n">sex_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">sex_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">sex_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">sex_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">sex_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">sex_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">sex_history</span> <span class="o">=</span> <span class="n">sex_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.6636 - accuracy: 0.6250 - precision_1: 0.6519 - recall_1: 0.6027
Epoch 1: val_loss did not improve from 0.66809
30/30 [==============================] - 1s 11ms/step - loss: 0.6773 - accuracy: 0.5410 - precision_1: 0.6038 - recall_1: 0.4579 - val_loss: 0.6776 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6670 - accuracy: 0.5938 - precision_1: 0.5217 - recall_1: 0.8571
Epoch 2: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6718 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6693 - accuracy: 0.5625 - precision_1: 0.5000 - recall_1: 0.7857
Epoch 3: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6694 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6360 - accuracy: 0.6875 - precision_1: 0.6364 - recall_1: 0.8750
Epoch 4: val_loss did not improve from 0.66809
30/30 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6682 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5989 - accuracy: 0.6250 - precision_1: 0.5000 - recall_1: 1.0000
Epoch 5: val_loss improved from 0.66809 to 0.66805, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6681 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6468 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.8333
Epoch 6: val_loss improved from 0.66805 to 0.66616, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6662 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6577 - accuracy: 0.7188 - precision_1: 0.7200 - recall_1: 0.9000
Epoch 7: val_loss improved from 0.66616 to 0.66504, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6650 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6462 - accuracy: 0.8125 - precision_1: 0.8214 - recall_1: 0.9583
Epoch 8: val_loss improved from 0.66504 to 0.66281, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6628 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6920 - accuracy: 0.5938 - precision_1: 0.6000 - recall_1: 0.9474
Epoch 9: val_loss improved from 0.66281 to 0.66131, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6613 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6429 - accuracy: 0.6250 - precision_1: 0.5652 - recall_1: 0.8667
Epoch 10: val_loss improved from 0.66131 to 0.66040, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6604 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6796 - accuracy: 0.5312 - precision_1: 0.5000 - recall_1: 0.9333
Epoch 11: val_loss improved from 0.66040 to 0.65968, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6597 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6013 - accuracy: 0.7500 - precision_1: 0.7083 - recall_1: 0.9444
Epoch 12: val_loss improved from 0.65968 to 0.65866, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6587 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6747 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.7778
Epoch 13: val_loss improved from 0.65866 to 0.65789, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6579 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7261 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 0.8125
Epoch 14: val_loss improved from 0.65789 to 0.65637, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6564 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6580 - accuracy: 0.5938 - precision_1: 0.5417 - recall_1: 0.8667
Epoch 15: val_loss improved from 0.65637 to 0.65586, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6559 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6345 - accuracy: 0.6562 - precision_1: 0.6087 - recall_1: 0.8750
Epoch 16: val_loss improved from 0.65586 to 0.65532, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6553 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6466 - accuracy: 0.5625 - precision_1: 0.4545 - recall_1: 0.8333
Epoch 17: val_loss improved from 0.65532 to 0.65507, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6551 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5756 - accuracy: 0.6562 - precision_1: 0.5217 - recall_1: 1.0000
Epoch 18: val_loss improved from 0.65507 to 0.65490, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6549 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6166 - accuracy: 0.7188 - precision_1: 0.6923 - recall_1: 0.9474
Epoch 19: val_loss improved from 0.65490 to 0.65376, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6538 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6325 - accuracy: 0.6562 - precision_1: 0.6154 - recall_1: 0.9412
Epoch 20: val_loss did not improve from 0.65376
30/30 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6538 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7057 - accuracy: 0.5312 - precision_1: 0.5000 - recall_1: 0.8000
Epoch 21: val_loss improved from 0.65376 to 0.65333, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6533 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6977 - accuracy: 0.5938 - precision_1: 0.6000 - recall_1: 0.8333
Epoch 22: val_loss did not improve from 0.65333
30/30 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6534 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6311 - accuracy: 0.6562 - precision_1: 0.6154 - recall_1: 0.9412
Epoch 23: val_loss improved from 0.65333 to 0.65229, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6523 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6690 - accuracy: 0.5938 - precision_1: 0.5600 - recall_1: 0.8750
Epoch 24: val_loss improved from 0.65229 to 0.65133, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6513 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6316 - accuracy: 0.6562 - precision_1: 0.6087 - recall_1: 0.8750
Epoch 25: val_loss did not improve from 0.65133
30/30 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6514 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6415 - accuracy: 0.5938 - precision_1: 0.5200 - recall_1: 0.9286
Epoch 26: val_loss improved from 0.65133 to 0.65107, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6511 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6793 - accuracy: 0.5625 - precision_1: 0.5200 - recall_1: 0.8667
Epoch 27: val_loss improved from 0.65107 to 0.65027, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6503 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6859 - accuracy: 0.5938 - precision_1: 0.5926 - recall_1: 0.8889
Epoch 28: val_loss improved from 0.65027 to 0.64994, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6499 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6262 - accuracy: 0.5938 - precision_1: 0.4783 - recall_1: 0.9167
Epoch 29: val_loss improved from 0.64994 to 0.64980, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6498 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6265 - accuracy: 0.7188 - precision_1: 0.7200 - recall_1: 0.9000
Epoch 30: val_loss improved from 0.64980 to 0.64975, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6498 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6740 - accuracy: 0.6562 - precision_1: 0.6800 - recall_1: 0.8500
Epoch 31: val_loss did not improve from 0.64975
30/30 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6498 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5946 - accuracy: 0.6562 - precision_1: 0.5600 - recall_1: 1.0000
Epoch 32: val_loss improved from 0.64975 to 0.64889, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6418 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6489 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6603 - accuracy: 0.5938 - precision_1: 0.5556 - recall_1: 0.9375
Epoch 33: val_loss improved from 0.64889 to 0.64880, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6488 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6377 - accuracy: 0.6562 - precision_1: 0.6296 - recall_1: 0.9444
Epoch 34: val_loss improved from 0.64880 to 0.64798, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6480 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6070 - accuracy: 0.7188 - precision_1: 0.6923 - recall_1: 0.9474
Epoch 35: val_loss did not improve from 0.64798
30/30 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6490 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6228 - accuracy: 0.6250 - precision_1: 0.5556 - recall_1: 1.0000
Epoch 36: val_loss did not improve from 0.64798
30/30 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6487 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6327 - accuracy: 0.6250 - precision_1: 0.5600 - recall_1: 0.9333
Epoch 37: val_loss did not improve from 0.64798
30/30 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6488 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6823 - accuracy: 0.5625 - precision_1: 0.5200 - recall_1: 0.8667
Epoch 38: val_loss improved from 0.64798 to 0.64784, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6478 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5810 - accuracy: 0.7188 - precision_1: 0.6538 - recall_1: 1.0000
Epoch 39: val_loss did not improve from 0.64784
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6482 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5559 - accuracy: 0.7188 - precision_1: 0.6087 - recall_1: 1.0000
Epoch 40: val_loss did not improve from 0.64784
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6483 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6384 - accuracy: 0.6562 - precision_1: 0.6250 - recall_1: 0.8824
Epoch 41: val_loss did not improve from 0.64784
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6482 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5356 - accuracy: 0.6875 - precision_1: 0.4737 - recall_1: 1.0000
Epoch 42: val_loss improved from 0.64784 to 0.64705, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6471 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7331 - accuracy: 0.5312 - precision_1: 0.5556 - recall_1: 0.8333
Epoch 43: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6472 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5917 - accuracy: 0.7188 - precision_1: 0.6667 - recall_1: 0.8000
Epoch 44: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6476 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6444 - accuracy: 0.6562 - precision_1: 0.6429 - recall_1: 0.9474
Epoch 45: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6474 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5794 - accuracy: 0.7188 - precision_1: 0.6538 - recall_1: 1.0000
Epoch 46: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6471 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7048 - accuracy: 0.5312 - precision_1: 0.4783 - recall_1: 0.7857
Epoch 47: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6473 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6186 - accuracy: 0.6250 - precision_1: 0.5217 - recall_1: 0.9231
Epoch 48: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6480 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5969 - accuracy: 0.7188 - precision_1: 0.6818 - recall_1: 0.8824
Epoch 49: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6480 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5980 - accuracy: 0.6875 - precision_1: 0.6296 - recall_1: 1.0000
Epoch 50: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6479 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6392 - accuracy: 0.6250 - precision_1: 0.5862 - recall_1: 1.0000
Epoch 51: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6477 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5967 - accuracy: 0.7188 - precision_1: 0.6818 - recall_1: 0.8824
Epoch 52: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6475 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6060 - accuracy: 0.6875 - precision_1: 0.6429 - recall_1: 1.0000
Epoch 53: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6477 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5979 - accuracy: 0.6875 - precision_1: 0.6296 - recall_1: 1.0000
Epoch 54: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6479 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6510 - accuracy: 0.6250 - precision_1: 0.5833 - recall_1: 0.8750
Epoch 55: val_loss did not improve from 0.64705
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6476 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6909 - accuracy: 0.4688 - precision_1: 0.3333 - recall_1: 0.8889
Epoch 56: val_loss improved from 0.64705 to 0.64686, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6469 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5909 - accuracy: 0.7500 - precision_1: 0.7391 - recall_1: 0.8947
Epoch 57: val_loss improved from 0.64686 to 0.64656, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6466 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6903 - accuracy: 0.6250 - precision_1: 0.6522 - recall_1: 0.7895
Epoch 58: val_loss did not improve from 0.64656
30/30 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6474 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6260 - accuracy: 0.6250 - precision_1: 0.5417 - recall_1: 0.9286
Epoch 59: val_loss did not improve from 0.64656
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6468 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6656 - accuracy: 0.5938 - precision_1: 0.5238 - recall_1: 0.7857
Epoch 60: val_loss did not improve from 0.64656
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6466 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6757 - accuracy: 0.5312 - precision_1: 0.4091 - recall_1: 0.8182
Epoch 61: val_loss improved from 0.64656 to 0.64637, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6464 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6435 - accuracy: 0.6250 - precision_1: 0.5652 - recall_1: 0.8667
Epoch 62: val_loss improved from 0.64637 to 0.64627, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6463 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6254 - accuracy: 0.7188 - precision_1: 0.7308 - recall_1: 0.9048
Epoch 63: val_loss did not improve from 0.64627
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6466 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6714 - accuracy: 0.5938 - precision_1: 0.5600 - recall_1: 0.8750
Epoch 64: val_loss did not improve from 0.64627
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6472 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7957 - accuracy: 0.4375 - precision_1: 0.4615 - recall_1: 0.7500
Epoch 65: val_loss did not improve from 0.64627
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6474 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5129 - accuracy: 0.8125 - precision_1: 0.7391 - recall_1: 1.0000
Epoch 66: val_loss did not improve from 0.64627
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6466 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7399 - accuracy: 0.4688 - precision_1: 0.4444 - recall_1: 0.8571
Epoch 67: val_loss did not improve from 0.64627
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6463 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6967 - accuracy: 0.5938 - precision_1: 0.5909 - recall_1: 0.7647
Epoch 68: val_loss did not improve from 0.64627
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6465 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6377 - accuracy: 0.5625 - precision_1: 0.4400 - recall_1: 1.0000
Epoch 69: val_loss improved from 0.64627 to 0.64622, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6462 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5640 - accuracy: 0.7188 - precision_1: 0.6250 - recall_1: 1.0000
Epoch 70: val_loss improved from 0.64622 to 0.64611, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6461 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5866 - accuracy: 0.6875 - precision_1: 0.5909 - recall_1: 0.9286
Epoch 71: val_loss improved from 0.64611 to 0.64559, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6456 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6184 - accuracy: 0.7188 - precision_1: 0.7273 - recall_1: 0.8421
Epoch 72: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6467 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6482 - accuracy: 0.6875 - precision_1: 0.7083 - recall_1: 0.8500
Epoch 73: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6466 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6118 - accuracy: 0.7500 - precision_1: 0.7692 - recall_1: 0.9091
Epoch 74: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6475 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6635 - accuracy: 0.6250 - precision_1: 0.5789 - recall_1: 0.7333
Epoch 75: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6468 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5498 - accuracy: 0.7812 - precision_1: 0.7308 - recall_1: 1.0000
Epoch 76: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6464 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6702 - accuracy: 0.5938 - precision_1: 0.5714 - recall_1: 0.9412
Epoch 77: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6468 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7007 - accuracy: 0.5625 - precision_1: 0.5556 - recall_1: 0.8824
Epoch 78: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6465 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6595 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.9000
Epoch 79: val_loss did not improve from 0.64559
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6459 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6358 - accuracy: 0.6562 - precision_1: 0.6296 - recall_1: 0.9444
Epoch 80: val_loss improved from 0.64559 to 0.64557, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6456 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6082 - accuracy: 0.6562 - precision_1: 0.5652 - recall_1: 0.9286
Epoch 81: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6458 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6144 - accuracy: 0.6250 - precision_1: 0.5000 - recall_1: 0.9167
Epoch 82: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6468 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6356 - accuracy: 0.6562 - precision_1: 0.6296 - recall_1: 0.9444
Epoch 83: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6469 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6239 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.8889
Epoch 84: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6467 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6511 - accuracy: 0.6250 - precision_1: 0.5833 - recall_1: 0.8750
Epoch 85: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6472 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7134 - accuracy: 0.5625 - precision_1: 0.5455 - recall_1: 0.7500
Epoch 86: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6466 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5800 - accuracy: 0.7500 - precision_1: 0.7200 - recall_1: 0.9474
Epoch 87: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6470 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6425 - accuracy: 0.7188 - precision_1: 0.7600 - recall_1: 0.8636
Epoch 88: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6473 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7034 - accuracy: 0.5000 - precision_1: 0.4444 - recall_1: 0.9231
Epoch 89: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6464 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6794 - accuracy: 0.5938 - precision_1: 0.5769 - recall_1: 0.8824
Epoch 90: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6458 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6148 - accuracy: 0.6562 - precision_1: 0.5833 - recall_1: 0.9333
Epoch 91: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6477 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6686 - accuracy: 0.5625 - precision_1: 0.5000 - recall_1: 0.9286
Epoch 92: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6472 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6613 - accuracy: 0.5625 - precision_1: 0.4800 - recall_1: 0.9231
Epoch 93: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6471 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6452 - accuracy: 0.6562 - precision_1: 0.6400 - recall_1: 0.8889
Epoch 94: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6482 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7113 - accuracy: 0.5312 - precision_1: 0.4783 - recall_1: 0.7857
Epoch 95: val_loss did not improve from 0.64557
30/30 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6439 - precision_1: 0.6068 - recall_1: 0.8949 - val_loss: 0.6464 - val_accuracy: 0.6597 - val_precision_1: 0.6480 - val_recall_1: 0.8657
Epoch 95: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Chest-pain-type">Chest pain type<a class="anchor-link" href="#Chest-pain-type">¶</a></h2><ul>
<li>val_accuracy: 0.7605</li>
<li>val_loss: 0.5380</li>
<li>val_precision: 0.7556</li>
<li>val_recall: 0.8095</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [159]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">chest_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"chest_model"</span><span class="p">)</span>
<span class="n">chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">chest_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">chest_history</span> <span class="o">=</span> <span class="n">chest_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.6614 - accuracy: 0.8438 - precision_1: 0.6632 - recall_1: 0.8591
Epoch 1: val_loss improved from 0.64557 to 0.61925, saving model to feature_model.keras
30/30 [==============================] - 1s 12ms/step - loss: 0.6499 - accuracy: 0.7500 - precision_1: 0.7293 - recall_1: 0.7838 - val_loss: 0.6192 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6279 - accuracy: 0.6562 - precision_1: 0.8667 - recall_1: 0.5909
Epoch 2: val_loss improved from 0.61925 to 0.59517, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5952 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6163 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 3: val_loss improved from 0.59517 to 0.57630, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5763 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5907 - accuracy: 0.7500 - precision_1: 0.8571 - recall_1: 0.6667
Epoch 4: val_loss improved from 0.57630 to 0.56262, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5626 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6601 - accuracy: 0.5938 - precision_1: 0.6667 - recall_1: 0.7000
Epoch 5: val_loss improved from 0.56262 to 0.54925, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5493 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4939 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 6: val_loss improved from 0.54925 to 0.54029, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5403 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6167 - accuracy: 0.7500 - precision_1: 0.6429 - recall_1: 0.7500
Epoch 7: val_loss improved from 0.54029 to 0.53426, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5343 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5981 - accuracy: 0.7500 - precision_1: 0.6842 - recall_1: 0.8667
Epoch 8: val_loss improved from 0.53426 to 0.52835, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5284 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5601 - accuracy: 0.7500 - precision_1: 0.8667 - recall_1: 0.6842
Epoch 9: val_loss improved from 0.52835 to 0.52681, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5268 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5804 - accuracy: 0.7188 - precision_1: 0.7333 - recall_1: 0.6875
Epoch 10: val_loss improved from 0.52681 to 0.52231, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5223 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6578 - accuracy: 0.6250 - precision_1: 0.6875 - recall_1: 0.6111
Epoch 11: val_loss improved from 0.52231 to 0.52063, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5206 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6169 - accuracy: 0.7188 - precision_1: 0.6471 - recall_1: 0.7857
Epoch 12: val_loss did not improve from 0.52063
30/30 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5237 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6157 - accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875
Epoch 13: val_loss improved from 0.52063 to 0.52061, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5206 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5635 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 14: val_loss improved from 0.52061 to 0.51941, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5194 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5628 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.6429
Epoch 15: val_loss improved from 0.51941 to 0.51720, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5172 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5897 - accuracy: 0.7188 - precision_1: 0.7895 - recall_1: 0.7500
Epoch 16: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5172 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5893 - accuracy: 0.7188 - precision_1: 0.8571 - recall_1: 0.6316
Epoch 17: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5184 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6547 - accuracy: 0.6875 - precision_1: 0.4167 - recall_1: 0.6250
Epoch 18: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5188 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5206 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.8696
Epoch 19: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5186 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5102 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 20: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5174 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5446 - accuracy: 0.7188 - precision_1: 1.0000 - recall_1: 0.5909
Epoch 21: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5173 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4063 - accuracy: 0.8750 - precision_1: 0.9375 - recall_1: 0.8333
Epoch 22: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5175 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4980 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 23: val_loss did not improve from 0.51720
30/30 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5179 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4205 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 24: val_loss improved from 0.51720 to 0.51719, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5172 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6839 - accuracy: 0.6250 - precision_1: 0.5714 - recall_1: 0.5714
Epoch 25: val_loss did not improve from 0.51719
30/30 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5173 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5356 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 26: val_loss did not improve from 0.51719
30/30 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5173 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4715 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 27: val_loss improved from 0.51719 to 0.51697, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5170 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5171 - accuracy: 0.7812 - precision_1: 0.8571 - recall_1: 0.7059
Epoch 28: val_loss did not improve from 0.51697
30/30 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5171 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4368 - accuracy: 0.8438 - precision_1: 1.0000 - recall_1: 0.7222
Epoch 29: val_loss did not improve from 0.51697
30/30 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5179 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3539 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8889
Epoch 30: val_loss did not improve from 0.51697
30/30 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5183 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6683 - accuracy: 0.6562 - precision_1: 0.8000 - recall_1: 0.6000
Epoch 31: val_loss did not improve from 0.51697
30/30 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5181 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5785 - accuracy: 0.7500 - precision_1: 0.7895 - recall_1: 0.7895
Epoch 32: val_loss did not improve from 0.51697
30/30 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5174 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5775 - accuracy: 0.7188 - precision_1: 0.7857 - recall_1: 0.6471
Epoch 33: val_loss improved from 0.51697 to 0.51663, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5166 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5229 - accuracy: 0.7812 - precision_1: 0.7059 - recall_1: 0.8571
Epoch 34: val_loss did not improve from 0.51663
30/30 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5173 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5462 - accuracy: 0.7500 - precision_1: 0.8571 - recall_1: 0.6667
Epoch 35: val_loss did not improve from 0.51663
30/30 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5167 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5762 - accuracy: 0.7500 - precision_1: 0.7222 - recall_1: 0.8125
Epoch 36: val_loss did not improve from 0.51663
30/30 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5168 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7643 - accuracy: 0.5312 - precision_1: 0.7222 - recall_1: 0.5652
Epoch 37: val_loss did not improve from 0.51663
30/30 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5177 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6522 - accuracy: 0.6562 - precision_1: 0.6000 - recall_1: 0.6429
Epoch 38: val_loss improved from 0.51663 to 0.51621, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5162 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6103 - accuracy: 0.7188 - precision_1: 0.6875 - recall_1: 0.7333
Epoch 39: val_loss improved from 0.51621 to 0.51619, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5162 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5928 - accuracy: 0.7188 - precision_1: 0.8125 - recall_1: 0.6842
Epoch 40: val_loss did not improve from 0.51619
30/30 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5166 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5234 - accuracy: 0.7812 - precision_1: 0.8750 - recall_1: 0.7368
Epoch 41: val_loss improved from 0.51619 to 0.51586, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5159 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5057 - accuracy: 0.8125 - precision_1: 0.8500 - recall_1: 0.8500
Epoch 42: val_loss did not improve from 0.51586
30/30 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5161 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7186 - accuracy: 0.5625 - precision_1: 0.6667 - recall_1: 0.5263
Epoch 43: val_loss did not improve from 0.51586
30/30 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5162 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6034 - accuracy: 0.7188 - precision_1: 0.7857 - recall_1: 0.6471
Epoch 44: val_loss did not improve from 0.51586
30/30 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5165 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5491 - accuracy: 0.7500 - precision_1: 0.7692 - recall_1: 0.6667
Epoch 45: val_loss improved from 0.51586 to 0.51584, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5158 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5955 - accuracy: 0.7500 - precision_1: 0.7059 - recall_1: 0.8000
Epoch 46: val_loss improved from 0.51584 to 0.51463, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5146 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7539 - accuracy: 0.5938 - precision_1: 0.5294 - recall_1: 0.6429
Epoch 47: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5155 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5828 - accuracy: 0.7188 - precision_1: 0.8000 - recall_1: 0.6667
Epoch 48: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5164 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5911 - accuracy: 0.7188 - precision_1: 0.7692 - recall_1: 0.6250
Epoch 49: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5174 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6726 - accuracy: 0.6562 - precision_1: 0.5789 - recall_1: 0.7857
Epoch 50: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5161 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4170 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 51: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5169 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4848 - accuracy: 0.8125 - precision_1: 0.9412 - recall_1: 0.7619
Epoch 52: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5166 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6852 - accuracy: 0.6562 - precision_1: 0.6190 - recall_1: 0.8125
Epoch 53: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5167 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6045 - accuracy: 0.7188 - precision_1: 0.7647 - recall_1: 0.7222
Epoch 54: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5171 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6901 - accuracy: 0.6250 - precision_1: 0.6316 - recall_1: 0.7059
Epoch 55: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5162 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5627 - accuracy: 0.7500 - precision_1: 0.7143 - recall_1: 0.8824
Epoch 56: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5152 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4276 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 57: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5153 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4738 - accuracy: 0.8125 - precision_1: 0.8824 - recall_1: 0.7895
Epoch 58: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5164 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4467 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 59: val_loss did not improve from 0.51463
30/30 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5153 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4674 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 60: val_loss improved from 0.51463 to 0.51446, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5145 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5953 - accuracy: 0.7188 - precision_1: 0.6250 - recall_1: 0.7692
Epoch 61: val_loss improved from 0.51446 to 0.51421, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5142 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4121 - accuracy: 0.9062 - precision_1: 0.8571 - recall_1: 0.9231
Epoch 62: val_loss did not improve from 0.51421
30/30 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5144 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5016 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 63: val_loss did not improve from 0.51421
30/30 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5157 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4748 - accuracy: 0.8125 - precision_1: 1.0000 - recall_1: 0.6842
Epoch 64: val_loss did not improve from 0.51421
30/30 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5159 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4856 - accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125
Epoch 65: val_loss improved from 0.51421 to 0.51405, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5140 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5488 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 66: val_loss did not improve from 0.51405
30/30 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5148 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4708 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 67: val_loss did not improve from 0.51405
30/30 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5149 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5302 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8000
Epoch 68: val_loss did not improve from 0.51405
30/30 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5155 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6078 - accuracy: 0.7188 - precision_1: 0.7647 - recall_1: 0.7222
Epoch 69: val_loss improved from 0.51405 to 0.51402, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5140 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4039 - accuracy: 0.9062 - precision_1: 0.8000 - recall_1: 0.8889
Epoch 70: val_loss did not improve from 0.51402
30/30 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5160 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5085 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 71: val_loss improved from 0.51402 to 0.51336, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5134 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6301 - accuracy: 0.6875 - precision_1: 0.6250 - recall_1: 0.7143
Epoch 72: val_loss did not improve from 0.51336
30/30 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5142 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6456 - accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875
Epoch 73: val_loss improved from 0.51336 to 0.51197, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5120 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6584 - accuracy: 0.6562 - precision_1: 0.5882 - recall_1: 0.7143
Epoch 74: val_loss did not improve from 0.51197
30/30 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5124 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5798 - accuracy: 0.7500 - precision_1: 0.8125 - recall_1: 0.7222
Epoch 75: val_loss did not improve from 0.51197
30/30 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5135 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4822 - accuracy: 0.8125 - precision_1: 0.7333 - recall_1: 0.8462
Epoch 76: val_loss did not improve from 0.51197
30/30 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5137 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5090 - accuracy: 0.8125 - precision_1: 0.6875 - recall_1: 0.9167
Epoch 77: val_loss did not improve from 0.51197
30/30 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5130 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5438 - accuracy: 0.7500 - precision_1: 0.8667 - recall_1: 0.6842
Epoch 78: val_loss improved from 0.51197 to 0.51065, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5106 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6886 - accuracy: 0.6250 - precision_1: 0.6250 - recall_1: 0.6250
Epoch 79: val_loss improved from 0.51065 to 0.51049, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5105 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5036 - accuracy: 0.7812 - precision_1: 0.7857 - recall_1: 0.7333
Epoch 80: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5125 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5662 - accuracy: 0.7188 - precision_1: 0.7826 - recall_1: 0.8182
Epoch 81: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5122 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5270 - accuracy: 0.7500 - precision_1: 0.8824 - recall_1: 0.7143
Epoch 82: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5123 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3572 - accuracy: 0.9375 - precision_1: 0.9091 - recall_1: 1.0000
Epoch 83: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5145 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5746 - accuracy: 0.7500 - precision_1: 0.7778 - recall_1: 0.7778
Epoch 84: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5143 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5682 - accuracy: 0.7500 - precision_1: 0.8125 - recall_1: 0.7222
Epoch 85: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5128 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5458 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 86: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5116 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5119 - accuracy: 0.7812 - precision_1: 0.8889 - recall_1: 0.7619
Epoch 87: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5114 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5442 - accuracy: 0.7500 - precision_1: 0.6000 - recall_1: 0.8182
Epoch 88: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5109 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5477 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.8333
Epoch 89: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5114 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6425 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.7059
Epoch 90: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5119 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4113 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 91: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5122 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4474 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 92: val_loss did not improve from 0.51049
30/30 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5111 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5434 - accuracy: 0.7500 - precision_1: 0.8125 - recall_1: 0.7222
Epoch 93: val_loss improved from 0.51049 to 0.50868, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5087 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4513 - accuracy: 0.8438 - precision_1: 0.7917 - recall_1: 1.0000
Epoch 94: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5087 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5429 - accuracy: 0.7500 - precision_1: 0.8500 - recall_1: 0.7727
Epoch 95: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5095 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4983 - accuracy: 0.8125 - precision_1: 0.7692 - recall_1: 0.7692
Epoch 96: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5087 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4772 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8889
Epoch 97: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5102 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5929 - accuracy: 0.7188 - precision_1: 0.6471 - recall_1: 0.7857
Epoch 98: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5102 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6362 - accuracy: 0.6875 - precision_1: 0.6154 - recall_1: 0.6154
Epoch 99: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5109 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6320 - accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875
Epoch 100: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7500 - precision_1: 0.7586 - recall_1: 0.7616 - val_loss: 0.5091 - val_accuracy: 0.7899 - val_precision_1: 0.8281 - val_recall_1: 0.7910
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Resting-bp">Resting bp<a class="anchor-link" href="#Resting-bp">¶</a></h2><ul>
<li>val_accuracy: 0.5882</li>
<li>val_loss: 0.6704</li>
<li>val_precision: 0.6400</li>
<li>val_recall: 0.5079</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [160]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">bp_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"bp_model"</span><span class="p">)</span>
<span class="n">bp_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">bp_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">bp_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">bp_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">bp_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">bp_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">bp_history</span> <span class="o">=</span> <span class="n">bp_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.7131 - accuracy: 0.5000 - precision_1: 0.7625 - recall_1: 0.8133
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 10ms/step - loss: 0.6908 - accuracy: 0.5336 - precision_1: 0.5719 - recall_1: 0.8537 - val_loss: 0.6761 - val_accuracy: 0.5294 - val_precision_1: 0.5655 - val_recall_1: 0.7090
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7314 - accuracy: 0.3750 - precision_1: 0.3913 - recall_1: 0.6000
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5189 - precision_1: 0.5290 - recall_1: 0.6828 - val_loss: 0.6767 - val_accuracy: 0.5588 - val_precision_1: 0.6142 - val_recall_1: 0.5821
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6411 - accuracy: 0.5938 - precision_1: 0.6316 - recall_1: 0.6667
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5399 - precision_1: 0.5558 - recall_1: 0.5737 - val_loss: 0.6769 - val_accuracy: 0.5420 - val_precision_1: 0.6050 - val_recall_1: 0.5373
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7123 - accuracy: 0.5000 - precision_1: 0.4783 - recall_1: 0.7333
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.5378 - precision_1: 0.5577 - recall_1: 0.5374 - val_loss: 0.6772 - val_accuracy: 0.5084 - val_precision_1: 0.5876 - val_recall_1: 0.4254
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7344 - accuracy: 0.4375 - precision_1: 0.4286 - recall_1: 0.3750
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5462 - precision_1: 0.5782 - recall_1: 0.4707 - val_loss: 0.6769 - val_accuracy: 0.5420 - val_precision_1: 0.6214 - val_recall_1: 0.4776
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6930 - accuracy: 0.4688 - precision_1: 0.6923 - recall_1: 0.4091
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5525 - precision_1: 0.5804 - recall_1: 0.5030 - val_loss: 0.6782 - val_accuracy: 0.5252 - val_precision_1: 0.6235 - val_recall_1: 0.3955
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6722 - accuracy: 0.5938 - precision_1: 0.9091 - recall_1: 0.4545
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5588 - precision_1: 0.5954 - recall_1: 0.4727 - val_loss: 0.6791 - val_accuracy: 0.5252 - val_precision_1: 0.6235 - val_recall_1: 0.3955
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7092 - accuracy: 0.4688 - precision_1: 0.5000 - recall_1: 0.2353
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5546 - precision_1: 0.5922 - recall_1: 0.4606 - val_loss: 0.6780 - val_accuracy: 0.5252 - val_precision_1: 0.6235 - val_recall_1: 0.3955
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6673 - accuracy: 0.6250 - precision_1: 0.9000 - recall_1: 0.4500
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5536 - precision_1: 0.5875 - recall_1: 0.4747 - val_loss: 0.6787 - val_accuracy: 0.5252 - val_precision_1: 0.6235 - val_recall_1: 0.3955
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6818 - accuracy: 0.5312 - precision_1: 0.7273 - recall_1: 0.4000
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.5536 - precision_1: 0.5897 - recall_1: 0.4646 - val_loss: 0.6777 - val_accuracy: 0.5462 - val_precision_1: 0.6383 - val_recall_1: 0.4478
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6594 - accuracy: 0.5938 - precision_1: 0.5455 - recall_1: 0.4286
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5536 - precision_1: 0.5879 - recall_1: 0.4727 - val_loss: 0.6775 - val_accuracy: 0.5462 - val_precision_1: 0.6383 - val_recall_1: 0.4478
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6741 - accuracy: 0.5000 - precision_1: 0.6000 - recall_1: 0.3333
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5578 - precision_1: 0.5902 - recall_1: 0.4889 - val_loss: 0.6790 - val_accuracy: 0.5462 - val_precision_1: 0.6383 - val_recall_1: 0.4478
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7143 - accuracy: 0.5625 - precision_1: 0.5000 - recall_1: 0.5000
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5536 - precision_1: 0.5879 - recall_1: 0.4727 - val_loss: 0.6778 - val_accuracy: 0.5462 - val_precision_1: 0.6383 - val_recall_1: 0.4478
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6986 - accuracy: 0.5312 - precision_1: 0.6000 - recall_1: 0.3529
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5546 - precision_1: 0.5894 - recall_1: 0.4727 - val_loss: 0.6771 - val_accuracy: 0.5546 - val_precision_1: 0.6429 - val_recall_1: 0.4701
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6892 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.6154
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.5546 - precision_1: 0.5868 - recall_1: 0.4848 - val_loss: 0.6776 - val_accuracy: 0.5546 - val_precision_1: 0.6429 - val_recall_1: 0.4701
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6732 - accuracy: 0.5312 - precision_1: 0.6154 - recall_1: 0.4444
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5546 - precision_1: 0.5864 - recall_1: 0.4869 - val_loss: 0.6780 - val_accuracy: 0.5546 - val_precision_1: 0.6429 - val_recall_1: 0.4701
Epoch 16: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Cholesterol">Cholesterol<a class="anchor-link" href="#Cholesterol">¶</a></h2><ul>
<li>val_accuracy: 0.5798</li>
<li>val_loss: 0.6686</li>
<li>val_precision: 0.6806</li>
<li>val_recall: 0.3889</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [161]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">ch_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"ch_model"</span><span class="p">)</span>
<span class="n">ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">ch_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">ch_history</span> <span class="o">=</span> <span class="n">ch_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.7107 - accuracy: 0.4062 - precision_1: 0.6429 - recall_1: 0.4118
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 10ms/step - loss: 0.6958 - accuracy: 0.4685 - precision_1: 0.5160 - recall_1: 0.4356 - val_loss: 0.6951 - val_accuracy: 0.5504 - val_precision_1: 0.5985 - val_recall_1: 0.6119
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6929 - accuracy: 0.5312 - precision_1: 0.5600 - recall_1: 0.7778
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4958 - precision_1: 0.5103 - recall_1: 0.7515 - val_loss: 0.6936 - val_accuracy: 0.5546 - val_precision_1: 0.5722 - val_recall_1: 0.8284
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6925 - accuracy: 0.5000 - precision_1: 0.5185 - recall_1: 0.8235
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5095 - precision_1: 0.5160 - recall_1: 0.9131 - val_loss: 0.6926 - val_accuracy: 0.5252 - val_precision_1: 0.5488 - val_recall_1: 0.8806
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6921 - accuracy: 0.5000 - precision_1: 0.4667 - recall_1: 1.0000
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5221 - precision_1: 0.5218 - recall_1: 0.9677 - val_loss: 0.6920 - val_accuracy: 0.5462 - val_precision_1: 0.5575 - val_recall_1: 0.9403
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6891 - accuracy: 0.6562 - precision_1: 0.6333 - recall_1: 1.0000
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5210 - precision_1: 0.5209 - recall_1: 0.9818 - val_loss: 0.6913 - val_accuracy: 0.5504 - val_precision_1: 0.5590 - val_recall_1: 0.9552
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6903 - accuracy: 0.5000 - precision_1: 0.4839 - recall_1: 1.0000
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5189 - precision_1: 0.5197 - recall_1: 0.9838 - val_loss: 0.6909 - val_accuracy: 0.5504 - val_precision_1: 0.5590 - val_recall_1: 0.9552
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6933 - accuracy: 0.4688 - precision_1: 0.4688 - recall_1: 1.0000
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5210 - precision_1: 0.5213 - recall_1: 0.9657 - val_loss: 0.6903 - val_accuracy: 0.5546 - val_precision_1: 0.5603 - val_recall_1: 0.9701
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6922 - accuracy: 0.5000 - precision_1: 0.5161 - recall_1: 0.9412
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.5357 - precision_1: 0.5304 - recall_1: 0.9333 - val_loss: 0.6899 - val_accuracy: 0.5840 - val_precision_1: 0.6061 - val_recall_1: 0.7463
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6861 - accuracy: 0.6562 - precision_1: 0.7143 - recall_1: 0.7500
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.6050 - precision_1: 0.6072 - recall_1: 0.6808 - val_loss: 0.6891 - val_accuracy: 0.5756 - val_precision_1: 0.6222 - val_recall_1: 0.6269
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6867 - accuracy: 0.6250 - precision_1: 0.6316 - recall_1: 0.7059
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.6134 - precision_1: 0.6342 - recall_1: 0.6061 - val_loss: 0.6884 - val_accuracy: 0.6134 - val_precision_1: 0.6875 - val_recall_1: 0.5746
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6888 - accuracy: 0.5938 - precision_1: 0.6667 - recall_1: 0.5556
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.6155 - precision_1: 0.6617 - recall_1: 0.5333 - val_loss: 0.6881 - val_accuracy: 0.5966 - val_precision_1: 0.6939 - val_recall_1: 0.5075
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6839 - accuracy: 0.6562 - precision_1: 0.7222 - recall_1: 0.6842
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.6124 - precision_1: 0.6575 - recall_1: 0.5313 - val_loss: 0.6870 - val_accuracy: 0.6176 - val_precision_1: 0.7416 - val_recall_1: 0.4925
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6822 - accuracy: 0.6562 - precision_1: 0.5000 - recall_1: 0.5455
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.6050 - precision_1: 0.6630 - recall_1: 0.4889 - val_loss: 0.6861 - val_accuracy: 0.6176 - val_precision_1: 0.7471 - val_recall_1: 0.4851
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6904 - accuracy: 0.5625 - precision_1: 0.6667 - recall_1: 0.3529
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.6145 - precision_1: 0.6808 - recall_1: 0.4869 - val_loss: 0.6853 - val_accuracy: 0.6092 - val_precision_1: 0.7470 - val_recall_1: 0.4627
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6838 - accuracy: 0.5312 - precision_1: 0.5000 - recall_1: 0.3333
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6092 - precision_1: 0.6952 - recall_1: 0.4424 - val_loss: 0.6844 - val_accuracy: 0.6092 - val_precision_1: 0.7470 - val_recall_1: 0.4627
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6857 - accuracy: 0.6250 - precision_1: 0.6667 - recall_1: 0.4000
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.5987 - precision_1: 0.6955 - recall_1: 0.4061 - val_loss: 0.6838 - val_accuracy: 0.6092 - val_precision_1: 0.7412 - val_recall_1: 0.4701
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6827 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.4615
Epoch 17: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6124 - precision_1: 0.7019 - recall_1: 0.4424 - val_loss: 0.6829 - val_accuracy: 0.6176 - val_precision_1: 0.7471 - val_recall_1: 0.4851
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6874 - accuracy: 0.5625 - precision_1: 0.6250 - recall_1: 0.5556
Epoch 18: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.6103 - precision_1: 0.6879 - recall_1: 0.4586 - val_loss: 0.6821 - val_accuracy: 0.6176 - val_precision_1: 0.7471 - val_recall_1: 0.4851
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6769 - accuracy: 0.6250 - precision_1: 0.7333 - recall_1: 0.5789
Epoch 19: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.6145 - precision_1: 0.7013 - recall_1: 0.4505 - val_loss: 0.6814 - val_accuracy: 0.6176 - val_precision_1: 0.7471 - val_recall_1: 0.4851
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6771 - accuracy: 0.5312 - precision_1: 0.7000 - recall_1: 0.3684
Epoch 20: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.6166 - precision_1: 0.6923 - recall_1: 0.4727 - val_loss: 0.6806 - val_accuracy: 0.6092 - val_precision_1: 0.7531 - val_recall_1: 0.4552
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6678 - accuracy: 0.6562 - precision_1: 0.8000 - recall_1: 0.2857
Epoch 21: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.6071 - precision_1: 0.7010 - recall_1: 0.4263 - val_loss: 0.6800 - val_accuracy: 0.6134 - val_precision_1: 0.7386 - val_recall_1: 0.4851
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6829 - accuracy: 0.5938 - precision_1: 0.7273 - recall_1: 0.4444
Epoch 22: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.6124 - precision_1: 0.6957 - recall_1: 0.4525 - val_loss: 0.6794 - val_accuracy: 0.6134 - val_precision_1: 0.7386 - val_recall_1: 0.4851
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6705 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.6667
Epoch 23: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.6166 - precision_1: 0.7044 - recall_1: 0.4525 - val_loss: 0.6787 - val_accuracy: 0.6134 - val_precision_1: 0.7386 - val_recall_1: 0.4851
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6664 - accuracy: 0.6562 - precision_1: 0.5556 - recall_1: 0.4167
Epoch 24: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.6071 - precision_1: 0.6764 - recall_1: 0.4687 - val_loss: 0.6779 - val_accuracy: 0.6176 - val_precision_1: 0.7416 - val_recall_1: 0.4925
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6724 - accuracy: 0.6562 - precision_1: 0.7857 - recall_1: 0.5789
Epoch 25: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.6155 - precision_1: 0.6925 - recall_1: 0.4687 - val_loss: 0.6772 - val_accuracy: 0.6176 - val_precision_1: 0.7416 - val_recall_1: 0.4925
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6597 - accuracy: 0.6562 - precision_1: 0.5556 - recall_1: 0.4167
Epoch 26: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.6103 - precision_1: 0.6761 - recall_1: 0.4808 - val_loss: 0.6763 - val_accuracy: 0.6134 - val_precision_1: 0.7283 - val_recall_1: 0.5000
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6884 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 0.4375
Epoch 27: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.6092 - precision_1: 0.6649 - recall_1: 0.5010 - val_loss: 0.6773 - val_accuracy: 0.6218 - val_precision_1: 0.7444 - val_recall_1: 0.5000
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6773 - accuracy: 0.5625 - precision_1: 0.5333 - recall_1: 0.5333
Epoch 28: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6082 - precision_1: 0.6743 - recall_1: 0.4768 - val_loss: 0.6752 - val_accuracy: 0.6134 - val_precision_1: 0.7283 - val_recall_1: 0.5000
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6319 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 29: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.6103 - precision_1: 0.6649 - recall_1: 0.5051 - val_loss: 0.6744 - val_accuracy: 0.6218 - val_precision_1: 0.7340 - val_recall_1: 0.5149
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6489 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 30: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6103 - precision_1: 0.6623 - recall_1: 0.5111 - val_loss: 0.6740 - val_accuracy: 0.6134 - val_precision_1: 0.7283 - val_recall_1: 0.5000
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6461 - accuracy: 0.7500 - precision_1: 0.8889 - recall_1: 0.5333
Epoch 31: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6155 - precision_1: 0.6739 - recall_1: 0.5051 - val_loss: 0.6734 - val_accuracy: 0.6218 - val_precision_1: 0.7340 - val_recall_1: 0.5149
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7033 - accuracy: 0.4688 - precision_1: 0.4444 - recall_1: 0.2500
Epoch 32: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6103 - precision_1: 0.6542 - recall_1: 0.5313 - val_loss: 0.6729 - val_accuracy: 0.6218 - val_precision_1: 0.7340 - val_recall_1: 0.5149
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6866 - accuracy: 0.6250 - precision_1: 0.8000 - recall_1: 0.5714
Epoch 33: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.6103 - precision_1: 0.6676 - recall_1: 0.4990 - val_loss: 0.6723 - val_accuracy: 0.6092 - val_precision_1: 0.7113 - val_recall_1: 0.5149
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6640 - accuracy: 0.6250 - precision_1: 0.6471 - recall_1: 0.6471
Epoch 34: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6124 - precision_1: 0.6712 - recall_1: 0.4990 - val_loss: 0.6716 - val_accuracy: 0.6050 - val_precision_1: 0.6961 - val_recall_1: 0.5299
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6811 - accuracy: 0.5625 - precision_1: 0.5714 - recall_1: 0.5000
Epoch 35: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6124 - precision_1: 0.6615 - recall_1: 0.5212 - val_loss: 0.6737 - val_accuracy: 0.6050 - val_precision_1: 0.6961 - val_recall_1: 0.5299
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6552 - accuracy: 0.6250 - precision_1: 0.7500 - recall_1: 0.6000
Epoch 36: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6166 - precision_1: 0.6609 - recall_1: 0.5394 - val_loss: 0.6703 - val_accuracy: 0.6050 - val_precision_1: 0.6923 - val_recall_1: 0.5373
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6504 - accuracy: 0.6562 - precision_1: 0.5833 - recall_1: 0.5385
Epoch 37: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6092 - precision_1: 0.6519 - recall_1: 0.5333 - val_loss: 0.6699 - val_accuracy: 0.6050 - val_precision_1: 0.6923 - val_recall_1: 0.5373
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6761 - accuracy: 0.6250 - precision_1: 0.7692 - recall_1: 0.5263
Epoch 38: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.6103 - precision_1: 0.6527 - recall_1: 0.5354 - val_loss: 0.6696 - val_accuracy: 0.6050 - val_precision_1: 0.6961 - val_recall_1: 0.5299
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6795 - accuracy: 0.5312 - precision_1: 0.6000 - recall_1: 0.3529
Epoch 39: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6082 - precision_1: 0.6445 - recall_1: 0.5495 - val_loss: 0.6693 - val_accuracy: 0.6134 - val_precision_1: 0.7100 - val_recall_1: 0.5299
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6087 - accuracy: 0.7812 - precision_1: 0.6923 - recall_1: 0.7500
Epoch 40: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.6103 - precision_1: 0.6558 - recall_1: 0.5273 - val_loss: 0.6687 - val_accuracy: 0.6092 - val_precision_1: 0.7030 - val_recall_1: 0.5299
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6664 - accuracy: 0.5625 - precision_1: 0.5000 - recall_1: 0.4286
Epoch 41: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.6113 - precision_1: 0.6559 - recall_1: 0.5313 - val_loss: 0.6680 - val_accuracy: 0.6050 - val_precision_1: 0.6923 - val_recall_1: 0.5373
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6469 - accuracy: 0.7188 - precision_1: 0.5714 - recall_1: 0.7273
Epoch 42: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.6113 - precision_1: 0.6566 - recall_1: 0.5293 - val_loss: 0.6676 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6669 - accuracy: 0.5625 - precision_1: 0.5333 - recall_1: 0.5333
Epoch 43: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6134 - precision_1: 0.6467 - recall_1: 0.5657 - val_loss: 0.6672 - val_accuracy: 0.6050 - val_precision_1: 0.6923 - val_recall_1: 0.5373
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6753 - accuracy: 0.6250 - precision_1: 0.7500 - recall_1: 0.5000
Epoch 44: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.6145 - precision_1: 0.6553 - recall_1: 0.5455 - val_loss: 0.6665 - val_accuracy: 0.6050 - val_precision_1: 0.6923 - val_recall_1: 0.5373
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6650 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.4615
Epoch 45: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.6092 - precision_1: 0.6511 - recall_1: 0.5354 - val_loss: 0.6661 - val_accuracy: 0.6092 - val_precision_1: 0.6847 - val_recall_1: 0.5672
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6833 - accuracy: 0.5938 - precision_1: 0.7778 - recall_1: 0.3889
Epoch 46: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6155 - precision_1: 0.6490 - recall_1: 0.5677 - val_loss: 0.6661 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6545 - accuracy: 0.6875 - precision_1: 0.8000 - recall_1: 0.6316
Epoch 47: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6134 - precision_1: 0.6508 - recall_1: 0.5535 - val_loss: 0.6653 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6779 - accuracy: 0.5625 - precision_1: 0.5000 - recall_1: 0.5714
Epoch 48: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.6113 - precision_1: 0.6499 - recall_1: 0.5475 - val_loss: 0.6646 - val_accuracy: 0.6050 - val_precision_1: 0.6754 - val_recall_1: 0.5746
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6796 - accuracy: 0.6250 - precision_1: 0.6000 - recall_1: 0.6000
Epoch 49: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.6103 - precision_1: 0.6455 - recall_1: 0.5556 - val_loss: 0.6644 - val_accuracy: 0.6176 - val_precision_1: 0.6838 - val_recall_1: 0.5970
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6455 - accuracy: 0.6250 - precision_1: 0.6429 - recall_1: 0.5625
Epoch 50: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6176 - precision_1: 0.6465 - recall_1: 0.5838 - val_loss: 0.6657 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6880 - accuracy: 0.5312 - precision_1: 0.5625 - recall_1: 0.5294
Epoch 51: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6092 - precision_1: 0.6440 - recall_1: 0.5556 - val_loss: 0.6648 - val_accuracy: 0.6050 - val_precision_1: 0.6754 - val_recall_1: 0.5746
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6623 - accuracy: 0.6250 - precision_1: 0.6250 - recall_1: 0.6250
Epoch 52: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6124 - precision_1: 0.6413 - recall_1: 0.5778 - val_loss: 0.6638 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6460 - accuracy: 0.5938 - precision_1: 0.6471 - recall_1: 0.6111
Epoch 53: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.6092 - precision_1: 0.6454 - recall_1: 0.5515 - val_loss: 0.6633 - val_accuracy: 0.6092 - val_precision_1: 0.6847 - val_recall_1: 0.5672
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6743 - accuracy: 0.5625 - precision_1: 0.6471 - recall_1: 0.5789
Epoch 54: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6103 - precision_1: 0.6429 - recall_1: 0.5636 - val_loss: 0.6623 - val_accuracy: 0.6050 - val_precision_1: 0.6754 - val_recall_1: 0.5746
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6452 - accuracy: 0.5938 - precision_1: 0.5294 - recall_1: 0.6429
Epoch 55: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6113 - precision_1: 0.6404 - recall_1: 0.5758 - val_loss: 0.6617 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6467 - accuracy: 0.6250 - precision_1: 0.7333 - recall_1: 0.5789
Epoch 56: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.6134 - precision_1: 0.6446 - recall_1: 0.5717 - val_loss: 0.6621 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6774 - accuracy: 0.5625 - precision_1: 0.6250 - recall_1: 0.5556
Epoch 57: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6134 - precision_1: 0.6523 - recall_1: 0.5495 - val_loss: 0.6611 - val_accuracy: 0.6176 - val_precision_1: 0.6838 - val_recall_1: 0.5970
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6266 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7895
Epoch 58: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6176 - precision_1: 0.6459 - recall_1: 0.5859 - val_loss: 0.6606 - val_accuracy: 0.6050 - val_precision_1: 0.6754 - val_recall_1: 0.5746
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6663 - accuracy: 0.6250 - precision_1: 0.5000 - recall_1: 0.4167
Epoch 59: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.6134 - precision_1: 0.6446 - recall_1: 0.5717 - val_loss: 0.6609 - val_accuracy: 0.6092 - val_precision_1: 0.6847 - val_recall_1: 0.5672
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6089 - accuracy: 0.7500 - precision_1: 0.8750 - recall_1: 0.7000
Epoch 60: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6092 - precision_1: 0.6388 - recall_1: 0.5717 - val_loss: 0.6604 - val_accuracy: 0.6092 - val_precision_1: 0.6952 - val_recall_1: 0.5448
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6651 - accuracy: 0.5625 - precision_1: 0.4286 - recall_1: 0.5000
Epoch 61: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6092 - precision_1: 0.6420 - recall_1: 0.5616 - val_loss: 0.6599 - val_accuracy: 0.6092 - val_precision_1: 0.6847 - val_recall_1: 0.5672
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6423 - accuracy: 0.6250 - precision_1: 0.6364 - recall_1: 0.4667
Epoch 62: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6113 - precision_1: 0.6430 - recall_1: 0.5677 - val_loss: 0.6592 - val_accuracy: 0.6050 - val_precision_1: 0.6754 - val_recall_1: 0.5746
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6703 - accuracy: 0.5625 - precision_1: 0.4667 - recall_1: 0.5385
Epoch 63: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6124 - precision_1: 0.6465 - recall_1: 0.5616 - val_loss: 0.6591 - val_accuracy: 0.6176 - val_precision_1: 0.6838 - val_recall_1: 0.5970
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6866 - accuracy: 0.5312 - precision_1: 0.7143 - recall_1: 0.4762
Epoch 64: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6124 - precision_1: 0.6425 - recall_1: 0.5737 - val_loss: 0.6590 - val_accuracy: 0.6050 - val_precision_1: 0.6754 - val_recall_1: 0.5746
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6227 - accuracy: 0.7188 - precision_1: 0.5833 - recall_1: 0.6364
Epoch 65: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6155 - precision_1: 0.6456 - recall_1: 0.5778 - val_loss: 0.6586 - val_accuracy: 0.6092 - val_precision_1: 0.6847 - val_recall_1: 0.5672
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6246 - accuracy: 0.6875 - precision_1: 0.8125 - recall_1: 0.6500
Epoch 66: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6166 - precision_1: 0.6471 - recall_1: 0.5778 - val_loss: 0.6582 - val_accuracy: 0.6050 - val_precision_1: 0.6887 - val_recall_1: 0.5448
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6673 - accuracy: 0.5625 - precision_1: 0.4444 - recall_1: 0.3077
Epoch 67: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6082 - precision_1: 0.6439 - recall_1: 0.5515 - val_loss: 0.6567 - val_accuracy: 0.6176 - val_precision_1: 0.6838 - val_recall_1: 0.5970
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6127 - accuracy: 0.6875 - precision_1: 0.7692 - recall_1: 0.5882
Epoch 68: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6145 - precision_1: 0.6455 - recall_1: 0.5737 - val_loss: 0.6568 - val_accuracy: 0.6176 - val_precision_1: 0.6838 - val_recall_1: 0.5970
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6554 - accuracy: 0.5938 - precision_1: 0.5652 - recall_1: 0.8125
Epoch 69: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6134 - precision_1: 0.6433 - recall_1: 0.5758 - val_loss: 0.6565 - val_accuracy: 0.6050 - val_precision_1: 0.6754 - val_recall_1: 0.5746
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6650 - accuracy: 0.5938 - precision_1: 0.6429 - recall_1: 0.5294
Epoch 70: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6145 - precision_1: 0.6448 - recall_1: 0.5758 - val_loss: 0.6564 - val_accuracy: 0.6176 - val_precision_1: 0.6838 - val_recall_1: 0.5970
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6968 - accuracy: 0.5312 - precision_1: 0.5625 - recall_1: 0.5294
Epoch 71: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.6124 - precision_1: 0.6445 - recall_1: 0.5677 - val_loss: 0.6562 - val_accuracy: 0.6218 - val_precision_1: 0.6897 - val_recall_1: 0.5970
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6153 - accuracy: 0.6875 - precision_1: 0.8000 - recall_1: 0.6316
Epoch 72: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6134 - precision_1: 0.6453 - recall_1: 0.5697 - val_loss: 0.6555 - val_accuracy: 0.6092 - val_precision_1: 0.6814 - val_recall_1: 0.5746
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6649 - accuracy: 0.5625 - precision_1: 0.5000 - recall_1: 0.2857
Epoch 73: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6113 - precision_1: 0.6417 - recall_1: 0.5717 - val_loss: 0.6548 - val_accuracy: 0.6218 - val_precision_1: 0.6897 - val_recall_1: 0.5970
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6296 - accuracy: 0.6875 - precision_1: 0.7273 - recall_1: 0.5333
Epoch 74: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6155 - precision_1: 0.6418 - recall_1: 0.5899 - val_loss: 0.6554 - val_accuracy: 0.6050 - val_precision_1: 0.6923 - val_recall_1: 0.5373
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6281 - accuracy: 0.5938 - precision_1: 0.6667 - recall_1: 0.4706
Epoch 75: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6124 - precision_1: 0.6465 - recall_1: 0.5616 - val_loss: 0.6544 - val_accuracy: 0.6218 - val_precision_1: 0.6897 - val_recall_1: 0.5970
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6341 - accuracy: 0.7188 - precision_1: 0.5714 - recall_1: 0.7273
Epoch 76: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.6103 - precision_1: 0.6416 - recall_1: 0.5677 - val_loss: 0.6534 - val_accuracy: 0.6218 - val_precision_1: 0.6803 - val_recall_1: 0.6194
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6510 - accuracy: 0.6562 - precision_1: 0.6000 - recall_1: 0.6429
Epoch 77: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6134 - precision_1: 0.6421 - recall_1: 0.5798 - val_loss: 0.6533 - val_accuracy: 0.6218 - val_precision_1: 0.6897 - val_recall_1: 0.5970
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6671 - accuracy: 0.6562 - precision_1: 0.7333 - recall_1: 0.6111
Epoch 78: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6155 - precision_1: 0.6387 - recall_1: 0.6000 - val_loss: 0.6534 - val_accuracy: 0.6092 - val_precision_1: 0.6952 - val_recall_1: 0.5448
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6076 - accuracy: 0.7188 - precision_1: 0.8824 - recall_1: 0.6818
Epoch 79: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6155 - precision_1: 0.6525 - recall_1: 0.5576 - val_loss: 0.6532 - val_accuracy: 0.6176 - val_precision_1: 0.6870 - val_recall_1: 0.5896
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6607 - accuracy: 0.5938 - precision_1: 0.6000 - recall_1: 0.5625
Epoch 80: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6536 - accuracy: 0.6134 - precision_1: 0.6421 - recall_1: 0.5798 - val_loss: 0.6528 - val_accuracy: 0.6050 - val_precision_1: 0.6852 - val_recall_1: 0.5522
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6636 - accuracy: 0.5938 - precision_1: 0.7333 - recall_1: 0.5500
Epoch 81: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6134 - precision_1: 0.6408 - recall_1: 0.5838 - val_loss: 0.6528 - val_accuracy: 0.6008 - val_precision_1: 0.6893 - val_recall_1: 0.5299
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7052 - accuracy: 0.4688 - precision_1: 0.3571 - recall_1: 0.3846
Epoch 82: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6092 - precision_1: 0.6447 - recall_1: 0.5535 - val_loss: 0.6519 - val_accuracy: 0.6050 - val_precision_1: 0.6852 - val_recall_1: 0.5522
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6817 - accuracy: 0.4375 - precision_1: 0.4615 - recall_1: 0.3529
Epoch 83: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6113 - precision_1: 0.6464 - recall_1: 0.5576 - val_loss: 0.6514 - val_accuracy: 0.6134 - val_precision_1: 0.6842 - val_recall_1: 0.5821
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5781 - accuracy: 0.7500 - precision_1: 0.6875 - recall_1: 0.7857
Epoch 84: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6103 - precision_1: 0.6416 - recall_1: 0.5677 - val_loss: 0.6515 - val_accuracy: 0.6134 - val_precision_1: 0.6810 - val_recall_1: 0.5896
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6810 - accuracy: 0.5938 - precision_1: 0.5625 - recall_1: 0.6000
Epoch 85: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6134 - precision_1: 0.6453 - recall_1: 0.5697 - val_loss: 0.6516 - val_accuracy: 0.6134 - val_precision_1: 0.6810 - val_recall_1: 0.5896
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5958 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.6667
Epoch 86: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6092 - precision_1: 0.6388 - recall_1: 0.5717 - val_loss: 0.6514 - val_accuracy: 0.6134 - val_precision_1: 0.6842 - val_recall_1: 0.5821
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6352 - accuracy: 0.6875 - precision_1: 0.7692 - recall_1: 0.5882
Epoch 87: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.6103 - precision_1: 0.6409 - recall_1: 0.5697 - val_loss: 0.6508 - val_accuracy: 0.6008 - val_precision_1: 0.6757 - val_recall_1: 0.5597
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6615 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.5385
Epoch 88: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6092 - precision_1: 0.6388 - recall_1: 0.5717 - val_loss: 0.6508 - val_accuracy: 0.6008 - val_precision_1: 0.6757 - val_recall_1: 0.5597
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6351 - accuracy: 0.5625 - precision_1: 0.5625 - recall_1: 0.5625
Epoch 89: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6113 - precision_1: 0.6443 - recall_1: 0.5636 - val_loss: 0.6504 - val_accuracy: 0.6008 - val_precision_1: 0.6757 - val_recall_1: 0.5597
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6329 - accuracy: 0.6562 - precision_1: 0.6875 - recall_1: 0.6471
Epoch 90: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6134 - precision_1: 0.6440 - recall_1: 0.5737 - val_loss: 0.6498 - val_accuracy: 0.6134 - val_precision_1: 0.6842 - val_recall_1: 0.5821
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6845 - accuracy: 0.4688 - precision_1: 0.5625 - recall_1: 0.4737
Epoch 91: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6145 - precision_1: 0.6495 - recall_1: 0.5616 - val_loss: 0.6492 - val_accuracy: 0.6134 - val_precision_1: 0.6750 - val_recall_1: 0.6045
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6551 - accuracy: 0.7188 - precision_1: 0.8571 - recall_1: 0.6316
Epoch 92: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6166 - precision_1: 0.6419 - recall_1: 0.5939 - val_loss: 0.6490 - val_accuracy: 0.6008 - val_precision_1: 0.6757 - val_recall_1: 0.5597
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6654 - accuracy: 0.5312 - precision_1: 0.4615 - recall_1: 0.4286
Epoch 93: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6155 - precision_1: 0.6449 - recall_1: 0.5798 - val_loss: 0.6490 - val_accuracy: 0.6134 - val_precision_1: 0.6842 - val_recall_1: 0.5821
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6334 - accuracy: 0.6250 - precision_1: 0.6667 - recall_1: 0.4000
Epoch 94: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.6134 - precision_1: 0.6446 - recall_1: 0.5717 - val_loss: 0.6484 - val_accuracy: 0.6134 - val_precision_1: 0.6750 - val_recall_1: 0.6045
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6420 - accuracy: 0.6562 - precision_1: 0.7273 - recall_1: 0.5000
Epoch 95: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6103 - precision_1: 0.6348 - recall_1: 0.5899 - val_loss: 0.6490 - val_accuracy: 0.6050 - val_precision_1: 0.6852 - val_recall_1: 0.5522
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6793 - accuracy: 0.5312 - precision_1: 0.4000 - recall_1: 0.5000
Epoch 96: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6134 - precision_1: 0.6508 - recall_1: 0.5535 - val_loss: 0.6487 - val_accuracy: 0.6176 - val_precision_1: 0.6870 - val_recall_1: 0.5896
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5982 - accuracy: 0.6250 - precision_1: 0.6875 - recall_1: 0.6111
Epoch 97: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6124 - precision_1: 0.6419 - recall_1: 0.5758 - val_loss: 0.6488 - val_accuracy: 0.6176 - val_precision_1: 0.6870 - val_recall_1: 0.5896
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6582 - accuracy: 0.6562 - precision_1: 0.5000 - recall_1: 0.4545
Epoch 98: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.6103 - precision_1: 0.6422 - recall_1: 0.5657 - val_loss: 0.6480 - val_accuracy: 0.6134 - val_precision_1: 0.6750 - val_recall_1: 0.6045
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6506 - accuracy: 0.6250 - precision_1: 0.5714 - recall_1: 0.5714
Epoch 99: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6155 - precision_1: 0.6463 - recall_1: 0.5758 - val_loss: 0.6477 - val_accuracy: 0.6092 - val_precision_1: 0.6694 - val_recall_1: 0.6045
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5931 - accuracy: 0.7188 - precision_1: 0.8333 - recall_1: 0.5882
Epoch 100: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6197 - precision_1: 0.6455 - recall_1: 0.5960 - val_loss: 0.6476 - val_accuracy: 0.6176 - val_precision_1: 0.6903 - val_recall_1: 0.5821
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Fasting-blood-sugar">Fasting blood sugar<a class="anchor-link" href="#Fasting-blood-sugar">¶</a></h2><ul>
<li>val_accuracy: 0.5924</li>
<li>val_loss: 0.6534</li>
<li>val_precision: 0.8222</li>
<li>val_recall: 0.2937</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [162]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">bs_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"bs_model"</span><span class="p">)</span>
<span class="n">bs_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">bs_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">bs_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">bs_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">bs_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">bs_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">bs_history</span> <span class="o">=</span> <span class="n">bs_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.7113 - accuracy: 0.4375 - precision_1: 0.6903 - recall_1: 0.5132
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 11ms/step - loss: 0.6955 - accuracy: 0.4643 - precision_1: 0.5205 - recall_1: 0.5660 - val_loss: 0.6900 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6924 - accuracy: 0.5000 - precision_1: 0.5556 - recall_1: 0.2941
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5105 - precision_1: 0.5172 - recall_1: 0.8788 - val_loss: 0.6864 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6867 - accuracy: 0.4688 - precision_1: 0.4688 - recall_1: 1.0000
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5231 - precision_1: 0.5330 - recall_1: 0.6687 - val_loss: 0.6841 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6864 - accuracy: 0.4375 - precision_1: 0.8000 - recall_1: 0.1905
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5420 - precision_1: 0.5533 - recall_1: 0.6182 - val_loss: 0.6812 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6872 - accuracy: 0.6250 - precision_1: 0.6667 - recall_1: 0.2857
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6781 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6736 - accuracy: 0.5625 - precision_1: 1.0000 - recall_1: 0.2632
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6748 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6730 - accuracy: 0.6250 - precision_1: 0.8333 - recall_1: 0.3125
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6710 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6693 - accuracy: 0.5938 - precision_1: 0.8333 - recall_1: 0.2941
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6681 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6497 - accuracy: 0.7188 - precision_1: 0.8000 - recall_1: 0.5333
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6657 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6194 - accuracy: 0.6875 - precision_1: 1.0000 - recall_1: 0.4737
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6635 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6484 - accuracy: 0.7188 - precision_1: 0.7778 - recall_1: 0.5000
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6619 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6938 - accuracy: 0.7188 - precision_1: 0.5000 - recall_1: 0.3333
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6604 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6990 - accuracy: 0.3750 - precision_1: 0.6250 - recall_1: 0.2273
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6601 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6959 - accuracy: 0.5625 - precision_1: 0.5714 - recall_1: 0.2667
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6599 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6442 - accuracy: 0.5000 - precision_1: 0.8750 - recall_1: 0.3182
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6596 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6624 - accuracy: 0.5625 - precision_1: 0.7500 - recall_1: 0.3333
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6595 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7343 - accuracy: 0.4062 - precision_1: 0.4000 - recall_1: 0.1111
Epoch 17: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6592 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6749 - accuracy: 0.6250 - precision_1: 0.6667 - recall_1: 0.2857
Epoch 18: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6591 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5893 - accuracy: 0.6250 - precision_1: 0.9167 - recall_1: 0.5000
Epoch 19: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6592 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6933 - accuracy: 0.4688 - precision_1: 0.6667 - recall_1: 0.2105
Epoch 20: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6591 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6370 - accuracy: 0.6875 - precision_1: 0.7778 - recall_1: 0.4667
Epoch 21: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6590 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6264 - accuracy: 0.6562 - precision_1: 1.0000 - recall_1: 0.3125
Epoch 22: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6590 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6484 - accuracy: 0.5938 - precision_1: 0.7778 - recall_1: 0.3889
Epoch 23: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6591 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6917 - accuracy: 0.5625 - precision_1: 0.6000 - recall_1: 0.2000
Epoch 24: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6594 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6789 - accuracy: 0.5312 - precision_1: 0.7500 - recall_1: 0.1765
Epoch 25: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6594 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5844 - accuracy: 0.7500 - precision_1: 1.0000 - recall_1: 0.5000
Epoch 26: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6597 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6869 - accuracy: 0.4375 - precision_1: 0.7000 - recall_1: 0.3182
Epoch 27: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6595 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6016 - accuracy: 0.7500 - precision_1: 0.8889 - recall_1: 0.5333
Epoch 28: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6596 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6412 - accuracy: 0.6875 - precision_1: 1.0000 - recall_1: 0.2308
Epoch 29: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6598 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6787 - accuracy: 0.4688 - precision_1: 0.8000 - recall_1: 0.2000
Epoch 30: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6599 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6538 - accuracy: 0.6250 - precision_1: 0.7500 - recall_1: 0.3750
Epoch 31: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6599 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6446 - accuracy: 0.5312 - precision_1: 1.0000 - recall_1: 0.2500
Epoch 32: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6600 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7132 - accuracy: 0.4688 - precision_1: 0.5000 - recall_1: 0.1176
Epoch 33: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6597 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6452 - accuracy: 0.6875 - precision_1: 0.7500 - recall_1: 0.4286
Epoch 34: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6597 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6584 - accuracy: 0.5938 - precision_1: 0.7500 - recall_1: 0.3529
Epoch 35: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6595 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7809 - accuracy: 0.3438 - precision_1: 0.2857 - recall_1: 0.1111
Epoch 36: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5746 - precision_1: 0.7250 - recall_1: 0.2929 - val_loss: 0.6592 - val_accuracy: 0.5630 - val_precision_1: 0.7778 - val_recall_1: 0.3134
Epoch 36: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="resting-ecg">resting ecg<a class="anchor-link" href="#resting-ecg">¶</a></h2><ul>
<li>val_accuracy: 0.5672</li>
<li>val_loss: 0.6859</li>
<li>val_precision: 0.6211</li>
<li>val_recall: 0.4683</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [163]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">ecg_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"ecg_model"</span><span class="p">)</span>
<span class="n">ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">ecg_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">ecg_history</span> <span class="o">=</span> <span class="n">ecg_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.6791 - accuracy: 0.6562 - precision_1: 0.7326 - recall_1: 0.4065
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 11ms/step - loss: 0.6932 - accuracy: 0.5200 - precision_1: 0.5338 - recall_1: 0.8537 - val_loss: 0.6893 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6960 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5200 - precision_1: 0.5200 - recall_1: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6842 - accuracy: 0.5938 - precision_1: 0.5938 - recall_1: 1.0000
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5200 - precision_1: 0.5200 - recall_1: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6867 - accuracy: 0.3750 - precision_1: 0.3750 - recall_1: 1.0000
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5200 - precision_1: 0.5200 - recall_1: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6875 - accuracy: 0.4688 - precision_1: 0.4688 - recall_1: 1.0000
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5200 - precision_1: 0.5200 - recall_1: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6736 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5179 - precision_1: 0.5193 - recall_1: 0.9798 - val_loss: 0.6883 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6799 - accuracy: 0.6250 - precision_1: 0.6250 - recall_1: 1.0000
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5336 - precision_1: 0.5316 - recall_1: 0.8667 - val_loss: 0.6884 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6835 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5357 - precision_1: 0.5427 - recall_1: 0.6808 - val_loss: 0.6881 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6922 - accuracy: 0.4688 - precision_1: 0.5000 - recall_1: 0.2353
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5410 - precision_1: 0.5449 - recall_1: 0.7111 - val_loss: 0.6880 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6995 - accuracy: 0.5000 - precision_1: 0.5385 - recall_1: 0.4118
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6877 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6805 - accuracy: 0.6875 - precision_1: 0.6923 - recall_1: 0.6000
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5441 - precision_1: 0.5701 - recall_1: 0.5010 - val_loss: 0.6876 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6864 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.5385
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6875 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6866 - accuracy: 0.5312 - precision_1: 0.5385 - recall_1: 0.4375
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6875 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6842 - accuracy: 0.6562 - precision_1: 0.6429 - recall_1: 0.6000
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6871 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6858 - accuracy: 0.6875 - precision_1: 0.6250 - recall_1: 0.4167
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6867 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6582 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6867 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7036 - accuracy: 0.5312 - precision_1: 0.3750 - recall_1: 0.2308
Epoch 17: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5389 - precision_1: 0.5667 - recall_1: 0.4808 - val_loss: 0.6867 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6942 - accuracy: 0.5000 - precision_1: 0.5455 - recall_1: 0.3529
Epoch 18: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6863 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7136 - accuracy: 0.5312 - precision_1: 0.2727 - recall_1: 0.3000
Epoch 19: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6862 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6841 - accuracy: 0.6250 - precision_1: 0.5333 - recall_1: 0.6154
Epoch 20: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6861 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6775 - accuracy: 0.5312 - precision_1: 0.7143 - recall_1: 0.4762
Epoch 21: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6860 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6794 - accuracy: 0.6562 - precision_1: 0.7500 - recall_1: 0.5294
Epoch 22: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6861 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6702 - accuracy: 0.5938 - precision_1: 0.8889 - recall_1: 0.4000
Epoch 23: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6865 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6762 - accuracy: 0.6250 - precision_1: 0.6471 - recall_1: 0.6471
Epoch 24: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6860 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6875 - accuracy: 0.5938 - precision_1: 0.5625 - recall_1: 0.6000
Epoch 25: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6857 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7029 - accuracy: 0.5000 - precision_1: 0.4286 - recall_1: 0.4286
Epoch 26: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6855 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6926 - accuracy: 0.5625 - precision_1: 0.5455 - recall_1: 0.4000
Epoch 27: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6858 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6854 - accuracy: 0.5938 - precision_1: 0.6000 - recall_1: 0.5625
Epoch 28: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6850 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7054 - accuracy: 0.4375 - precision_1: 0.4167 - recall_1: 0.3125
Epoch 29: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6849 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6959 - accuracy: 0.4062 - precision_1: 0.5333 - recall_1: 0.4000
Epoch 30: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6855 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6864 - accuracy: 0.5312 - precision_1: 0.6667 - recall_1: 0.3333
Epoch 31: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6885 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6848 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7035 - accuracy: 0.4688 - precision_1: 0.4167 - recall_1: 0.3333
Epoch 32: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6851 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6996 - accuracy: 0.4688 - precision_1: 0.5000 - recall_1: 0.5882
Epoch 33: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6843 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6971 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 0.4375
Epoch 34: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6836 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7169 - accuracy: 0.4375 - precision_1: 0.3333 - recall_1: 0.2857
Epoch 35: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6839 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6848 - accuracy: 0.5312 - precision_1: 0.6154 - recall_1: 0.4444
Epoch 36: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6839 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6791 - accuracy: 0.6250 - precision_1: 0.6154 - recall_1: 0.5333
Epoch 37: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6842 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6771 - accuracy: 0.5938 - precision_1: 0.6667 - recall_1: 0.5556
Epoch 38: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6840 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6956 - accuracy: 0.4375 - precision_1: 0.5625 - recall_1: 0.4500
Epoch 39: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6834 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6690 - accuracy: 0.5938 - precision_1: 0.7333 - recall_1: 0.5500
Epoch 40: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6833 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6576 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7059
Epoch 41: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6829 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6991 - accuracy: 0.4688 - precision_1: 0.5000 - recall_1: 0.3529
Epoch 42: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6826 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6939 - accuracy: 0.5625 - precision_1: 0.5000 - recall_1: 0.4286
Epoch 43: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6828 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7040 - accuracy: 0.4375 - precision_1: 0.4545 - recall_1: 0.2941
Epoch 44: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6826 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6995 - accuracy: 0.5625 - precision_1: 0.4286 - recall_1: 0.5000
Epoch 45: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6824 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6824 - accuracy: 0.5625 - precision_1: 0.6154 - recall_1: 0.4706
Epoch 46: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6827 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6580 - accuracy: 0.6875 - precision_1: 0.9091 - recall_1: 0.5263
Epoch 47: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6827 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6970 - accuracy: 0.5312 - precision_1: 0.4545 - recall_1: 0.3571
Epoch 48: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6822 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7162 - accuracy: 0.5000 - precision_1: 0.3125 - recall_1: 0.5000
Epoch 49: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6817 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6591 - accuracy: 0.6562 - precision_1: 0.7857 - recall_1: 0.5789
Epoch 50: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6818 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6883 - accuracy: 0.4688 - precision_1: 0.6000 - recall_1: 0.4500
Epoch 51: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6815 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6928 - accuracy: 0.5312 - precision_1: 0.5455 - recall_1: 0.3750
Epoch 52: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6824 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6760 - accuracy: 0.5312 - precision_1: 0.6500 - recall_1: 0.6190
Epoch 53: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6819 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6792 - accuracy: 0.5625 - precision_1: 0.6429 - recall_1: 0.5000
Epoch 54: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6815 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6781 - accuracy: 0.5312 - precision_1: 0.6923 - recall_1: 0.4500
Epoch 55: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6812 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6757 - accuracy: 0.5312 - precision_1: 0.6471 - recall_1: 0.5500
Epoch 56: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6813 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6990 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 0.4375
Epoch 57: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6804 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6626 - accuracy: 0.6250 - precision_1: 0.8182 - recall_1: 0.4737
Epoch 58: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6812 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6779 - accuracy: 0.5938 - precision_1: 0.6471 - recall_1: 0.6111
Epoch 59: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6806 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6721 - accuracy: 0.5625 - precision_1: 0.7333 - recall_1: 0.5238
Epoch 60: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6802 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6872 - accuracy: 0.5938 - precision_1: 0.6000 - recall_1: 0.4000
Epoch 61: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6803 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6835 - accuracy: 0.5938 - precision_1: 0.5556 - recall_1: 0.3571
Epoch 62: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6801 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6590 - accuracy: 0.6562 - precision_1: 0.7333 - recall_1: 0.6111
Epoch 63: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6803 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6841 - accuracy: 0.5000 - precision_1: 0.6154 - recall_1: 0.4211
Epoch 64: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6796 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6744 - accuracy: 0.5625 - precision_1: 0.6667 - recall_1: 0.6000
Epoch 65: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6791 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6895 - accuracy: 0.5625 - precision_1: 0.5455 - recall_1: 0.4000
Epoch 66: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6797 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6985 - accuracy: 0.5000 - precision_1: 0.4167 - recall_1: 0.3571
Epoch 67: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6799 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6916 - accuracy: 0.5312 - precision_1: 0.5000 - recall_1: 0.3333
Epoch 68: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6803 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6801 - accuracy: 0.5312 - precision_1: 0.5625 - recall_1: 0.5294
Epoch 69: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6807 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6852 - accuracy: 0.5938 - precision_1: 0.5833 - recall_1: 0.4667
Epoch 70: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6795 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6752 - accuracy: 0.5625 - precision_1: 0.7000 - recall_1: 0.3889
Epoch 71: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6796 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6924 - accuracy: 0.4688 - precision_1: 0.5455 - recall_1: 0.3333
Epoch 72: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6800 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6816 - accuracy: 0.5938 - precision_1: 0.6000 - recall_1: 0.5625
Epoch 73: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6798 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6752 - accuracy: 0.5312 - precision_1: 0.7500 - recall_1: 0.4286
Epoch 74: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6797 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6853 - accuracy: 0.5000 - precision_1: 0.5455 - recall_1: 0.3529
Epoch 75: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6789 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6852 - accuracy: 0.5625 - precision_1: 0.6154 - recall_1: 0.4706
Epoch 76: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6798 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6816 - accuracy: 0.5312 - precision_1: 0.6000 - recall_1: 0.5000
Epoch 77: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6786 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6815 - accuracy: 0.5938 - precision_1: 0.5625 - recall_1: 0.6000
Epoch 78: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6791 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6546 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.6429
Epoch 79: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6787 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7112 - accuracy: 0.3750 - precision_1: 0.5000 - recall_1: 0.3500
Epoch 80: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6785 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6733 - accuracy: 0.6250 - precision_1: 0.6154 - recall_1: 0.5333
Epoch 81: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6787 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6543 - accuracy: 0.6875 - precision_1: 0.6429 - recall_1: 0.6429
Epoch 82: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6792 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6903 - accuracy: 0.5625 - precision_1: 0.5455 - recall_1: 0.4000
Epoch 83: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6790 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7271 - accuracy: 0.4375 - precision_1: 0.4118 - recall_1: 0.4667
Epoch 84: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6790 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6798 - accuracy: 0.5938 - precision_1: 0.7143 - recall_1: 0.5263
Epoch 85: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6787 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6777 - accuracy: 0.5312 - precision_1: 0.6429 - recall_1: 0.4737
Epoch 86: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6783 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7009 - accuracy: 0.5312 - precision_1: 0.5000 - recall_1: 0.4667
Epoch 87: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6797 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7117 - accuracy: 0.4375 - precision_1: 0.2727 - recall_1: 0.2308
Epoch 88: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6782 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6836 - accuracy: 0.6250 - precision_1: 0.6923 - recall_1: 0.5294
Epoch 89: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6790 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7152 - accuracy: 0.4375 - precision_1: 0.4000 - recall_1: 0.2500
Epoch 90: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6787 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6892 - accuracy: 0.5312 - precision_1: 0.6154 - recall_1: 0.4444
Epoch 91: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6784 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6964 - accuracy: 0.5625 - precision_1: 0.4667 - recall_1: 0.5385
Epoch 92: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6778 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6837 - accuracy: 0.5625 - precision_1: 0.5556 - recall_1: 0.3333
Epoch 93: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6777 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6845 - accuracy: 0.6250 - precision_1: 0.5625 - recall_1: 0.6429
Epoch 94: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6784 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6897 - accuracy: 0.5938 - precision_1: 0.6429 - recall_1: 0.5294
Epoch 95: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6790 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7043 - accuracy: 0.5312 - precision_1: 0.4545 - recall_1: 0.3571
Epoch 96: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6780 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6845 - accuracy: 0.5000 - precision_1: 0.6154 - recall_1: 0.4211
Epoch 97: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6781 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6865 - accuracy: 0.5938 - precision_1: 0.6154 - recall_1: 0.5000
Epoch 98: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6780 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6915 - accuracy: 0.4688 - precision_1: 0.4667 - recall_1: 0.4375
Epoch 99: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6783 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6913 - accuracy: 0.5938 - precision_1: 0.5000 - recall_1: 0.3846
Epoch 100: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5473 - precision_1: 0.5804 - recall_1: 0.4667 - val_loss: 0.6775 - val_accuracy: 0.5462 - val_precision_1: 0.6204 - val_recall_1: 0.5000
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="max-heart-rate">max heart rate<a class="anchor-link" href="#max-heart-rate">¶</a></h2><ul>
<li>val_accuracy: 0.6345</li>
<li>val_loss: 0.6337</li>
<li>val_precision: 0.6696</li>
<li>val_recall: 0.6111</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [164]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">heart_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"heart_model"</span><span class="p">)</span>
<span class="n">heart_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">heart_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">heart_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">heart_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">heart_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">heart_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">heart_history</span> <span class="o">=</span> <span class="n">heart_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
30/30 [==============================] - ETA: 0s - loss: 0.6735 - accuracy: 0.6586 - precision_1: 0.6944 - recall_1: 0.5564 
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 11ms/step - loss: 0.6735 - accuracy: 0.6586 - precision_1: 0.6944 - recall_1: 0.5564 - val_loss: 0.6676 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6523 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.6250
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6723 - precision_1: 0.7047 - recall_1: 0.6364 - val_loss: 0.6536 - val_accuracy: 0.6639 - val_precision_1: 0.7143 - val_recall_1: 0.6716
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6556 - accuracy: 0.6562 - precision_1: 0.6500 - recall_1: 0.7647
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6796 - precision_1: 0.7093 - recall_1: 0.6505 - val_loss: 0.6415 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6233 - accuracy: 0.6562 - precision_1: 0.8125 - recall_1: 0.6190
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6786 - precision_1: 0.7153 - recall_1: 0.6343 - val_loss: 0.6334 - val_accuracy: 0.6639 - val_precision_1: 0.7143 - val_recall_1: 0.6716
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6260 - accuracy: 0.5938 - precision_1: 0.7059 - recall_1: 0.6000
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6765 - precision_1: 0.6994 - recall_1: 0.6626 - val_loss: 0.6285 - val_accuracy: 0.6639 - val_precision_1: 0.7143 - val_recall_1: 0.6716
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5627 - accuracy: 0.7500 - precision_1: 0.7895 - recall_1: 0.7895
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6744 - precision_1: 0.6981 - recall_1: 0.6586 - val_loss: 0.6267 - val_accuracy: 0.6639 - val_precision_1: 0.7143 - val_recall_1: 0.6716
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6266 - accuracy: 0.6562 - precision_1: 0.7500 - recall_1: 0.7143
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.6712 - precision_1: 0.6961 - recall_1: 0.6525 - val_loss: 0.6264 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5800 - accuracy: 0.6562 - precision_1: 0.4444 - recall_1: 0.4000
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6733 - precision_1: 0.7035 - recall_1: 0.6424 - val_loss: 0.6260 - val_accuracy: 0.6639 - val_precision_1: 0.7143 - val_recall_1: 0.6716
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6016 - accuracy: 0.6562 - precision_1: 0.7000 - recall_1: 0.7368
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.6817 - precision_1: 0.7105 - recall_1: 0.6545 - val_loss: 0.6277 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5799 - accuracy: 0.7500 - precision_1: 0.6429 - recall_1: 0.7500
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6775 - precision_1: 0.7146 - recall_1: 0.6323 - val_loss: 0.6283 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5997 - accuracy: 0.6875 - precision_1: 0.5333 - recall_1: 0.7273
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6786 - precision_1: 0.7172 - recall_1: 0.6303 - val_loss: 0.6288 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6640 - accuracy: 0.5625 - precision_1: 0.5556 - recall_1: 0.3333
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.6786 - precision_1: 0.7172 - recall_1: 0.6303 - val_loss: 0.6309 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6099 - accuracy: 0.6562 - precision_1: 0.6429 - recall_1: 0.6000
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6786 - precision_1: 0.7172 - recall_1: 0.6303 - val_loss: 0.6317 - val_accuracy: 0.6303 - val_precision_1: 0.7018 - val_recall_1: 0.5970
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4754 - accuracy: 0.7500 - precision_1: 0.8333 - recall_1: 0.7500
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6796 - precision_1: 0.7209 - recall_1: 0.6263 - val_loss: 0.6315 - val_accuracy: 0.6345 - val_precision_1: 0.7080 - val_recall_1: 0.5970
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6184 - accuracy: 0.6562 - precision_1: 0.7222 - recall_1: 0.6842
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6786 - precision_1: 0.7203 - recall_1: 0.6242 - val_loss: 0.6324 - val_accuracy: 0.6345 - val_precision_1: 0.7080 - val_recall_1: 0.5970
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5721 - accuracy: 0.7188 - precision_1: 0.8000 - recall_1: 0.6667
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.6796 - precision_1: 0.7220 - recall_1: 0.6242 - val_loss: 0.6323 - val_accuracy: 0.6345 - val_precision_1: 0.7080 - val_recall_1: 0.5970
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6057 - accuracy: 0.6562 - precision_1: 0.6875 - recall_1: 0.6471
Epoch 17: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.6786 - precision_1: 0.7213 - recall_1: 0.6222 - val_loss: 0.6330 - val_accuracy: 0.6345 - val_precision_1: 0.7080 - val_recall_1: 0.5970
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5984 - accuracy: 0.6562 - precision_1: 0.6429 - recall_1: 0.6000
Epoch 18: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6796 - precision_1: 0.7230 - recall_1: 0.6222 - val_loss: 0.6325 - val_accuracy: 0.6345 - val_precision_1: 0.7080 - val_recall_1: 0.5970
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6445 - accuracy: 0.6250 - precision_1: 0.5333 - recall_1: 0.6154
Epoch 19: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6828 - precision_1: 0.7281 - recall_1: 0.6222 - val_loss: 0.6328 - val_accuracy: 0.6303 - val_precision_1: 0.7130 - val_recall_1: 0.5746
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5192 - accuracy: 0.7500 - precision_1: 0.8333 - recall_1: 0.6250
Epoch 20: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6859 - precision_1: 0.7356 - recall_1: 0.6182 - val_loss: 0.6327 - val_accuracy: 0.6303 - val_precision_1: 0.7130 - val_recall_1: 0.5746
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6474 - accuracy: 0.6250 - precision_1: 0.7059 - recall_1: 0.6316
Epoch 21: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6859 - precision_1: 0.7356 - recall_1: 0.6182 - val_loss: 0.6332 - val_accuracy: 0.6303 - val_precision_1: 0.7130 - val_recall_1: 0.5746
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5655 - accuracy: 0.7188 - precision_1: 0.7368 - recall_1: 0.7778
Epoch 22: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.6859 - precision_1: 0.7356 - recall_1: 0.6182 - val_loss: 0.6332 - val_accuracy: 0.6303 - val_precision_1: 0.7130 - val_recall_1: 0.5746
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5775 - accuracy: 0.6875 - precision_1: 0.7000 - recall_1: 0.5000
Epoch 23: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6901 - precision_1: 0.7427 - recall_1: 0.6182 - val_loss: 0.6323 - val_accuracy: 0.6303 - val_precision_1: 0.7130 - val_recall_1: 0.5746
Epoch 23: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="exercise-angina">exercise angina<a class="anchor-link" href="#exercise-angina">¶</a></h2><ul>
<li>val_accuracy: 0.7479</li>
<li>val_loss: 0.5573</li>
<li>val_precision: 0.8173</li>
<li>val_recall: 0.6746</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [165]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">ang_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"ang_model"</span><span class="p">)</span>
<span class="n">ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">ang_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">ang_history</span> <span class="o">=</span> <span class="n">ang_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.6950 - accuracy: 0.4375 - precision_1: 0.6500 - recall_1: 0.6149
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 11ms/step - loss: 0.6606 - accuracy: 0.5987 - precision_1: 0.5948 - recall_1: 0.7933 - val_loss: 0.6260 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6744 - accuracy: 0.5625 - precision_1: 0.6667 - recall_1: 0.4444
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6360 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5956 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5947 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5697 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6026 - accuracy: 0.6875 - precision_1: 0.9000 - recall_1: 0.5000
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5517 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6141 - accuracy: 0.7188 - precision_1: 0.8571 - recall_1: 0.4286
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5417 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6165 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.6000
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5322 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7241 - accuracy: 0.5938 - precision_1: 0.5455 - recall_1: 0.4286
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5253 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5897 - accuracy: 0.7188 - precision_1: 0.7857 - recall_1: 0.6471
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5218 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7025 - accuracy: 0.5938 - precision_1: 0.6364 - recall_1: 0.4375
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5195 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6326 - accuracy: 0.7188 - precision_1: 0.6667 - recall_1: 0.7143
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5174 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5027 - accuracy: 0.7812 - precision_1: 0.9231 - recall_1: 0.6667
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5168 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5147 - accuracy: 0.7500 - precision_1: 0.9286 - recall_1: 0.6500
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5161 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5604 - accuracy: 0.7188 - precision_1: 0.8571 - recall_1: 0.6316
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5158 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6272 - accuracy: 0.6562 - precision_1: 0.7857 - recall_1: 0.5789
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5171 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7176 - accuracy: 0.5938 - precision_1: 0.6429 - recall_1: 0.5294
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5164 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6082 - accuracy: 0.6562 - precision_1: 0.8462 - recall_1: 0.5500
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5167 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5833 - accuracy: 0.6875 - precision_1: 0.9000 - recall_1: 0.5000
Epoch 17: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5180 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5633 - accuracy: 0.7188 - precision_1: 0.9000 - recall_1: 0.5294
Epoch 18: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5171 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4721 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 19: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5167 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6433 - accuracy: 0.6250 - precision_1: 0.8571 - recall_1: 0.3529
Epoch 20: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5158 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5154 - accuracy: 0.7500 - precision_1: 1.0000 - recall_1: 0.5556
Epoch 21: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5162 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6736 - accuracy: 0.6562 - precision_1: 0.5714 - recall_1: 0.3333
Epoch 22: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5164 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5190 - accuracy: 0.8125 - precision_1: 0.8182 - recall_1: 0.6923
Epoch 23: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5166 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5204 - accuracy: 0.7812 - precision_1: 0.9000 - recall_1: 0.6000
Epoch 24: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5174 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6548 - accuracy: 0.6875 - precision_1: 0.6429 - recall_1: 0.6429
Epoch 25: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5176 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6890 - accuracy: 0.5938 - precision_1: 0.7333 - recall_1: 0.5500
Epoch 26: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5173 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5143 - accuracy: 0.7812 - precision_1: 0.9091 - recall_1: 0.6250
Epoch 27: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5172 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6742 - accuracy: 0.6250 - precision_1: 0.7000 - recall_1: 0.4375
Epoch 28: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7185 - precision_1: 0.8093 - recall_1: 0.6000 - val_loss: 0.5178 - val_accuracy: 0.7647 - val_precision_1: 0.9149 - val_recall_1: 0.6418
Epoch 28: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="oldpeak">oldpeak<a class="anchor-link" href="#oldpeak">¶</a></h2><ul>
<li>val_accuracy: 0.7437</li>
<li>val_loss: 0.5588</li>
<li>val_precision: 0.7519</li>
<li>val_recall: 0.7698</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [166]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">peak_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"peak_model"</span><span class="p">)</span>
<span class="n">peak_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">peak_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">peak_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">peak_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">peak_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">peak_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">peak_history</span> <span class="o">=</span> <span class="n">peak_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 18s - loss: 0.7119 - accuracy: 0.4688 - precision_1: 0.9149 - recall_1: 0.5695
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 10ms/step - loss: 0.6892 - accuracy: 0.5609 - precision_1: 0.7524 - recall_1: 0.3672 - val_loss: 0.6788 - val_accuracy: 0.6555 - val_precision_1: 0.7549 - val_recall_1: 0.5746
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6748 - accuracy: 0.6875 - precision_1: 0.6923 - recall_1: 0.6000
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.7048 - precision_1: 0.7306 - recall_1: 0.6848 - val_loss: 0.6541 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6529 - accuracy: 0.6875 - precision_1: 0.7500 - recall_1: 0.5625
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.6352 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6711 - accuracy: 0.5938 - precision_1: 0.7143 - recall_1: 0.5263
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.6217 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6648 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.6250
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.6121 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5781 - accuracy: 0.7188 - precision_1: 0.7222 - recall_1: 0.7647
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.6057 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6959 - accuracy: 0.5625 - precision_1: 0.6429 - recall_1: 0.5000
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.6018 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5389 - accuracy: 0.7188 - precision_1: 0.7368 - recall_1: 0.7778
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5983 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5975 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5580 - accuracy: 0.7188 - precision_1: 0.8235 - recall_1: 0.7000
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5963 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5719 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7895
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5957 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5545 - accuracy: 0.7812 - precision_1: 0.8667 - recall_1: 0.7222
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5968 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5952 - accuracy: 0.6562 - precision_1: 0.8182 - recall_1: 0.5000
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5952 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7082 - accuracy: 0.5938 - precision_1: 0.4706 - recall_1: 0.6667
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5951 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6052 - accuracy: 0.7500 - precision_1: 0.8235 - recall_1: 0.7368
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5940 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6931 - accuracy: 0.6250 - precision_1: 0.5556 - recall_1: 0.7143
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5947 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5286 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.6667
Epoch 17: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5942 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7249 - accuracy: 0.5938 - precision_1: 0.4444 - recall_1: 0.3333
Epoch 18: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5943 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6757 - accuracy: 0.6562 - precision_1: 0.6875 - recall_1: 0.6471
Epoch 19: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5935 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6142 - accuracy: 0.6562 - precision_1: 0.7333 - recall_1: 0.6111
Epoch 20: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5941 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.8012 - accuracy: 0.5312 - precision_1: 0.4375 - recall_1: 0.5385
Epoch 21: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5945 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5724 - accuracy: 0.7812 - precision_1: 0.7059 - recall_1: 0.8571
Epoch 22: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5947 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5456 - accuracy: 0.7500 - precision_1: 0.8235 - recall_1: 0.7368
Epoch 23: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5935 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5713 - accuracy: 0.7188 - precision_1: 0.7857 - recall_1: 0.6471
Epoch 24: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5952 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6650 - accuracy: 0.6562 - precision_1: 0.6923 - recall_1: 0.5625
Epoch 25: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7069 - precision_1: 0.7318 - recall_1: 0.6889 - val_loss: 0.5945 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6987 - accuracy: 0.5938 - precision_1: 0.6316 - recall_1: 0.6667
Epoch 26: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5944 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5432 - accuracy: 0.7500 - precision_1: 0.7857 - recall_1: 0.6875
Epoch 27: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5932 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6064 - accuracy: 0.7188 - precision_1: 0.7059 - recall_1: 0.7500
Epoch 28: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5934 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5678 - accuracy: 0.7188 - precision_1: 0.8750 - recall_1: 0.6667
Epoch 29: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5935 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5545 - accuracy: 0.7812 - precision_1: 0.9231 - recall_1: 0.6667
Epoch 30: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5928 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6560 - accuracy: 0.6250 - precision_1: 0.6667 - recall_1: 0.5882
Epoch 31: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5924 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5571 - accuracy: 0.7188 - precision_1: 0.8750 - recall_1: 0.6667
Epoch 32: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5938 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5205 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 33: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5934 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6617 - accuracy: 0.5938 - precision_1: 0.6111 - recall_1: 0.6471
Epoch 34: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5931 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5376 - accuracy: 0.6875 - precision_1: 0.7500 - recall_1: 0.6667
Epoch 35: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5933 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6034 - accuracy: 0.6250 - precision_1: 0.5714 - recall_1: 0.5714
Epoch 36: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7080 - precision_1: 0.7333 - recall_1: 0.6889 - val_loss: 0.5930 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5557 - accuracy: 0.7812 - precision_1: 0.6842 - recall_1: 0.9286
Epoch 37: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5936 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4855 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 38: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5931 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5587 - accuracy: 0.7500 - precision_1: 0.6667 - recall_1: 0.8571
Epoch 39: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5931 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6641 - accuracy: 0.6562 - precision_1: 0.6471 - recall_1: 0.6875
Epoch 40: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7080 - precision_1: 0.7333 - recall_1: 0.6889 - val_loss: 0.5926 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5669 - accuracy: 0.7500 - precision_1: 0.6667 - recall_1: 0.7692
Epoch 41: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5921 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4984 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 42: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5926 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.8360 - accuracy: 0.5000 - precision_1: 0.3333 - recall_1: 0.4545
Epoch 43: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5934 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5358 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.8333
Epoch 44: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5940 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6048 - accuracy: 0.6250 - precision_1: 0.6500 - recall_1: 0.7222
Epoch 45: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7080 - precision_1: 0.7364 - recall_1: 0.6828 - val_loss: 0.5928 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4600 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 46: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5940 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6388 - accuracy: 0.6562 - precision_1: 0.5333 - recall_1: 0.6667
Epoch 47: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7059 - precision_1: 0.7342 - recall_1: 0.6808 - val_loss: 0.5934 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6097 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.6250
Epoch 48: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7059 - precision_1: 0.7322 - recall_1: 0.6848 - val_loss: 0.5931 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6235 - accuracy: 0.6562 - precision_1: 0.6154 - recall_1: 0.5714
Epoch 49: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5940 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6309 - accuracy: 0.6250 - precision_1: 0.7647 - recall_1: 0.6190
Epoch 50: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7059 - precision_1: 0.7342 - recall_1: 0.6808 - val_loss: 0.5934 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5680 - accuracy: 0.7188 - precision_1: 0.7647 - recall_1: 0.7222
Epoch 51: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7059 - precision_1: 0.7312 - recall_1: 0.6869 - val_loss: 0.5923 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5858 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.7500
Epoch 52: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5919 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6903 - accuracy: 0.6250 - precision_1: 0.6111 - recall_1: 0.6875
Epoch 53: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5913 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5770 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.6667
Epoch 54: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7038 - precision_1: 0.7290 - recall_1: 0.6848 - val_loss: 0.5908 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7392 - accuracy: 0.4688 - precision_1: 0.5625 - recall_1: 0.4737
Epoch 55: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5921 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6025 - accuracy: 0.7188 - precision_1: 0.6923 - recall_1: 0.6429
Epoch 56: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5913 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5120 - accuracy: 0.7812 - precision_1: 0.7333 - recall_1: 0.7857
Epoch 57: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7080 - precision_1: 0.7323 - recall_1: 0.6909 - val_loss: 0.5914 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5695 - accuracy: 0.7188 - precision_1: 0.7895 - recall_1: 0.7500
Epoch 58: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5929 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6716 - accuracy: 0.5938 - precision_1: 0.7059 - recall_1: 0.6000
Epoch 59: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5918 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6031 - accuracy: 0.6875 - precision_1: 0.7059 - recall_1: 0.7059
Epoch 60: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7069 - precision_1: 0.7338 - recall_1: 0.6848 - val_loss: 0.5908 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6065 - accuracy: 0.7188 - precision_1: 0.7857 - recall_1: 0.6471
Epoch 61: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5936 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7163 - accuracy: 0.5625 - precision_1: 0.6111 - recall_1: 0.6111
Epoch 62: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7059 - precision_1: 0.7332 - recall_1: 0.6828 - val_loss: 0.5910 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5940 - accuracy: 0.7188 - precision_1: 0.6154 - recall_1: 0.6667
Epoch 63: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5902 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6261 - accuracy: 0.6562 - precision_1: 0.6111 - recall_1: 0.7333
Epoch 64: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7059 - precision_1: 0.7302 - recall_1: 0.6889 - val_loss: 0.5922 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7625 - accuracy: 0.5625 - precision_1: 0.6875 - recall_1: 0.5500
Epoch 65: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7080 - precision_1: 0.7343 - recall_1: 0.6869 - val_loss: 0.5916 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6311 - accuracy: 0.6562 - precision_1: 0.7500 - recall_1: 0.6316
Epoch 66: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7048 - precision_1: 0.7316 - recall_1: 0.6828 - val_loss: 0.5904 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5512 - accuracy: 0.7188 - precision_1: 0.8667 - recall_1: 0.6500
Epoch 67: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7069 - precision_1: 0.7338 - recall_1: 0.6848 - val_loss: 0.5918 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6102 - accuracy: 0.6562 - precision_1: 0.7500 - recall_1: 0.6316
Epoch 68: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5927 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5876 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.8333
Epoch 69: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7101 - precision_1: 0.7407 - recall_1: 0.6808 - val_loss: 0.5909 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5235 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 70: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7080 - precision_1: 0.7313 - recall_1: 0.6929 - val_loss: 0.5948 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6352 - accuracy: 0.6250 - precision_1: 0.6667 - recall_1: 0.6667
Epoch 71: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.7101 - precision_1: 0.7428 - recall_1: 0.6768 - val_loss: 0.5934 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5932 - accuracy: 0.7188 - precision_1: 0.5294 - recall_1: 0.9000
Epoch 72: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7080 - precision_1: 0.7354 - recall_1: 0.6848 - val_loss: 0.5915 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5930 - accuracy: 0.7500 - precision_1: 0.7778 - recall_1: 0.7778
Epoch 73: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7080 - precision_1: 0.7354 - recall_1: 0.6848 - val_loss: 0.5910 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5953 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7059
Epoch 74: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7080 - precision_1: 0.7313 - recall_1: 0.6929 - val_loss: 0.5919 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5284 - accuracy: 0.7188 - precision_1: 0.6250 - recall_1: 0.7692
Epoch 75: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7090 - precision_1: 0.7401 - recall_1: 0.6788 - val_loss: 0.5898 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6152 - accuracy: 0.6875 - precision_1: 0.7857 - recall_1: 0.6111
Epoch 76: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5893 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5804 - accuracy: 0.7500 - precision_1: 0.8571 - recall_1: 0.6667
Epoch 77: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7101 - precision_1: 0.7355 - recall_1: 0.6909 - val_loss: 0.5931 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5755 - accuracy: 0.7500 - precision_1: 0.7222 - recall_1: 0.8125
Epoch 78: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7143 - precision_1: 0.7483 - recall_1: 0.6788 - val_loss: 0.5911 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7253 - accuracy: 0.5625 - precision_1: 0.6667 - recall_1: 0.5263
Epoch 79: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7122 - precision_1: 0.7356 - recall_1: 0.6970 - val_loss: 0.5921 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5805 - accuracy: 0.6875 - precision_1: 0.7333 - recall_1: 0.6471
Epoch 80: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7111 - precision_1: 0.7391 - recall_1: 0.6869 - val_loss: 0.5908 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6098 - accuracy: 0.6875 - precision_1: 0.7778 - recall_1: 0.7000
Epoch 81: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7080 - precision_1: 0.7354 - recall_1: 0.6848 - val_loss: 0.5906 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4687 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 82: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7059 - precision_1: 0.7302 - recall_1: 0.6889 - val_loss: 0.5918 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4220 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 83: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7069 - precision_1: 0.7368 - recall_1: 0.6788 - val_loss: 0.5908 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6428 - accuracy: 0.6562 - precision_1: 0.5882 - recall_1: 0.7143
Epoch 84: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7101 - precision_1: 0.7375 - recall_1: 0.6869 - val_loss: 0.5909 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6339 - accuracy: 0.6562 - precision_1: 0.8000 - recall_1: 0.4706
Epoch 85: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7122 - precision_1: 0.7418 - recall_1: 0.6848 - val_loss: 0.5904 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5724 - accuracy: 0.6875 - precision_1: 0.8571 - recall_1: 0.6000
Epoch 86: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7090 - precision_1: 0.7319 - recall_1: 0.6949 - val_loss: 0.5917 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5925 - accuracy: 0.6875 - precision_1: 0.8000 - recall_1: 0.7273
Epoch 87: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5901 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5283 - accuracy: 0.7812 - precision_1: 0.9333 - recall_1: 0.7000
Epoch 88: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.7059 - precision_1: 0.7302 - recall_1: 0.6889 - val_loss: 0.5920 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5659 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 89: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7122 - precision_1: 0.7429 - recall_1: 0.6828 - val_loss: 0.5889 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6336 - accuracy: 0.6562 - precision_1: 0.5625 - recall_1: 0.6923
Epoch 90: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7132 - precision_1: 0.7434 - recall_1: 0.6848 - val_loss: 0.5874 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6639 - accuracy: 0.5938 - precision_1: 0.6471 - recall_1: 0.6111
Epoch 91: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7132 - precision_1: 0.7342 - recall_1: 0.7030 - val_loss: 0.5886 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5001 - accuracy: 0.8125 - precision_1: 1.0000 - recall_1: 0.6471
Epoch 92: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7101 - precision_1: 0.7325 - recall_1: 0.6970 - val_loss: 0.5921 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5907 - accuracy: 0.7188 - precision_1: 0.7778 - recall_1: 0.7368
Epoch 93: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7111 - precision_1: 0.7391 - recall_1: 0.6869 - val_loss: 0.5900 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5934 - accuracy: 0.6875 - precision_1: 0.7143 - recall_1: 0.6250
Epoch 94: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7069 - precision_1: 0.7308 - recall_1: 0.6909 - val_loss: 0.5892 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4877 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 95: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7111 - precision_1: 0.7321 - recall_1: 0.7010 - val_loss: 0.5919 - val_accuracy: 0.6891 - val_precision_1: 0.7830 - val_recall_1: 0.6194
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5160 - accuracy: 0.7500 - precision_1: 0.9375 - recall_1: 0.6818
Epoch 96: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7090 - precision_1: 0.7319 - recall_1: 0.6949 - val_loss: 0.5902 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6949 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.7059
Epoch 97: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7111 - precision_1: 0.7331 - recall_1: 0.6990 - val_loss: 0.5915 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4574 - accuracy: 0.8438 - precision_1: 0.9444 - recall_1: 0.8095
Epoch 98: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7101 - precision_1: 0.7325 - recall_1: 0.6970 - val_loss: 0.5888 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5615 - accuracy: 0.7500 - precision_1: 0.8421 - recall_1: 0.7619
Epoch 99: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7111 - precision_1: 0.7321 - recall_1: 0.7010 - val_loss: 0.5896 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6119 - accuracy: 0.6875 - precision_1: 0.6250 - recall_1: 0.7143
Epoch 100: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7143 - precision_1: 0.7388 - recall_1: 0.6970 - val_loss: 0.5903 - val_accuracy: 0.6891 - val_precision_1: 0.7727 - val_recall_1: 0.6343
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="ST-slope">ST slope<a class="anchor-link" href="#ST-slope">¶</a></h2><ul>
<li>val_accuracy: 0.7731</li>
<li>val_loss: 0.5739</li>
<li>val_precision: 0.7687</li>
<li>val_recall: 0.8175</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [167]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">slop_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"slop_model"</span><span class="p">)</span>
<span class="n">slop_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,)))</span>
<span class="n">slop_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">slop_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">slop_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">slop_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">slop_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">slop_history</span> <span class="o">=</span> <span class="n">slop_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">[:,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALID</span><span class="p">[:,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 18s - loss: 0.7190 - accuracy: 0.5312 - precision_1: 0.7183 - recall_1: 0.6755
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 11ms/step - loss: 0.6935 - accuracy: 0.5200 - precision_1: 0.5461 - recall_1: 0.9221 - val_loss: 0.6794 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6799 - accuracy: 0.4688 - precision_1: 0.4688 - recall_1: 1.0000
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.5200 - precision_1: 0.5200 - recall_1: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.5630 - val_precision_1: 0.5630 - val_recall_1: 1.0000
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6406 - accuracy: 0.5938 - precision_1: 0.5938 - recall_1: 1.0000
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.7164 - precision_1: 0.6772 - recall_1: 0.8687 - val_loss: 0.6513 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6495 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8889
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.7952 - precision_1: 0.7852 - recall_1: 0.8343 - val_loss: 0.6366 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6259 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.6234 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5741 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 6: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.6110 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6365 - accuracy: 0.8125 - precision_1: 0.7059 - recall_1: 0.9231
Epoch 7: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.6005 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6901 - accuracy: 0.6250 - precision_1: 0.5385 - recall_1: 0.5385
Epoch 8: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5918 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6253 - accuracy: 0.7812 - precision_1: 0.6818 - recall_1: 1.0000
Epoch 9: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5842 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6203 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 10: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5781 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5720 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 11: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5731 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5004 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 12: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5694 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5648 - accuracy: 0.7500 - precision_1: 0.7778 - recall_1: 0.7778
Epoch 13: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5673 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5405 - accuracy: 0.7812 - precision_1: 0.6923 - recall_1: 0.7500
Epoch 14: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5670 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4774 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 15: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5682 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5276 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 16: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5691 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4172 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 17: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5709 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4782 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.8571
Epoch 18: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5715 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5207 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 19: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5720 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4110 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 20: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5725 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4354 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 21: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5717 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4629 - accuracy: 0.8438 - precision_1: 0.9444 - recall_1: 0.8095
Epoch 22: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5724 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5414 - accuracy: 0.7812 - precision_1: 0.7368 - recall_1: 0.8750
Epoch 23: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5728 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7758 - accuracy: 0.6250 - precision_1: 0.6250 - recall_1: 0.6250
Epoch 24: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5729 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5927 - accuracy: 0.7500 - precision_1: 0.7000 - recall_1: 0.8750
Epoch 25: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5728 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3991 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 26: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5723 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3907 - accuracy: 0.8750 - precision_1: 0.7333 - recall_1: 1.0000
Epoch 27: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5722 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5245 - accuracy: 0.7812 - precision_1: 0.7391 - recall_1: 0.9444
Epoch 28: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5728 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6219 - accuracy: 0.6875 - precision_1: 0.5333 - recall_1: 0.7273
Epoch 29: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7941 - precision_1: 0.7848 - recall_1: 0.8323 - val_loss: 0.5723 - val_accuracy: 0.7479 - val_precision_1: 0.7681 - val_recall_1: 0.7910
Epoch 29: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Plot-feature-importance">Plot feature importance<a class="anchor-link" href="#Plot-feature-importance">¶</a></h2>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [168]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">sl</span> <span class="o">=</span> <span class="n">slop_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">pk</span> <span class="o">=</span> <span class="n">peak_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">age</span> <span class="o">=</span> <span class="n">age_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sex</span> <span class="o">=</span> <span class="n">sex_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ecg</span> <span class="o">=</span> <span class="n">ecg_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ang</span> <span class="o">=</span> <span class="n">ang_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">chest</span> <span class="o">=</span> <span class="n">chest_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">bp</span> <span class="o">=</span> <span class="n">bp_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ch</span> <span class="o">=</span> <span class="n">ch_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">bs</span> <span class="o">=</span> <span class="n">bs_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">heart</span> <span class="o">=</span> <span class="n">heart_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">plot_feature_importance</span><span class="p">():</span>
  <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'age'</span><span class="p">,</span> <span class="s1">'sex'</span><span class="p">,</span> <span class="s1">'chest pain type'</span><span class="p">,</span> <span class="s1">'resting bp s'</span><span class="p">,</span> <span class="s1">'cholesterol'</span><span class="p">,</span> <span class="s1">'fasting blood sugar'</span><span class="p">,</span><span class="s1">'resting ecg'</span><span class="p">,</span> <span class="s1">'max heart rate'</span><span class="p">,</span> <span class="s1">'exercise angina'</span><span class="p">,</span> <span class="s1">'oldpeak'</span><span class="p">,</span> <span class="s1">'ST slope'</span><span class="p">]</span>
  <span class="n">vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">age</span><span class="p">,</span> <span class="n">sex</span><span class="p">,</span> <span class="n">chest</span><span class="p">,</span> <span class="n">bp</span><span class="p">,</span> <span class="n">ch</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">ecg</span><span class="p">,</span> <span class="n">heart</span><span class="p">,</span> <span class="n">ang</span><span class="p">,</span> <span class="n">pk</span><span class="p">,</span> <span class="n">sl</span><span class="p">]</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">vals</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Feature importance'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_feature_importance</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [169]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1">#['age', 'sex', 'chest pain type', 'resting bp s', 'cholesterol', 'fasting blood sugar',</span>
<span class="c1"># 'resting ecg', 'max heart rate', 'exercise angina', 'oldpeak', 'ST slope', 'target']</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Remove-resting-ecg">Remove resting ecg<a class="anchor-link" href="#Remove-resting-ecg">¶</a></h2><ul>
<li>val_accuracy: 0.8235</li>
<li>val_loss: 0.3971</li>
<li>val_precision: 0.8043</li>
<li>val_recall: 0.8810</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [170]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">ETRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">XTRAIN</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">EVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">XVALID</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_ecg_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_ecg_model"</span><span class="p">)</span>
<span class="n">less_ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,)))</span>
<span class="n">less_ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ecg_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_ecg_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_ecg_history</span> <span class="o">=</span> <span class="n">less_ecg_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ETRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">EVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.7412 - accuracy: 0.3125 - precision_1: 0.7244 - recall_1: 0.7434
Epoch 1: val_loss did not improve from 0.50868
30/30 [==============================] - 1s 11ms/step - loss: 0.7053 - accuracy: 0.4664 - precision_1: 0.5342 - recall_1: 0.7568 - val_loss: 0.6679 - val_accuracy: 0.5840 - val_precision_1: 0.5907 - val_recall_1: 0.8507
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6818 - accuracy: 0.4688 - precision_1: 0.4091 - recall_1: 0.6923
Epoch 2: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6082 - precision_1: 0.5816 - recall_1: 0.8788 - val_loss: 0.6243 - val_accuracy: 0.6807 - val_precision_1: 0.6629 - val_recall_1: 0.8806
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6542 - accuracy: 0.6562 - precision_1: 0.5926 - recall_1: 1.0000
Epoch 3: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.7153 - precision_1: 0.6713 - recall_1: 0.8869 - val_loss: 0.5881 - val_accuracy: 0.7353 - val_precision_1: 0.7320 - val_recall_1: 0.8358
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6008 - accuracy: 0.8750 - precision_1: 0.7857 - recall_1: 0.9167
Epoch 4: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7584 - precision_1: 0.7273 - recall_1: 0.8566 - val_loss: 0.5557 - val_accuracy: 0.7563 - val_precision_1: 0.7676 - val_recall_1: 0.8134
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5743 - accuracy: 0.7812 - precision_1: 0.8571 - recall_1: 0.7059
Epoch 5: val_loss did not improve from 0.50868
30/30 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7679 - precision_1: 0.7482 - recall_1: 0.8343 - val_loss: 0.5264 - val_accuracy: 0.7521 - val_precision_1: 0.7778 - val_recall_1: 0.7836
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4388 - accuracy: 0.8125 - precision_1: 0.8462 - recall_1: 0.9167
Epoch 6: val_loss improved from 0.50868 to 0.50346, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7805 - precision_1: 0.7708 - recall_1: 0.8222 - val_loss: 0.5035 - val_accuracy: 0.7731 - val_precision_1: 0.7985 - val_recall_1: 0.7985
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5306 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 7: val_loss improved from 0.50346 to 0.48623, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7931 - precision_1: 0.7899 - recall_1: 0.8202 - val_loss: 0.4862 - val_accuracy: 0.7857 - val_precision_1: 0.8268 - val_recall_1: 0.7836
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6453 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.7500
Epoch 8: val_loss improved from 0.48623 to 0.47020, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7994 - precision_1: 0.8089 - recall_1: 0.8040 - val_loss: 0.4702 - val_accuracy: 0.7941 - val_precision_1: 0.8512 - val_recall_1: 0.7687
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4176 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 9: val_loss improved from 0.47020 to 0.45757, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7962 - precision_1: 0.8116 - recall_1: 0.7919 - val_loss: 0.4576 - val_accuracy: 0.8067 - val_precision_1: 0.8793 - val_recall_1: 0.7612
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4980 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7059
Epoch 10: val_loss improved from 0.45757 to 0.44654, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.8046 - precision_1: 0.8253 - recall_1: 0.7919 - val_loss: 0.4465 - val_accuracy: 0.8025 - val_precision_1: 0.8783 - val_recall_1: 0.7537
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5230 - accuracy: 0.7188 - precision_1: 0.7857 - recall_1: 0.6471
Epoch 11: val_loss improved from 0.44654 to 0.43686, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8130 - precision_1: 0.8423 - recall_1: 0.7879 - val_loss: 0.4369 - val_accuracy: 0.8067 - val_precision_1: 0.8860 - val_recall_1: 0.7537
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3519 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 12: val_loss improved from 0.43686 to 0.42848, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.8183 - precision_1: 0.8500 - recall_1: 0.7899 - val_loss: 0.4285 - val_accuracy: 0.8025 - val_precision_1: 0.8783 - val_recall_1: 0.7537
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5590 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 13: val_loss improved from 0.42848 to 0.42287, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8235 - precision_1: 0.8516 - recall_1: 0.8000 - val_loss: 0.4229 - val_accuracy: 0.8025 - val_precision_1: 0.8783 - val_recall_1: 0.7537
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4227 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.8421
Epoch 14: val_loss improved from 0.42287 to 0.41974, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8309 - precision_1: 0.8584 - recall_1: 0.8081 - val_loss: 0.4197 - val_accuracy: 0.8151 - val_precision_1: 0.8947 - val_recall_1: 0.7612
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5633 - accuracy: 0.7188 - precision_1: 0.8667 - recall_1: 0.6500
Epoch 15: val_loss improved from 0.41974 to 0.41528, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8309 - precision_1: 0.8584 - recall_1: 0.8081 - val_loss: 0.4153 - val_accuracy: 0.8151 - val_precision_1: 0.8947 - val_recall_1: 0.7612
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3836 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 16: val_loss improved from 0.41528 to 0.41193, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8298 - precision_1: 0.8535 - recall_1: 0.8121 - val_loss: 0.4119 - val_accuracy: 0.8193 - val_precision_1: 0.8957 - val_recall_1: 0.7687
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4306 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 17: val_loss improved from 0.41193 to 0.40809, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8319 - precision_1: 0.8541 - recall_1: 0.8162 - val_loss: 0.4081 - val_accuracy: 0.8193 - val_precision_1: 0.8957 - val_recall_1: 0.7687
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2814 - accuracy: 0.9375 - precision_1: 0.8667 - recall_1: 1.0000
Epoch 18: val_loss improved from 0.40809 to 0.40470, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8309 - precision_1: 0.8538 - recall_1: 0.8141 - val_loss: 0.4047 - val_accuracy: 0.8151 - val_precision_1: 0.8879 - val_recall_1: 0.7687
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4771 - accuracy: 0.7500 - precision_1: 0.9286 - recall_1: 0.6500
Epoch 19: val_loss improved from 0.40470 to 0.39873, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8309 - precision_1: 0.8538 - recall_1: 0.8141 - val_loss: 0.3987 - val_accuracy: 0.8193 - val_precision_1: 0.8889 - val_recall_1: 0.7761
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3579 - accuracy: 0.8438 - precision_1: 0.8182 - recall_1: 0.7500
Epoch 20: val_loss improved from 0.39873 to 0.39556, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8319 - precision_1: 0.8512 - recall_1: 0.8202 - val_loss: 0.3956 - val_accuracy: 0.8277 - val_precision_1: 0.8908 - val_recall_1: 0.7910
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3745 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7500
Epoch 21: val_loss improved from 0.39556 to 0.39539, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8340 - precision_1: 0.8503 - recall_1: 0.8263 - val_loss: 0.3954 - val_accuracy: 0.8277 - val_precision_1: 0.8908 - val_recall_1: 0.7910
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3827 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 22: val_loss improved from 0.39539 to 0.39125, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8330 - precision_1: 0.8500 - recall_1: 0.8242 - val_loss: 0.3912 - val_accuracy: 0.8319 - val_precision_1: 0.8917 - val_recall_1: 0.7985
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2506 - accuracy: 0.9062 - precision_1: 0.8696 - recall_1: 1.0000
Epoch 23: val_loss improved from 0.39125 to 0.38746, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8351 - precision_1: 0.8521 - recall_1: 0.8263 - val_loss: 0.3875 - val_accuracy: 0.8361 - val_precision_1: 0.8926 - val_recall_1: 0.8060
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3613 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 24: val_loss improved from 0.38746 to 0.38392, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3960 - accuracy: 0.8340 - precision_1: 0.8489 - recall_1: 0.8283 - val_loss: 0.3839 - val_accuracy: 0.8403 - val_precision_1: 0.8934 - val_recall_1: 0.8134
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 25: val_loss improved from 0.38392 to 0.38122, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8361 - precision_1: 0.8509 - recall_1: 0.8303 - val_loss: 0.3812 - val_accuracy: 0.8403 - val_precision_1: 0.8934 - val_recall_1: 0.8134
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3906 - accuracy: 0.8438 - precision_1: 0.8696 - recall_1: 0.9091
Epoch 26: val_loss did not improve from 0.38122
30/30 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8361 - precision_1: 0.8480 - recall_1: 0.8343 - val_loss: 0.3825 - val_accuracy: 0.8403 - val_precision_1: 0.9068 - val_recall_1: 0.7985
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3573 - accuracy: 0.9062 - precision_1: 0.9231 - recall_1: 0.8571
Epoch 27: val_loss improved from 0.38122 to 0.37945, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8351 - precision_1: 0.8492 - recall_1: 0.8303 - val_loss: 0.3794 - val_accuracy: 0.8445 - val_precision_1: 0.9076 - val_recall_1: 0.8060
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5587 - accuracy: 0.7812 - precision_1: 0.8750 - recall_1: 0.7368
Epoch 28: val_loss improved from 0.37945 to 0.37307, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8372 - precision_1: 0.8512 - recall_1: 0.8323 - val_loss: 0.3731 - val_accuracy: 0.8445 - val_precision_1: 0.9008 - val_recall_1: 0.8134
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4961 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8000
Epoch 29: val_loss improved from 0.37307 to 0.37229, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3828 - accuracy: 0.8393 - precision_1: 0.8504 - recall_1: 0.8384 - val_loss: 0.3723 - val_accuracy: 0.8445 - val_precision_1: 0.9008 - val_recall_1: 0.8134
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5029 - accuracy: 0.7500 - precision_1: 0.7143 - recall_1: 0.7143
Epoch 30: val_loss improved from 0.37229 to 0.37066, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8393 - precision_1: 0.8504 - recall_1: 0.8384 - val_loss: 0.3707 - val_accuracy: 0.8403 - val_precision_1: 0.9000 - val_recall_1: 0.8060
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4520 - accuracy: 0.8125 - precision_1: 0.8824 - recall_1: 0.7895
Epoch 31: val_loss improved from 0.37066 to 0.36795, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8393 - precision_1: 0.8504 - recall_1: 0.8384 - val_loss: 0.3679 - val_accuracy: 0.8403 - val_precision_1: 0.9000 - val_recall_1: 0.8060
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3009 - accuracy: 0.8750 - precision_1: 0.9375 - recall_1: 0.8333
Epoch 32: val_loss improved from 0.36795 to 0.36664, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8393 - precision_1: 0.8490 - recall_1: 0.8404 - val_loss: 0.3666 - val_accuracy: 0.8361 - val_precision_1: 0.8926 - val_recall_1: 0.8060
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4479 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8000
Epoch 33: val_loss improved from 0.36664 to 0.36496, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3734 - accuracy: 0.8393 - precision_1: 0.8490 - recall_1: 0.8404 - val_loss: 0.3650 - val_accuracy: 0.8403 - val_precision_1: 0.8934 - val_recall_1: 0.8134
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8438 - precision_1: 0.8095 - recall_1: 0.9444
Epoch 34: val_loss improved from 0.36496 to 0.36372, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8393 - precision_1: 0.8490 - recall_1: 0.8404 - val_loss: 0.3637 - val_accuracy: 0.8403 - val_precision_1: 0.8934 - val_recall_1: 0.8134
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3441 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.7692
Epoch 35: val_loss did not improve from 0.36372
30/30 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8393 - precision_1: 0.8476 - recall_1: 0.8424 - val_loss: 0.3641 - val_accuracy: 0.8403 - val_precision_1: 0.8934 - val_recall_1: 0.8134
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4685 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 36: val_loss improved from 0.36372 to 0.36226, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8414 - precision_1: 0.8510 - recall_1: 0.8424 - val_loss: 0.3623 - val_accuracy: 0.8403 - val_precision_1: 0.8934 - val_recall_1: 0.8134
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4872 - accuracy: 0.7500 - precision_1: 0.7000 - recall_1: 0.8750
Epoch 37: val_loss improved from 0.36226 to 0.36128, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8403 - precision_1: 0.8465 - recall_1: 0.8465 - val_loss: 0.3613 - val_accuracy: 0.8445 - val_precision_1: 0.9008 - val_recall_1: 0.8134
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3951 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 38: val_loss improved from 0.36128 to 0.35809, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8414 - precision_1: 0.8482 - recall_1: 0.8465 - val_loss: 0.3581 - val_accuracy: 0.8445 - val_precision_1: 0.8943 - val_recall_1: 0.8209
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3359 - accuracy: 0.8125 - precision_1: 0.8462 - recall_1: 0.7333
Epoch 39: val_loss improved from 0.35809 to 0.35639, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8414 - precision_1: 0.8482 - recall_1: 0.8465 - val_loss: 0.3564 - val_accuracy: 0.8403 - val_precision_1: 0.8934 - val_recall_1: 0.8134
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4023 - accuracy: 0.7812 - precision_1: 0.6154 - recall_1: 0.8000
Epoch 40: val_loss did not improve from 0.35639
30/30 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8403 - precision_1: 0.8465 - recall_1: 0.8465 - val_loss: 0.3565 - val_accuracy: 0.8445 - val_precision_1: 0.9008 - val_recall_1: 0.8134
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3084 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 41: val_loss improved from 0.35639 to 0.35479, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8393 - precision_1: 0.8462 - recall_1: 0.8444 - val_loss: 0.3548 - val_accuracy: 0.8487 - val_precision_1: 0.8952 - val_recall_1: 0.8284
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3803 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 42: val_loss improved from 0.35479 to 0.35190, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3564 - accuracy: 0.8456 - precision_1: 0.8508 - recall_1: 0.8525 - val_loss: 0.3519 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3589 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 43: val_loss did not improve from 0.35190
30/30 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8435 - precision_1: 0.8460 - recall_1: 0.8545 - val_loss: 0.3541 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8750 - precision_1: 0.9412 - recall_1: 0.8421
Epoch 44: val_loss did not improve from 0.35190
30/30 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8466 - precision_1: 0.8511 - recall_1: 0.8545 - val_loss: 0.3529 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3157 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 45: val_loss improved from 0.35190 to 0.35076, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8477 - precision_1: 0.8528 - recall_1: 0.8545 - val_loss: 0.3508 - val_accuracy: 0.8529 - val_precision_1: 0.8898 - val_recall_1: 0.8433
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2439 - accuracy: 0.9375 - precision_1: 0.9412 - recall_1: 0.9412
Epoch 46: val_loss improved from 0.35076 to 0.35068, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8487 - precision_1: 0.8531 - recall_1: 0.8566 - val_loss: 0.3507 - val_accuracy: 0.8613 - val_precision_1: 0.8976 - val_recall_1: 0.8507
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4766 - accuracy: 0.6562 - precision_1: 0.6000 - recall_1: 0.8000
Epoch 47: val_loss improved from 0.35068 to 0.34889, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8508 - precision_1: 0.8566 - recall_1: 0.8566 - val_loss: 0.3489 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3050 - accuracy: 0.8750 - precision_1: 0.9375 - recall_1: 0.8333
Epoch 48: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8487 - precision_1: 0.8489 - recall_1: 0.8626 - val_loss: 0.3504 - val_accuracy: 0.8613 - val_precision_1: 0.8976 - val_recall_1: 0.8507
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1243 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 49: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8477 - precision_1: 0.8472 - recall_1: 0.8626 - val_loss: 0.3515 - val_accuracy: 0.8613 - val_precision_1: 0.8976 - val_recall_1: 0.8507
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1422 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 50: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8498 - precision_1: 0.8520 - recall_1: 0.8606 - val_loss: 0.3501 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3092 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 51: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8477 - precision_1: 0.8458 - recall_1: 0.8646 - val_loss: 0.3514 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4279 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 52: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8466 - precision_1: 0.8469 - recall_1: 0.8606 - val_loss: 0.3513 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4622 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.7500
Epoch 53: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8519 - precision_1: 0.8526 - recall_1: 0.8646 - val_loss: 0.3508 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1944 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9474
Epoch 54: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8540 - precision_1: 0.8546 - recall_1: 0.8667 - val_loss: 0.3512 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2484 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 55: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8519 - precision_1: 0.8512 - recall_1: 0.8667 - val_loss: 0.3492 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2935 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 56: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8561 - precision_1: 0.8552 - recall_1: 0.8707 - val_loss: 0.3491 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2443 - accuracy: 0.9375 - precision_1: 0.9412 - recall_1: 0.9412
Epoch 57: val_loss did not improve from 0.34889
30/30 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8561 - precision_1: 0.8538 - recall_1: 0.8727 - val_loss: 0.3508 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8438 - precision_1: 0.8095 - recall_1: 0.9444
Epoch 58: val_loss improved from 0.34889 to 0.34545, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8592 - precision_1: 0.8588 - recall_1: 0.8727 - val_loss: 0.3455 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3161 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 59: val_loss did not improve from 0.34545
30/30 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8582 - precision_1: 0.8529 - recall_1: 0.8788 - val_loss: 0.3463 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3596 - accuracy: 0.8125 - precision_1: 0.6429 - recall_1: 0.9000
Epoch 60: val_loss did not improve from 0.34545
30/30 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8603 - precision_1: 0.8577 - recall_1: 0.8768 - val_loss: 0.3476 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5291 - accuracy: 0.7812 - precision_1: 0.8889 - recall_1: 0.7619
Epoch 61: val_loss did not improve from 0.34545
30/30 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8624 - precision_1: 0.8611 - recall_1: 0.8768 - val_loss: 0.3464 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3558 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 62: val_loss did not improve from 0.34545
30/30 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8603 - precision_1: 0.8577 - recall_1: 0.8768 - val_loss: 0.3459 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2786 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 63: val_loss did not improve from 0.34545
30/30 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8603 - precision_1: 0.8563 - recall_1: 0.8788 - val_loss: 0.3492 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 64: val_loss did not improve from 0.34545
30/30 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8592 - precision_1: 0.8560 - recall_1: 0.8768 - val_loss: 0.3476 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5308 - accuracy: 0.7500 - precision_1: 0.8125 - recall_1: 0.7222
Epoch 65: val_loss did not improve from 0.34545
30/30 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8613 - precision_1: 0.8594 - recall_1: 0.8768 - val_loss: 0.3482 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3575 - accuracy: 0.8125 - precision_1: 0.8462 - recall_1: 0.7333
Epoch 66: val_loss improved from 0.34545 to 0.34543, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3208 - accuracy: 0.8603 - precision_1: 0.8591 - recall_1: 0.8747 - val_loss: 0.3454 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3128 - accuracy: 0.8750 - precision_1: 0.9167 - recall_1: 0.7857
Epoch 67: val_loss did not improve from 0.34543
30/30 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8613 - precision_1: 0.8580 - recall_1: 0.8788 - val_loss: 0.3478 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2384 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 68: val_loss improved from 0.34543 to 0.34487, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8634 - precision_1: 0.8628 - recall_1: 0.8768 - val_loss: 0.3449 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3398 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.8571
Epoch 69: val_loss improved from 0.34487 to 0.34310, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8634 - precision_1: 0.8657 - recall_1: 0.8727 - val_loss: 0.3431 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2514 - accuracy: 0.9062 - precision_1: 0.8235 - recall_1: 1.0000
Epoch 70: val_loss improved from 0.34310 to 0.33952, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8624 - precision_1: 0.8655 - recall_1: 0.8707 - val_loss: 0.3395 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2014 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 71: val_loss improved from 0.33952 to 0.33877, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8645 - precision_1: 0.8660 - recall_1: 0.8747 - val_loss: 0.3388 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8947
Epoch 72: val_loss did not improve from 0.33877
30/30 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8634 - precision_1: 0.8643 - recall_1: 0.8747 - val_loss: 0.3408 - val_accuracy: 0.8529 - val_precision_1: 0.8898 - val_recall_1: 0.8433
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3673 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8889
Epoch 73: val_loss did not improve from 0.33877
30/30 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8655 - precision_1: 0.8663 - recall_1: 0.8768 - val_loss: 0.3412 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2762 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 74: val_loss did not improve from 0.33877
30/30 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.8655 - precision_1: 0.8707 - recall_1: 0.8707 - val_loss: 0.3392 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2658 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 75: val_loss improved from 0.33877 to 0.33835, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8718 - precision_1: 0.8753 - recall_1: 0.8788 - val_loss: 0.3384 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3459 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 76: val_loss improved from 0.33835 to 0.33617, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.8666 - precision_1: 0.8695 - recall_1: 0.8747 - val_loss: 0.3362 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2871 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 77: val_loss did not improve from 0.33617
30/30 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.8697 - precision_1: 0.8688 - recall_1: 0.8828 - val_loss: 0.3404 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3616 - accuracy: 0.8438 - precision_1: 0.9474 - recall_1: 0.8182
Epoch 78: val_loss did not improve from 0.33617
30/30 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.8718 - precision_1: 0.8768 - recall_1: 0.8768 - val_loss: 0.3408 - val_accuracy: 0.8403 - val_precision_1: 0.8871 - val_recall_1: 0.8209
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1095 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 79: val_loss did not improve from 0.33617
30/30 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8750 - precision_1: 0.8806 - recall_1: 0.8788 - val_loss: 0.3409 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2775 - accuracy: 0.9062 - precision_1: 0.8636 - recall_1: 1.0000
Epoch 80: val_loss did not improve from 0.33617
30/30 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8739 - precision_1: 0.8819 - recall_1: 0.8747 - val_loss: 0.3385 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.9474
Epoch 81: val_loss improved from 0.33617 to 0.33137, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.3053 - accuracy: 0.8792 - precision_1: 0.8862 - recall_1: 0.8808 - val_loss: 0.3314 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3281 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8889
Epoch 82: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8739 - precision_1: 0.8728 - recall_1: 0.8869 - val_loss: 0.3349 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3195 - accuracy: 0.8438 - precision_1: 0.7895 - recall_1: 0.9375
Epoch 83: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8739 - precision_1: 0.8728 - recall_1: 0.8869 - val_loss: 0.3397 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2479 - accuracy: 0.9375 - precision_1: 0.9500 - recall_1: 0.9500
Epoch 84: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8771 - precision_1: 0.8841 - recall_1: 0.8788 - val_loss: 0.3374 - val_accuracy: 0.8529 - val_precision_1: 0.8960 - val_recall_1: 0.8358
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4216 - accuracy: 0.7812 - precision_1: 0.8500 - recall_1: 0.8095
Epoch 85: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8718 - precision_1: 0.8708 - recall_1: 0.8848 - val_loss: 0.3434 - val_accuracy: 0.8529 - val_precision_1: 0.8960 - val_recall_1: 0.8358
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3976 - accuracy: 0.8438 - precision_1: 0.9412 - recall_1: 0.8000
Epoch 86: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8750 - precision_1: 0.8837 - recall_1: 0.8747 - val_loss: 0.3364 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2807 - accuracy: 0.9375 - precision_1: 0.9500 - recall_1: 0.9500
Epoch 87: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8803 - precision_1: 0.8880 - recall_1: 0.8808 - val_loss: 0.3386 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4522 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 88: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8792 - precision_1: 0.8846 - recall_1: 0.8828 - val_loss: 0.3368 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1771 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9524
Epoch 89: val_loss did not improve from 0.33137
30/30 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8792 - precision_1: 0.8831 - recall_1: 0.8848 - val_loss: 0.3390 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 90: val_loss improved from 0.33137 to 0.33109, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2998 - accuracy: 0.8824 - precision_1: 0.8932 - recall_1: 0.8788 - val_loss: 0.3311 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3776 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.9524
Epoch 91: val_loss did not improve from 0.33109
30/30 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8771 - precision_1: 0.8780 - recall_1: 0.8869 - val_loss: 0.3360 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4258 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 92: val_loss did not improve from 0.33109
30/30 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8803 - precision_1: 0.8896 - recall_1: 0.8788 - val_loss: 0.3350 - val_accuracy: 0.8445 - val_precision_1: 0.8880 - val_recall_1: 0.8284
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2582 - accuracy: 0.9062 - precision_1: 0.8421 - recall_1: 1.0000
Epoch 93: val_loss did not improve from 0.33109
30/30 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8813 - precision_1: 0.8898 - recall_1: 0.8808 - val_loss: 0.3355 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3002 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 94: val_loss did not improve from 0.33109
30/30 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.8824 - precision_1: 0.8916 - recall_1: 0.8808 - val_loss: 0.3314 - val_accuracy: 0.8403 - val_precision_1: 0.8750 - val_recall_1: 0.8358
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3304 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7333
Epoch 95: val_loss improved from 0.33109 to 0.32977, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2966 - accuracy: 0.8824 - precision_1: 0.8869 - recall_1: 0.8869 - val_loss: 0.3298 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3120 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 96: val_loss did not improve from 0.32977
30/30 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8834 - precision_1: 0.8887 - recall_1: 0.8869 - val_loss: 0.3351 - val_accuracy: 0.8529 - val_precision_1: 0.8960 - val_recall_1: 0.8358
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2406 - accuracy: 0.9062 - precision_1: 0.8182 - recall_1: 0.9000
Epoch 97: val_loss did not improve from 0.32977
30/30 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8834 - precision_1: 0.8887 - recall_1: 0.8869 - val_loss: 0.3312 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3930 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 98: val_loss improved from 0.32977 to 0.32852, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8824 - precision_1: 0.8932 - recall_1: 0.8788 - val_loss: 0.3285 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2313 - accuracy: 0.8750 - precision_1: 0.7857 - recall_1: 0.9167
Epoch 99: val_loss improved from 0.32852 to 0.32645, saving model to feature_model.keras
30/30 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8813 - precision_1: 0.8866 - recall_1: 0.8848 - val_loss: 0.3264 - val_accuracy: 0.8613 - val_precision_1: 0.8797 - val_recall_1: 0.8731
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3010 - accuracy: 0.8750 - precision_1: 0.7647 - recall_1: 1.0000
Epoch 100: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8834 - precision_1: 0.8902 - recall_1: 0.8848 - val_loss: 0.3299 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Remove-fasting-blood-sugar">Remove fasting blood sugar<a class="anchor-link" href="#Remove-fasting-blood-sugar">¶</a></h2><ul>
<li>val_accuracy: 0.8067</li>
<li>val_loss: 0.4022</li>
<li>val_precision: 0.7941</li>
<li>val_recall: 0.8571</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [171]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">FTRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">ETRAIN</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">FVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">EVALID</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_fasting_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_fasting_model"</span><span class="p">)</span>
<span class="n">less_fasting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,)))</span>
<span class="n">less_fasting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_fasting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_fasting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_fasting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_fasting_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_fasting_history</span> <span class="o">=</span> <span class="n">less_fasting_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">FTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">FVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 18s - loss: 0.6035 - accuracy: 0.6875 - precision_1: 0.8639 - recall_1: 0.8355
Epoch 1: val_loss did not improve from 0.32645
30/30 [==============================] - 1s 10ms/step - loss: 0.6177 - accuracy: 0.6964 - precision_1: 0.7253 - recall_1: 0.7806 - val_loss: 0.5935 - val_accuracy: 0.7101 - val_precision_1: 0.7600 - val_recall_1: 0.7090
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5668 - accuracy: 0.6875 - precision_1: 0.8000 - recall_1: 0.6316
Epoch 2: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7595 - precision_1: 0.7725 - recall_1: 0.7616 - val_loss: 0.5552 - val_accuracy: 0.7311 - val_precision_1: 0.7966 - val_recall_1: 0.7015
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4902 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 3: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7763 - precision_1: 0.8052 - recall_1: 0.7515 - val_loss: 0.5199 - val_accuracy: 0.7437 - val_precision_1: 0.8120 - val_recall_1: 0.7090
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5924 - accuracy: 0.6875 - precision_1: 0.7692 - recall_1: 0.5882
Epoch 4: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7931 - precision_1: 0.8170 - recall_1: 0.7758 - val_loss: 0.4919 - val_accuracy: 0.7563 - val_precision_1: 0.8220 - val_recall_1: 0.7239
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4965 - accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125
Epoch 5: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7962 - precision_1: 0.8251 - recall_1: 0.7717 - val_loss: 0.4705 - val_accuracy: 0.7605 - val_precision_1: 0.8291 - val_recall_1: 0.7239
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4104 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 6: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7983 - precision_1: 0.8301 - recall_1: 0.7697 - val_loss: 0.4508 - val_accuracy: 0.7605 - val_precision_1: 0.8182 - val_recall_1: 0.7388
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4757 - accuracy: 0.7188 - precision_1: 0.7222 - recall_1: 0.7647
Epoch 7: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8109 - precision_1: 0.8274 - recall_1: 0.8040 - val_loss: 0.4365 - val_accuracy: 0.7983 - val_precision_1: 0.8258 - val_recall_1: 0.8134
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3118 - accuracy: 0.9062 - precision_1: 0.9231 - recall_1: 0.8571
Epoch 8: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8246 - precision_1: 0.8228 - recall_1: 0.8444 - val_loss: 0.4281 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2503 - accuracy: 0.9688 - precision_1: 0.9474 - recall_1: 1.0000
Epoch 9: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8246 - precision_1: 0.8216 - recall_1: 0.8465 - val_loss: 0.4198 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3560 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.9130
Epoch 10: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8298 - precision_1: 0.8258 - recall_1: 0.8525 - val_loss: 0.4142 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3414 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 11: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8361 - precision_1: 0.8343 - recall_1: 0.8545 - val_loss: 0.4057 - val_accuracy: 0.8277 - val_precision_1: 0.8496 - val_recall_1: 0.8433
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5357 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 12: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8393 - precision_1: 0.8340 - recall_1: 0.8626 - val_loss: 0.4003 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 13/100
30/30 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8393 - precision_1: 0.8301 - recall_1: 0.8687
Epoch 13: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8393 - precision_1: 0.8301 - recall_1: 0.8687 - val_loss: 0.3969 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3652 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8000
Epoch 14: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8435 - precision_1: 0.8353 - recall_1: 0.8707 - val_loss: 0.3935 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5418 - accuracy: 0.7500 - precision_1: 0.6667 - recall_1: 0.6667
Epoch 15: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8435 - precision_1: 0.8379 - recall_1: 0.8667 - val_loss: 0.3894 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8750 - precision_1: 0.9412 - recall_1: 0.8421
Epoch 16: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8508 - precision_1: 0.8454 - recall_1: 0.8727 - val_loss: 0.3873 - val_accuracy: 0.8487 - val_precision_1: 0.8712 - val_recall_1: 0.8582
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4301 - accuracy: 0.8750 - precision_1: 0.7857 - recall_1: 0.9167
Epoch 17: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8529 - precision_1: 0.8501 - recall_1: 0.8707 - val_loss: 0.3827 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5310 - accuracy: 0.8125 - precision_1: 0.7143 - recall_1: 1.0000
Epoch 18: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8529 - precision_1: 0.8460 - recall_1: 0.8768 - val_loss: 0.3829 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3546 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 19: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8519 - precision_1: 0.8471 - recall_1: 0.8727 - val_loss: 0.3795 - val_accuracy: 0.8319 - val_precision_1: 0.8561 - val_recall_1: 0.8433
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3904 - accuracy: 0.8750 - precision_1: 0.9545 - recall_1: 0.8750
Epoch 20: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3699 - accuracy: 0.8519 - precision_1: 0.8471 - recall_1: 0.8727 - val_loss: 0.3766 - val_accuracy: 0.8361 - val_precision_1: 0.8626 - val_recall_1: 0.8433
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3528 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 21: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8519 - precision_1: 0.8471 - recall_1: 0.8727 - val_loss: 0.3758 - val_accuracy: 0.8403 - val_precision_1: 0.8692 - val_recall_1: 0.8433
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 22: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8561 - precision_1: 0.8538 - recall_1: 0.8727 - val_loss: 0.3720 - val_accuracy: 0.8403 - val_precision_1: 0.8636 - val_recall_1: 0.8507
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4303 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8889
Epoch 23: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8561 - precision_1: 0.8496 - recall_1: 0.8788 - val_loss: 0.3766 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2410 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 24: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8571 - precision_1: 0.8583 - recall_1: 0.8687 - val_loss: 0.3683 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2943 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 25: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8561 - precision_1: 0.8538 - recall_1: 0.8727 - val_loss: 0.3702 - val_accuracy: 0.8445 - val_precision_1: 0.8760 - val_recall_1: 0.8433
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4446 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 26: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8540 - precision_1: 0.8546 - recall_1: 0.8667 - val_loss: 0.3646 - val_accuracy: 0.8445 - val_precision_1: 0.8702 - val_recall_1: 0.8507
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3191 - accuracy: 0.9062 - precision_1: 0.9231 - recall_1: 0.8571
Epoch 27: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8582 - precision_1: 0.8557 - recall_1: 0.8747 - val_loss: 0.3636 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2948 - accuracy: 0.9688 - precision_1: 0.9444 - recall_1: 1.0000
Epoch 28: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8634 - precision_1: 0.8600 - recall_1: 0.8808 - val_loss: 0.3658 - val_accuracy: 0.8487 - val_precision_1: 0.8769 - val_recall_1: 0.8507
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4366 - accuracy: 0.7812 - precision_1: 0.7857 - recall_1: 0.7333
Epoch 29: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8603 - precision_1: 0.8591 - recall_1: 0.8747 - val_loss: 0.3626 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2215 - accuracy: 0.9688 - precision_1: 0.9444 - recall_1: 1.0000
Epoch 30: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8634 - precision_1: 0.8614 - recall_1: 0.8788 - val_loss: 0.3594 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5362 - accuracy: 0.8438 - precision_1: 0.7143 - recall_1: 0.9091
Epoch 31: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8666 - precision_1: 0.8622 - recall_1: 0.8848 - val_loss: 0.3619 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2905 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.9474
Epoch 32: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8634 - precision_1: 0.8600 - recall_1: 0.8808 - val_loss: 0.3635 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3904 - accuracy: 0.8125 - precision_1: 0.7895 - recall_1: 0.8824
Epoch 33: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8645 - precision_1: 0.8690 - recall_1: 0.8707 - val_loss: 0.3555 - val_accuracy: 0.8571 - val_precision_1: 0.8788 - val_recall_1: 0.8657
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3543 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7778
Epoch 34: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8655 - precision_1: 0.8634 - recall_1: 0.8808 - val_loss: 0.3580 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1990 - accuracy: 0.9375 - precision_1: 0.9474 - recall_1: 0.9474
Epoch 35: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8624 - precision_1: 0.8669 - recall_1: 0.8687 - val_loss: 0.3552 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4185 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 36: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8624 - precision_1: 0.8684 - recall_1: 0.8667 - val_loss: 0.3527 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3452 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 37: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8687 - precision_1: 0.8671 - recall_1: 0.8828 - val_loss: 0.3568 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2746 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8235
Epoch 38: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8613 - precision_1: 0.8697 - recall_1: 0.8626 - val_loss: 0.3502 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3390 - accuracy: 0.8125 - precision_1: 0.7647 - recall_1: 0.8667
Epoch 39: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8634 - precision_1: 0.8672 - recall_1: 0.8707 - val_loss: 0.3545 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1693 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 40: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8645 - precision_1: 0.8704 - recall_1: 0.8687 - val_loss: 0.3496 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1698 - accuracy: 0.9375 - precision_1: 0.8571 - recall_1: 1.0000
Epoch 41: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8634 - precision_1: 0.8672 - recall_1: 0.8707 - val_loss: 0.3483 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 42: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8655 - precision_1: 0.8692 - recall_1: 0.8727 - val_loss: 0.3531 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2964 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.9474
Epoch 43: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8666 - precision_1: 0.8695 - recall_1: 0.8747 - val_loss: 0.3527 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3829 - accuracy: 0.8125 - precision_1: 0.7059 - recall_1: 0.9231
Epoch 44: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8718 - precision_1: 0.8768 - recall_1: 0.8768 - val_loss: 0.3514 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3552 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 45: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8666 - precision_1: 0.8740 - recall_1: 0.8687 - val_loss: 0.3502 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2239 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 46: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8718 - precision_1: 0.8783 - recall_1: 0.8747 - val_loss: 0.3507 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1648 - accuracy: 0.9688 - precision_1: 0.9412 - recall_1: 1.0000
Epoch 47: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8718 - precision_1: 0.8798 - recall_1: 0.8727 - val_loss: 0.3497 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5406 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.8571
Epoch 48: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8697 - precision_1: 0.8747 - recall_1: 0.8747 - val_loss: 0.3500 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2912 - accuracy: 0.9062 - precision_1: 0.9565 - recall_1: 0.9167
Epoch 49: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8708 - precision_1: 0.8750 - recall_1: 0.8768 - val_loss: 0.3504 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3284 - accuracy: 0.9062 - precision_1: 0.9412 - recall_1: 0.8889
Epoch 50: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8687 - precision_1: 0.8745 - recall_1: 0.8727 - val_loss: 0.3528 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4121 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 51: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8718 - precision_1: 0.8768 - recall_1: 0.8768 - val_loss: 0.3549 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3381 - accuracy: 0.8438 - precision_1: 0.7857 - recall_1: 0.8462
Epoch 52: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8761 - precision_1: 0.8824 - recall_1: 0.8788 - val_loss: 0.3555 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2676 - accuracy: 0.8750 - precision_1: 0.7857 - recall_1: 0.9167
Epoch 53: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8718 - precision_1: 0.8768 - recall_1: 0.8768 - val_loss: 0.3537 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2951 - accuracy: 0.8750 - precision_1: 0.7778 - recall_1: 1.0000
Epoch 54: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8718 - precision_1: 0.8783 - recall_1: 0.8747 - val_loss: 0.3532 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4176 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 55: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8718 - precision_1: 0.8845 - recall_1: 0.8667 - val_loss: 0.3489 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3173 - accuracy: 0.9062 - precision_1: 0.9524 - recall_1: 0.9091
Epoch 56: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8708 - precision_1: 0.8765 - recall_1: 0.8747 - val_loss: 0.3518 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 56: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Remove-Cholesterol">Remove Cholesterol<a class="anchor-link" href="#Remove-Cholesterol">¶</a></h2><ul>
<li>val_accuracy: 0.8445</li>
<li>val_loss: 0.3999</li>
<li>val_precision: 0.8296</li>
<li>val_recall: 0.8889</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [172]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">CTRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">FTRAIN</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">CVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">FVALID</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_ch_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_ch_model"</span><span class="p">)</span>
<span class="n">less_ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,)))</span>
<span class="n">less_ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ch_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_ch_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_ch_history</span> <span class="o">=</span> <span class="n">less_ch_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">CTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">CVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 20s - loss: 0.6723 - accuracy: 0.5938 - precision_1: 0.8272 - recall_1: 0.8758
Epoch 1: val_loss did not improve from 0.32645
30/30 [==============================] - 1s 11ms/step - loss: 0.6297 - accuracy: 0.5683 - precision_1: 0.5911 - recall_1: 0.9491 - val_loss: 0.6062 - val_accuracy: 0.6345 - val_precision_1: 0.6193 - val_recall_1: 0.9104
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5960 - accuracy: 0.6562 - precision_1: 0.6552 - recall_1: 0.9500
Epoch 2: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6660 - precision_1: 0.6169 - recall_1: 0.9434 - val_loss: 0.5649 - val_accuracy: 0.7269 - val_precision_1: 0.7117 - val_recall_1: 0.8657
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5506 - accuracy: 0.6250 - precision_1: 0.5600 - recall_1: 0.9333
Epoch 3: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7784 - precision_1: 0.7313 - recall_1: 0.9071 - val_loss: 0.5336 - val_accuracy: 0.7605 - val_precision_1: 0.7770 - val_recall_1: 0.8060
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3815 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9167
Epoch 4: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8246 - precision_1: 0.8060 - recall_1: 0.8727 - val_loss: 0.5101 - val_accuracy: 0.7815 - val_precision_1: 0.8060 - val_recall_1: 0.8060
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4803 - accuracy: 0.8125 - precision_1: 0.8421 - recall_1: 0.8421
Epoch 5: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.8288 - precision_1: 0.8168 - recall_1: 0.8646 - val_loss: 0.4913 - val_accuracy: 0.7899 - val_precision_1: 0.8231 - val_recall_1: 0.7985
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5424 - accuracy: 0.8125 - precision_1: 0.8889 - recall_1: 0.8000
Epoch 6: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8298 - precision_1: 0.8246 - recall_1: 0.8545 - val_loss: 0.4760 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3587 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8889
Epoch 7: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8351 - precision_1: 0.8340 - recall_1: 0.8525 - val_loss: 0.4618 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4659 - accuracy: 0.8438 - precision_1: 0.9375 - recall_1: 0.7895
Epoch 8: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8351 - precision_1: 0.8394 - recall_1: 0.8444 - val_loss: 0.4467 - val_accuracy: 0.8067 - val_precision_1: 0.8492 - val_recall_1: 0.7985
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5314 - accuracy: 0.7500 - precision_1: 0.7778 - recall_1: 0.7778
Epoch 9: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8393 - precision_1: 0.8504 - recall_1: 0.8384 - val_loss: 0.4343 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4605 - accuracy: 0.7188 - precision_1: 0.7778 - recall_1: 0.7368
Epoch 10: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8403 - precision_1: 0.8507 - recall_1: 0.8404 - val_loss: 0.4220 - val_accuracy: 0.8151 - val_precision_1: 0.8629 - val_recall_1: 0.7985
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4242 - accuracy: 0.7812 - precision_1: 0.7647 - recall_1: 0.8125
Epoch 11: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8403 - precision_1: 0.8522 - recall_1: 0.8384 - val_loss: 0.4133 - val_accuracy: 0.8193 - val_precision_1: 0.8699 - val_recall_1: 0.7985
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3836 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 12: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8424 - precision_1: 0.8542 - recall_1: 0.8404 - val_loss: 0.4056 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4140 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 13: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8435 - precision_1: 0.8531 - recall_1: 0.8444 - val_loss: 0.3995 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3585 - accuracy: 0.8438 - precision_1: 1.0000 - recall_1: 0.6875
Epoch 14: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8393 - precision_1: 0.8533 - recall_1: 0.8343 - val_loss: 0.3927 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3622 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 15: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8445 - precision_1: 0.8519 - recall_1: 0.8485 - val_loss: 0.3874 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4257 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 16: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8435 - precision_1: 0.8488 - recall_1: 0.8505 - val_loss: 0.3845 - val_accuracy: 0.8319 - val_precision_1: 0.8790 - val_recall_1: 0.8134
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4159 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 17: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8456 - precision_1: 0.8551 - recall_1: 0.8465 - val_loss: 0.3794 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3799 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 18: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8456 - precision_1: 0.8537 - recall_1: 0.8485 - val_loss: 0.3755 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3781 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 19: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8508 - precision_1: 0.8523 - recall_1: 0.8626 - val_loss: 0.3743 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4443 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 20: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8508 - precision_1: 0.8523 - recall_1: 0.8626 - val_loss: 0.3718 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2702 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9000
Epoch 21: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8477 - precision_1: 0.8514 - recall_1: 0.8566 - val_loss: 0.3668 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2873 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 22: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8477 - precision_1: 0.8458 - recall_1: 0.8646 - val_loss: 0.3660 - val_accuracy: 0.8445 - val_precision_1: 0.8819 - val_recall_1: 0.8358
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4127 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 23: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8529 - precision_1: 0.8529 - recall_1: 0.8667 - val_loss: 0.3669 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3293 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 24: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8508 - precision_1: 0.8468 - recall_1: 0.8707 - val_loss: 0.3688 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5264 - accuracy: 0.7812 - precision_1: 0.7333 - recall_1: 0.7857
Epoch 25: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8487 - precision_1: 0.8517 - recall_1: 0.8586 - val_loss: 0.3612 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4575 - accuracy: 0.7812 - precision_1: 0.7059 - recall_1: 0.8571
Epoch 26: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8540 - precision_1: 0.8532 - recall_1: 0.8687 - val_loss: 0.3605 - val_accuracy: 0.8487 - val_precision_1: 0.8889 - val_recall_1: 0.8358
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2196 - accuracy: 0.9688 - precision_1: 0.9375 - recall_1: 1.0000
Epoch 27: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8550 - precision_1: 0.8549 - recall_1: 0.8687 - val_loss: 0.3592 - val_accuracy: 0.8529 - val_precision_1: 0.8898 - val_recall_1: 0.8433
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3910 - accuracy: 0.8438 - precision_1: 0.8500 - recall_1: 0.8947
Epoch 28: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8561 - precision_1: 0.8524 - recall_1: 0.8747 - val_loss: 0.3580 - val_accuracy: 0.8529 - val_precision_1: 0.8898 - val_recall_1: 0.8433
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5065 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 29: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8550 - precision_1: 0.8521 - recall_1: 0.8727 - val_loss: 0.3567 - val_accuracy: 0.8529 - val_precision_1: 0.8898 - val_recall_1: 0.8433
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3070 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 30: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8571 - precision_1: 0.8569 - recall_1: 0.8707 - val_loss: 0.3554 - val_accuracy: 0.8487 - val_precision_1: 0.8828 - val_recall_1: 0.8433
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3011 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 31: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8550 - precision_1: 0.8535 - recall_1: 0.8707 - val_loss: 0.3563 - val_accuracy: 0.8529 - val_precision_1: 0.8898 - val_recall_1: 0.8433
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1798 - accuracy: 0.9375 - precision_1: 0.8571 - recall_1: 1.0000
Epoch 32: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8571 - precision_1: 0.8554 - recall_1: 0.8727 - val_loss: 0.3543 - val_accuracy: 0.8487 - val_precision_1: 0.8828 - val_recall_1: 0.8433
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4667 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 33: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8603 - precision_1: 0.8620 - recall_1: 0.8707 - val_loss: 0.3505 - val_accuracy: 0.8529 - val_precision_1: 0.8779 - val_recall_1: 0.8582
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3577 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 34: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8582 - precision_1: 0.8557 - recall_1: 0.8747 - val_loss: 0.3532 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4602 - accuracy: 0.8438 - precision_1: 0.7895 - recall_1: 0.9375
Epoch 35: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8592 - precision_1: 0.8588 - recall_1: 0.8727 - val_loss: 0.3508 - val_accuracy: 0.8529 - val_precision_1: 0.8837 - val_recall_1: 0.8507
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3286 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 36: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8613 - precision_1: 0.8594 - recall_1: 0.8768 - val_loss: 0.3486 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2835 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.9091
Epoch 37: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8571 - precision_1: 0.8527 - recall_1: 0.8768 - val_loss: 0.3496 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 38: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8571 - precision_1: 0.8583 - recall_1: 0.8687 - val_loss: 0.3482 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4145 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 39: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8592 - precision_1: 0.8560 - recall_1: 0.8768 - val_loss: 0.3500 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2455 - accuracy: 0.9375 - precision_1: 0.9333 - recall_1: 0.9333
Epoch 40: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8655 - precision_1: 0.8648 - recall_1: 0.8788 - val_loss: 0.3508 - val_accuracy: 0.8613 - val_precision_1: 0.8976 - val_recall_1: 0.8507
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2951 - accuracy: 0.8438 - precision_1: 0.6923 - recall_1: 0.9000
Epoch 41: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8613 - precision_1: 0.8594 - recall_1: 0.8768 - val_loss: 0.3498 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2030 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9444
Epoch 42: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8666 - precision_1: 0.8651 - recall_1: 0.8808 - val_loss: 0.3502 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1964 - accuracy: 0.9688 - precision_1: 0.9474 - recall_1: 1.0000
Epoch 43: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3363 - accuracy: 0.8645 - precision_1: 0.8645 - recall_1: 0.8768 - val_loss: 0.3480 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3221 - accuracy: 0.9062 - precision_1: 0.9200 - recall_1: 0.9583
Epoch 44: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8666 - precision_1: 0.8651 - recall_1: 0.8808 - val_loss: 0.3471 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3009 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 45: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8655 - precision_1: 0.8634 - recall_1: 0.8808 - val_loss: 0.3511 - val_accuracy: 0.8655 - val_precision_1: 0.9048 - val_recall_1: 0.8507
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2278 - accuracy: 0.9375 - precision_1: 0.9375 - recall_1: 0.9375
Epoch 46: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8645 - precision_1: 0.8675 - recall_1: 0.8727 - val_loss: 0.3470 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3650 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 47: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8676 - precision_1: 0.8683 - recall_1: 0.8788 - val_loss: 0.3472 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3080 - accuracy: 0.8750 - precision_1: 0.8696 - recall_1: 0.9524
Epoch 48: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8687 - precision_1: 0.8715 - recall_1: 0.8768 - val_loss: 0.3466 - val_accuracy: 0.8571 - val_precision_1: 0.8906 - val_recall_1: 0.8507
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9062 - precision_1: 0.9474 - recall_1: 0.9000
Epoch 49: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8687 - precision_1: 0.8671 - recall_1: 0.8828 - val_loss: 0.3474 - val_accuracy: 0.8655 - val_precision_1: 0.8984 - val_recall_1: 0.8582
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2739 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9048
Epoch 50: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8676 - precision_1: 0.8653 - recall_1: 0.8828 - val_loss: 0.3497 - val_accuracy: 0.8655 - val_precision_1: 0.9048 - val_recall_1: 0.8507
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3236 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 51: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8718 - precision_1: 0.8723 - recall_1: 0.8828 - val_loss: 0.3478 - val_accuracy: 0.8655 - val_precision_1: 0.9048 - val_recall_1: 0.8507
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2997 - accuracy: 0.9375 - precision_1: 0.8889 - recall_1: 1.0000
Epoch 52: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8729 - precision_1: 0.8770 - recall_1: 0.8788 - val_loss: 0.3445 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3132 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 53: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8761 - precision_1: 0.8762 - recall_1: 0.8869 - val_loss: 0.3489 - val_accuracy: 0.8655 - val_precision_1: 0.8984 - val_recall_1: 0.8582
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3792 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 54: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8750 - precision_1: 0.8821 - recall_1: 0.8768 - val_loss: 0.3439 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3029 - accuracy: 0.8750 - precision_1: 0.9375 - recall_1: 0.8333
Epoch 55: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8687 - precision_1: 0.8671 - recall_1: 0.8828 - val_loss: 0.3477 - val_accuracy: 0.8697 - val_precision_1: 0.8992 - val_recall_1: 0.8657
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3002 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 56: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8739 - precision_1: 0.8788 - recall_1: 0.8788 - val_loss: 0.3442 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4180 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 57: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8708 - precision_1: 0.8676 - recall_1: 0.8869 - val_loss: 0.3452 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2911 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 58: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8697 - precision_1: 0.8703 - recall_1: 0.8808 - val_loss: 0.3452 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4544 - accuracy: 0.8125 - precision_1: 0.8500 - recall_1: 0.8500
Epoch 59: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8718 - precision_1: 0.8737 - recall_1: 0.8808 - val_loss: 0.3462 - val_accuracy: 0.8697 - val_precision_1: 0.8992 - val_recall_1: 0.8657
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1316 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 60: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8750 - precision_1: 0.8852 - recall_1: 0.8727 - val_loss: 0.3416 - val_accuracy: 0.8782 - val_precision_1: 0.8947 - val_recall_1: 0.8881
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2379 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 61: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8708 - precision_1: 0.8661 - recall_1: 0.8889 - val_loss: 0.3457 - val_accuracy: 0.8697 - val_precision_1: 0.8992 - val_recall_1: 0.8657
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 62: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8729 - precision_1: 0.8725 - recall_1: 0.8848 - val_loss: 0.3463 - val_accuracy: 0.8697 - val_precision_1: 0.8992 - val_recall_1: 0.8657
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3973 - accuracy: 0.8750 - precision_1: 0.8400 - recall_1: 1.0000
Epoch 63: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8739 - precision_1: 0.8788 - recall_1: 0.8788 - val_loss: 0.3428 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2047 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 64: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8729 - precision_1: 0.8740 - recall_1: 0.8828 - val_loss: 0.3433 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2889 - accuracy: 0.9062 - precision_1: 0.9167 - recall_1: 0.8462
Epoch 65: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8782 - precision_1: 0.8828 - recall_1: 0.8828 - val_loss: 0.3421 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4333 - accuracy: 0.7812 - precision_1: 0.8824 - recall_1: 0.7500
Epoch 66: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8750 - precision_1: 0.8745 - recall_1: 0.8869 - val_loss: 0.3419 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3015 - accuracy: 0.8438 - precision_1: 0.8500 - recall_1: 0.8947
Epoch 67: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8708 - precision_1: 0.8735 - recall_1: 0.8788 - val_loss: 0.3426 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2942 - accuracy: 0.8750 - precision_1: 0.7857 - recall_1: 0.9167
Epoch 68: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8771 - precision_1: 0.8810 - recall_1: 0.8828 - val_loss: 0.3397 - val_accuracy: 0.8697 - val_precision_1: 0.8872 - val_recall_1: 0.8806
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 69: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8771 - precision_1: 0.8780 - recall_1: 0.8869 - val_loss: 0.3432 - val_accuracy: 0.8655 - val_precision_1: 0.8923 - val_recall_1: 0.8657
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2206 - accuracy: 0.9375 - precision_1: 0.9048 - recall_1: 1.0000
Epoch 70: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8729 - precision_1: 0.8740 - recall_1: 0.8828 - val_loss: 0.3456 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4777 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.6364
Epoch 71: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8750 - precision_1: 0.8806 - recall_1: 0.8788 - val_loss: 0.3401 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1339 - accuracy: 0.9688 - precision_1: 0.9474 - recall_1: 1.0000
Epoch 72: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8750 - precision_1: 0.8775 - recall_1: 0.8828 - val_loss: 0.3410 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8750 - precision_1: 0.9375 - recall_1: 0.8333
Epoch 73: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8676 - precision_1: 0.8697 - recall_1: 0.8768 - val_loss: 0.3390 - val_accuracy: 0.8697 - val_precision_1: 0.8872 - val_recall_1: 0.8806
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5216 - accuracy: 0.8750 - precision_1: 0.9048 - recall_1: 0.9048
Epoch 74: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8718 - precision_1: 0.8737 - recall_1: 0.8808 - val_loss: 0.3390 - val_accuracy: 0.8697 - val_precision_1: 0.8872 - val_recall_1: 0.8806
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4937 - accuracy: 0.6875 - precision_1: 0.6957 - recall_1: 0.8421
Epoch 75: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8761 - precision_1: 0.8808 - recall_1: 0.8808 - val_loss: 0.3385 - val_accuracy: 0.8697 - val_precision_1: 0.8872 - val_recall_1: 0.8806
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 76: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8782 - precision_1: 0.8782 - recall_1: 0.8889 - val_loss: 0.3402 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2684 - accuracy: 0.9375 - precision_1: 0.9412 - recall_1: 0.9412
Epoch 77: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8771 - precision_1: 0.8826 - recall_1: 0.8808 - val_loss: 0.3374 - val_accuracy: 0.8739 - val_precision_1: 0.8824 - val_recall_1: 0.8955
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2389 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 78: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8718 - precision_1: 0.8708 - recall_1: 0.8848 - val_loss: 0.3425 - val_accuracy: 0.8655 - val_precision_1: 0.8984 - val_recall_1: 0.8582
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1952 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8333
Epoch 79: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8761 - precision_1: 0.8839 - recall_1: 0.8768 - val_loss: 0.3370 - val_accuracy: 0.8782 - val_precision_1: 0.8889 - val_recall_1: 0.8955
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4893 - accuracy: 0.8438 - precision_1: 0.8500 - recall_1: 0.8947
Epoch 80: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8782 - precision_1: 0.8828 - recall_1: 0.8828 - val_loss: 0.3352 - val_accuracy: 0.8782 - val_precision_1: 0.8889 - val_recall_1: 0.8955
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2958 - accuracy: 0.8750 - precision_1: 0.8182 - recall_1: 0.8182
Epoch 81: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8761 - precision_1: 0.8748 - recall_1: 0.8889 - val_loss: 0.3392 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3324 - accuracy: 0.8438 - precision_1: 0.9000 - recall_1: 0.8571
Epoch 82: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8782 - precision_1: 0.8828 - recall_1: 0.8828 - val_loss: 0.3373 - val_accuracy: 0.8697 - val_precision_1: 0.8872 - val_recall_1: 0.8806
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5223 - accuracy: 0.7188 - precision_1: 0.6923 - recall_1: 0.6429
Epoch 83: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8771 - precision_1: 0.8826 - recall_1: 0.8808 - val_loss: 0.3365 - val_accuracy: 0.8739 - val_precision_1: 0.8824 - val_recall_1: 0.8955
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2134 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9375
Epoch 84: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8750 - precision_1: 0.8745 - recall_1: 0.8869 - val_loss: 0.3384 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3494 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.8333
Epoch 85: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8761 - precision_1: 0.8748 - recall_1: 0.8889 - val_loss: 0.3440 - val_accuracy: 0.8571 - val_precision_1: 0.9032 - val_recall_1: 0.8358
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1965 - accuracy: 0.9688 - precision_1: 0.9412 - recall_1: 1.0000
Epoch 86: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8761 - precision_1: 0.8839 - recall_1: 0.8768 - val_loss: 0.3382 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2146 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 87: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8771 - precision_1: 0.8841 - recall_1: 0.8788 - val_loss: 0.3335 - val_accuracy: 0.8739 - val_precision_1: 0.8824 - val_recall_1: 0.8955
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2772 - accuracy: 0.9062 - precision_1: 0.7500 - recall_1: 1.0000
Epoch 88: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8750 - precision_1: 0.8745 - recall_1: 0.8869 - val_loss: 0.3387 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3371 - accuracy: 0.8438 - precision_1: 0.9231 - recall_1: 0.7500
Epoch 89: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8771 - precision_1: 0.8810 - recall_1: 0.8828 - val_loss: 0.3421 - val_accuracy: 0.8613 - val_precision_1: 0.8915 - val_recall_1: 0.8582
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2075 - accuracy: 0.9375 - precision_1: 0.8462 - recall_1: 1.0000
Epoch 90: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8750 - precision_1: 0.8806 - recall_1: 0.8788 - val_loss: 0.3369 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6268 - accuracy: 0.7500 - precision_1: 0.8235 - recall_1: 0.7368
Epoch 91: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8761 - precision_1: 0.8762 - recall_1: 0.8869 - val_loss: 0.3411 - val_accuracy: 0.8613 - val_precision_1: 0.8855 - val_recall_1: 0.8657
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2955 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 92: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8750 - precision_1: 0.8775 - recall_1: 0.8828 - val_loss: 0.3386 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5599 - accuracy: 0.7812 - precision_1: 0.6923 - recall_1: 0.7500
Epoch 93: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8750 - precision_1: 0.8775 - recall_1: 0.8828 - val_loss: 0.3362 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.8438 - precision_1: 1.0000 - recall_1: 0.7059
Epoch 94: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8750 - precision_1: 0.8775 - recall_1: 0.8828 - val_loss: 0.3375 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1657 - accuracy: 0.9375 - precision_1: 0.8667 - recall_1: 1.0000
Epoch 95: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8750 - precision_1: 0.8775 - recall_1: 0.8828 - val_loss: 0.3334 - val_accuracy: 0.8739 - val_precision_1: 0.8881 - val_recall_1: 0.8881
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4477 - accuracy: 0.8125 - precision_1: 0.7647 - recall_1: 0.8667
Epoch 96: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8771 - precision_1: 0.8780 - recall_1: 0.8869 - val_loss: 0.3385 - val_accuracy: 0.8571 - val_precision_1: 0.8846 - val_recall_1: 0.8582
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2528 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8824
Epoch 97: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8782 - precision_1: 0.8828 - recall_1: 0.8828 - val_loss: 0.3338 - val_accuracy: 0.8697 - val_precision_1: 0.8815 - val_recall_1: 0.8881
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3525 - accuracy: 0.8438 - precision_1: 0.8095 - recall_1: 0.9444
Epoch 98: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8739 - precision_1: 0.8773 - recall_1: 0.8808 - val_loss: 0.3346 - val_accuracy: 0.8739 - val_precision_1: 0.8881 - val_recall_1: 0.8881
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2721 - accuracy: 0.8750 - precision_1: 0.9091 - recall_1: 0.7692
Epoch 99: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8750 - precision_1: 0.8790 - recall_1: 0.8808 - val_loss: 0.3338 - val_accuracy: 0.8739 - val_precision_1: 0.8881 - val_recall_1: 0.8881
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1720 - accuracy: 0.9375 - precision_1: 0.9333 - recall_1: 0.9333
Epoch 100: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8761 - precision_1: 0.8762 - recall_1: 0.8869 - val_loss: 0.3341 - val_accuracy: 0.8739 - val_precision_1: 0.8881 - val_recall_1: 0.8881
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Remove-resting-bp">Remove resting bp<a class="anchor-link" href="#Remove-resting-bp">¶</a></h2><ul>
<li>val_accuracy: 0.8151</li>
<li>val_loss: 0.4053</li>
<li>val_precision: 0.7887</li>
<li>val_recall: 0.8889</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [173]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">RTRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">CTRAIN</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">RVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">CVALID</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_resting_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_resting_model"</span><span class="p">)</span>
<span class="n">less_resting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,)))</span>
<span class="n">less_resting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_resting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_resting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_resting_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_resting_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_resting_history</span> <span class="o">=</span> <span class="n">less_resting_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">RTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">RVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.7085 - accuracy: 0.5625 - precision_1: 0.8667 - recall_1: 0.8442
Epoch 1: val_loss did not improve from 0.32645
30/30 [==============================] - 1s 10ms/step - loss: 0.6822 - accuracy: 0.5861 - precision_1: 0.6466 - recall_1: 0.7186 - val_loss: 0.6643 - val_accuracy: 0.6387 - val_precision_1: 0.6875 - val_recall_1: 0.6567
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6497 - accuracy: 0.6562 - precision_1: 0.6190 - recall_1: 0.8125
Epoch 2: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6933 - precision_1: 0.6971 - recall_1: 0.7253 - val_loss: 0.6297 - val_accuracy: 0.7101 - val_precision_1: 0.7481 - val_recall_1: 0.7313
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6364 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 3: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.7553 - precision_1: 0.7589 - recall_1: 0.7758 - val_loss: 0.5886 - val_accuracy: 0.7479 - val_precision_1: 0.7846 - val_recall_1: 0.7612
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5679 - accuracy: 0.7188 - precision_1: 0.6667 - recall_1: 0.7143
Epoch 4: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7668 - precision_1: 0.7703 - recall_1: 0.7859 - val_loss: 0.5315 - val_accuracy: 0.7731 - val_precision_1: 0.8077 - val_recall_1: 0.7836
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5084 - accuracy: 0.7812 - precision_1: 0.7368 - recall_1: 0.8750
Epoch 5: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7857 - precision_1: 0.7825 - recall_1: 0.8141 - val_loss: 0.4841 - val_accuracy: 0.7857 - val_precision_1: 0.8268 - val_recall_1: 0.7836
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4460 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 6: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7952 - precision_1: 0.7930 - recall_1: 0.8202 - val_loss: 0.4543 - val_accuracy: 0.7941 - val_precision_1: 0.8346 - val_recall_1: 0.7910
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5690 - accuracy: 0.7188 - precision_1: 0.6875 - recall_1: 0.7333
Epoch 7: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7952 - precision_1: 0.7941 - recall_1: 0.8182 - val_loss: 0.4357 - val_accuracy: 0.8067 - val_precision_1: 0.8333 - val_recall_1: 0.8209
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3764 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 8: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7994 - precision_1: 0.7969 - recall_1: 0.8242 - val_loss: 0.4261 - val_accuracy: 0.8109 - val_precision_1: 0.8397 - val_recall_1: 0.8209
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4722 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 9: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8067 - precision_1: 0.8019 - recall_1: 0.8343 - val_loss: 0.4217 - val_accuracy: 0.8151 - val_precision_1: 0.8409 - val_recall_1: 0.8284
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6623 - accuracy: 0.6562 - precision_1: 0.7500 - recall_1: 0.7143
Epoch 10: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8057 - precision_1: 0.8004 - recall_1: 0.8343 - val_loss: 0.4194 - val_accuracy: 0.7983 - val_precision_1: 0.8308 - val_recall_1: 0.8060
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4489 - accuracy: 0.8125 - precision_1: 0.8421 - recall_1: 0.8421
Epoch 11: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8088 - precision_1: 0.8063 - recall_1: 0.8323 - val_loss: 0.4167 - val_accuracy: 0.7983 - val_precision_1: 0.8308 - val_recall_1: 0.8060
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5858 - accuracy: 0.7500 - precision_1: 0.8095 - recall_1: 0.8095
Epoch 12: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8172 - precision_1: 0.8129 - recall_1: 0.8424 - val_loss: 0.4142 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3757 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 13: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8183 - precision_1: 0.8157 - recall_1: 0.8404 - val_loss: 0.4119 - val_accuracy: 0.8067 - val_precision_1: 0.8385 - val_recall_1: 0.8134
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3773 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.9375
Epoch 14: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8204 - precision_1: 0.8202 - recall_1: 0.8384 - val_loss: 0.4102 - val_accuracy: 0.8067 - val_precision_1: 0.8385 - val_recall_1: 0.8134
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4232 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 15: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8214 - precision_1: 0.8205 - recall_1: 0.8404 - val_loss: 0.4092 - val_accuracy: 0.7983 - val_precision_1: 0.8308 - val_recall_1: 0.8060
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 16: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8256 - precision_1: 0.8283 - recall_1: 0.8384 - val_loss: 0.4077 - val_accuracy: 0.7983 - val_precision_1: 0.8308 - val_recall_1: 0.8060
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3627 - accuracy: 0.8438 - precision_1: 0.8947 - recall_1: 0.8500
Epoch 17: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8298 - precision_1: 0.8310 - recall_1: 0.8444 - val_loss: 0.4071 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6104 - accuracy: 0.6875 - precision_1: 0.6316 - recall_1: 0.8000
Epoch 18: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8267 - precision_1: 0.8300 - recall_1: 0.8384 - val_loss: 0.4058 - val_accuracy: 0.8025 - val_precision_1: 0.8372 - val_recall_1: 0.8060
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3682 - accuracy: 0.8125 - precision_1: 0.8636 - recall_1: 0.8636
Epoch 19: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8309 - precision_1: 0.8340 - recall_1: 0.8424 - val_loss: 0.4058 - val_accuracy: 0.7899 - val_precision_1: 0.8333 - val_recall_1: 0.7836
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3325 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 20: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8277 - precision_1: 0.8303 - recall_1: 0.8404 - val_loss: 0.4056 - val_accuracy: 0.7857 - val_precision_1: 0.8320 - val_recall_1: 0.7761
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2905 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.8571
Epoch 21: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8309 - precision_1: 0.8353 - recall_1: 0.8404 - val_loss: 0.4064 - val_accuracy: 0.7857 - val_precision_1: 0.8320 - val_recall_1: 0.7761
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2850 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 22: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8298 - precision_1: 0.8364 - recall_1: 0.8364 - val_loss: 0.4041 - val_accuracy: 0.7941 - val_precision_1: 0.8346 - val_recall_1: 0.7910
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3995 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 23: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8361 - precision_1: 0.8466 - recall_1: 0.8364 - val_loss: 0.4028 - val_accuracy: 0.7941 - val_precision_1: 0.8346 - val_recall_1: 0.7910
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3766 - accuracy: 0.8750 - precision_1: 0.8500 - recall_1: 0.9444
Epoch 24: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8372 - precision_1: 0.8455 - recall_1: 0.8404 - val_loss: 0.4026 - val_accuracy: 0.7941 - val_precision_1: 0.8346 - val_recall_1: 0.7910
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3952 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8333
Epoch 25: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8382 - precision_1: 0.8487 - recall_1: 0.8384 - val_loss: 0.4017 - val_accuracy: 0.7941 - val_precision_1: 0.8346 - val_recall_1: 0.7910
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4500 - accuracy: 0.8125 - precision_1: 1.0000 - recall_1: 0.6667
Epoch 26: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3792 - accuracy: 0.8382 - precision_1: 0.8487 - recall_1: 0.8384 - val_loss: 0.4015 - val_accuracy: 0.7983 - val_precision_1: 0.8413 - val_recall_1: 0.7910
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 27: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3779 - accuracy: 0.8351 - precision_1: 0.8463 - recall_1: 0.8343 - val_loss: 0.4002 - val_accuracy: 0.7941 - val_precision_1: 0.8346 - val_recall_1: 0.7910
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3803 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 28: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8372 - precision_1: 0.8512 - recall_1: 0.8323 - val_loss: 0.3984 - val_accuracy: 0.8025 - val_precision_1: 0.8372 - val_recall_1: 0.8060
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4311 - accuracy: 0.8125 - precision_1: 0.8462 - recall_1: 0.7333
Epoch 29: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8372 - precision_1: 0.8498 - recall_1: 0.8343 - val_loss: 0.3980 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2581 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 30: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8372 - precision_1: 0.8512 - recall_1: 0.8323 - val_loss: 0.3967 - val_accuracy: 0.7983 - val_precision_1: 0.8359 - val_recall_1: 0.7985
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3806 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 31: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8393 - precision_1: 0.8519 - recall_1: 0.8364 - val_loss: 0.3956 - val_accuracy: 0.8025 - val_precision_1: 0.8372 - val_recall_1: 0.8060
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3619 - accuracy: 0.7812 - precision_1: 0.6923 - recall_1: 0.7500
Epoch 32: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8414 - precision_1: 0.8539 - recall_1: 0.8384 - val_loss: 0.3949 - val_accuracy: 0.8067 - val_precision_1: 0.8438 - val_recall_1: 0.8060
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2217 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8500
Epoch 33: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8424 - precision_1: 0.8528 - recall_1: 0.8424 - val_loss: 0.3947 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3915 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.7500
Epoch 34: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8435 - precision_1: 0.8574 - recall_1: 0.8384 - val_loss: 0.3934 - val_accuracy: 0.8067 - val_precision_1: 0.8438 - val_recall_1: 0.8060
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1515 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9524
Epoch 35: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8477 - precision_1: 0.8586 - recall_1: 0.8465 - val_loss: 0.3912 - val_accuracy: 0.8067 - val_precision_1: 0.8438 - val_recall_1: 0.8060
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5276 - accuracy: 0.7812 - precision_1: 0.6429 - recall_1: 0.8182
Epoch 36: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8456 - precision_1: 0.8566 - recall_1: 0.8444 - val_loss: 0.3912 - val_accuracy: 0.8151 - val_precision_1: 0.8571 - val_recall_1: 0.8060
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3797 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 37: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8487 - precision_1: 0.8604 - recall_1: 0.8465 - val_loss: 0.3920 - val_accuracy: 0.8067 - val_precision_1: 0.8548 - val_recall_1: 0.7910
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2807 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 38: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8445 - precision_1: 0.8592 - recall_1: 0.8384 - val_loss: 0.3896 - val_accuracy: 0.8151 - val_precision_1: 0.8571 - val_recall_1: 0.8060
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3306 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.6667
Epoch 39: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8477 - precision_1: 0.8616 - recall_1: 0.8424 - val_loss: 0.3892 - val_accuracy: 0.8109 - val_precision_1: 0.8560 - val_recall_1: 0.7985
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1699 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9231
Epoch 40: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8477 - precision_1: 0.8586 - recall_1: 0.8465 - val_loss: 0.3887 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3071 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 41: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8487 - precision_1: 0.8619 - recall_1: 0.8444 - val_loss: 0.3883 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5090 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.9375
Epoch 42: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8456 - precision_1: 0.8625 - recall_1: 0.8364 - val_loss: 0.3860 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3087 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 43: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8487 - precision_1: 0.8649 - recall_1: 0.8404 - val_loss: 0.3842 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2755 - accuracy: 0.8438 - precision_1: 0.9375 - recall_1: 0.7895
Epoch 44: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8477 - precision_1: 0.8631 - recall_1: 0.8404 - val_loss: 0.3854 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4534 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 45: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8508 - precision_1: 0.8669 - recall_1: 0.8424 - val_loss: 0.3833 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3534 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.8571
Epoch 46: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8508 - precision_1: 0.8669 - recall_1: 0.8424 - val_loss: 0.3820 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5002 - accuracy: 0.7500 - precision_1: 0.7273 - recall_1: 0.6154
Epoch 47: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8498 - precision_1: 0.8667 - recall_1: 0.8404 - val_loss: 0.3800 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4678 - accuracy: 0.7500 - precision_1: 0.7857 - recall_1: 0.6875
Epoch 48: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8498 - precision_1: 0.8651 - recall_1: 0.8424 - val_loss: 0.3803 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4257 - accuracy: 0.7812 - precision_1: 0.7857 - recall_1: 0.7333
Epoch 49: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8487 - precision_1: 0.8619 - recall_1: 0.8444 - val_loss: 0.3815 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2842 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 50: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8508 - precision_1: 0.8595 - recall_1: 0.8525 - val_loss: 0.3829 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4018 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 51: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8571 - precision_1: 0.8732 - recall_1: 0.8485 - val_loss: 0.3807 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2132 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8750
Epoch 52: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8529 - precision_1: 0.8630 - recall_1: 0.8525 - val_loss: 0.3816 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2743 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 53: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8571 - precision_1: 0.8732 - recall_1: 0.8485 - val_loss: 0.3807 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2944 - accuracy: 0.8438 - precision_1: 0.9091 - recall_1: 0.8696
Epoch 54: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8561 - precision_1: 0.8729 - recall_1: 0.8465 - val_loss: 0.3768 - val_accuracy: 0.8361 - val_precision_1: 0.8682 - val_recall_1: 0.8358
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2557 - accuracy: 0.9688 - precision_1: 0.9333 - recall_1: 1.0000
Epoch 55: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8582 - precision_1: 0.8673 - recall_1: 0.8586 - val_loss: 0.3784 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2463 - accuracy: 0.9062 - precision_1: 0.9286 - recall_1: 0.8667
Epoch 56: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8561 - precision_1: 0.8698 - recall_1: 0.8505 - val_loss: 0.3786 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2120 - accuracy: 0.9062 - precision_1: 0.8333 - recall_1: 0.9091
Epoch 57: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8540 - precision_1: 0.8693 - recall_1: 0.8465 - val_loss: 0.3762 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3860 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 58: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8582 - precision_1: 0.8673 - recall_1: 0.8586 - val_loss: 0.3789 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2662 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7333
Epoch 59: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8613 - precision_1: 0.8742 - recall_1: 0.8566 - val_loss: 0.3785 - val_accuracy: 0.8193 - val_precision_1: 0.8640 - val_recall_1: 0.8060
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3211 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.9000
Epoch 60: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8592 - precision_1: 0.8753 - recall_1: 0.8505 - val_loss: 0.3754 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3399 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.7692
Epoch 61: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8613 - precision_1: 0.8742 - recall_1: 0.8566 - val_loss: 0.3775 - val_accuracy: 0.8277 - val_precision_1: 0.8780 - val_recall_1: 0.8060
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5047 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 62: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8592 - precision_1: 0.8753 - recall_1: 0.8505 - val_loss: 0.3713 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4174 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 63: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8603 - precision_1: 0.8740 - recall_1: 0.8545 - val_loss: 0.3719 - val_accuracy: 0.8319 - val_precision_1: 0.8615 - val_recall_1: 0.8358
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3600 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 64: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8613 - precision_1: 0.8697 - recall_1: 0.8626 - val_loss: 0.3754 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1949 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8824
Epoch 65: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8624 - precision_1: 0.8760 - recall_1: 0.8566 - val_loss: 0.3717 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3040 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 66: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8613 - precision_1: 0.8758 - recall_1: 0.8545 - val_loss: 0.3707 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2481 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 67: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8655 - precision_1: 0.8784 - recall_1: 0.8606 - val_loss: 0.3706 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1362 - accuracy: 0.9688 - precision_1: 0.9333 - recall_1: 1.0000
Epoch 68: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8624 - precision_1: 0.8760 - recall_1: 0.8566 - val_loss: 0.3717 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4988 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 69: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8645 - precision_1: 0.8781 - recall_1: 0.8586 - val_loss: 0.3699 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4700 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 70: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8655 - precision_1: 0.8768 - recall_1: 0.8626 - val_loss: 0.3689 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2690 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.9000
Epoch 71: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8645 - precision_1: 0.8781 - recall_1: 0.8586 - val_loss: 0.3667 - val_accuracy: 0.8319 - val_precision_1: 0.8672 - val_recall_1: 0.8284
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2910 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 72: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.8655 - precision_1: 0.8768 - recall_1: 0.8626 - val_loss: 0.3656 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3947 - accuracy: 0.7500 - precision_1: 0.7333 - recall_1: 0.7333
Epoch 73: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8697 - precision_1: 0.8793 - recall_1: 0.8687 - val_loss: 0.3698 - val_accuracy: 0.8319 - val_precision_1: 0.8730 - val_recall_1: 0.8209
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2668 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7895
Epoch 74: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8645 - precision_1: 0.8765 - recall_1: 0.8606 - val_loss: 0.3697 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1702 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.9091
Epoch 75: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8697 - precision_1: 0.8841 - recall_1: 0.8626 - val_loss: 0.3707 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3034 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 76: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8739 - precision_1: 0.8898 - recall_1: 0.8646 - val_loss: 0.3672 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4920 - accuracy: 0.7812 - precision_1: 0.9412 - recall_1: 0.7273
Epoch 77: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8729 - precision_1: 0.8832 - recall_1: 0.8707 - val_loss: 0.3681 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3667 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 78: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8729 - precision_1: 0.8880 - recall_1: 0.8646 - val_loss: 0.3679 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3369 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.9412
Epoch 79: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8697 - precision_1: 0.8889 - recall_1: 0.8566 - val_loss: 0.3637 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2414 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 80: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8697 - precision_1: 0.8825 - recall_1: 0.8646 - val_loss: 0.3647 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2205 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8889
Epoch 81: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8729 - precision_1: 0.8864 - recall_1: 0.8667 - val_loss: 0.3643 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3753 - accuracy: 0.8125 - precision_1: 0.8667 - recall_1: 0.7647
Epoch 82: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8708 - precision_1: 0.8843 - recall_1: 0.8646 - val_loss: 0.3653 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4211 - accuracy: 0.8438 - precision_1: 0.8000 - recall_1: 0.8571
Epoch 83: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8708 - precision_1: 0.8811 - recall_1: 0.8687 - val_loss: 0.3671 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3361 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 84: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8729 - precision_1: 0.8880 - recall_1: 0.8646 - val_loss: 0.3661 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3177 - accuracy: 0.9375 - precision_1: 0.9500 - recall_1: 0.9500
Epoch 85: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.8729 - precision_1: 0.8880 - recall_1: 0.8646 - val_loss: 0.3634 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 86: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8718 - precision_1: 0.8861 - recall_1: 0.8646 - val_loss: 0.3620 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1636 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9333
Epoch 87: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8718 - precision_1: 0.8877 - recall_1: 0.8626 - val_loss: 0.3650 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5382 - accuracy: 0.7188 - precision_1: 0.6923 - recall_1: 0.6429
Epoch 88: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8718 - precision_1: 0.8861 - recall_1: 0.8646 - val_loss: 0.3635 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2559 - accuracy: 0.9062 - precision_1: 0.9091 - recall_1: 0.9524
Epoch 89: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8697 - precision_1: 0.8825 - recall_1: 0.8646 - val_loss: 0.3675 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1599 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9545
Epoch 90: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8718 - precision_1: 0.8877 - recall_1: 0.8626 - val_loss: 0.3636 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5527 - accuracy: 0.7500 - precision_1: 0.6875 - recall_1: 0.7857
Epoch 91: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8729 - precision_1: 0.8896 - recall_1: 0.8626 - val_loss: 0.3598 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1857 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8889
Epoch 92: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8739 - precision_1: 0.8819 - recall_1: 0.8747 - val_loss: 0.3638 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2902 - accuracy: 0.8750 - precision_1: 0.9333 - recall_1: 0.8235
Epoch 93: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8708 - precision_1: 0.8859 - recall_1: 0.8626 - val_loss: 0.3648 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4575 - accuracy: 0.7812 - precision_1: 0.7391 - recall_1: 0.9444
Epoch 94: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8676 - precision_1: 0.8836 - recall_1: 0.8586 - val_loss: 0.3663 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3283 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 95: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3187 - accuracy: 0.8697 - precision_1: 0.8841 - recall_1: 0.8626 - val_loss: 0.3643 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2845 - accuracy: 0.9375 - precision_1: 0.8667 - recall_1: 1.0000
Epoch 96: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8697 - precision_1: 0.8857 - recall_1: 0.8606 - val_loss: 0.3624 - val_accuracy: 0.8109 - val_precision_1: 0.8450 - val_recall_1: 0.8134
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2144 - accuracy: 0.9688 - precision_1: 0.9545 - recall_1: 1.0000
Epoch 97: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8708 - precision_1: 0.8827 - recall_1: 0.8667 - val_loss: 0.3583 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2662 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 98: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8687 - precision_1: 0.8807 - recall_1: 0.8646 - val_loss: 0.3574 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3634 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 99: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8718 - precision_1: 0.8845 - recall_1: 0.8667 - val_loss: 0.3588 - val_accuracy: 0.8151 - val_precision_1: 0.8462 - val_recall_1: 0.8209
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4165 - accuracy: 0.8125 - precision_1: 0.8750 - recall_1: 0.7778
Epoch 100: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8718 - precision_1: 0.8845 - recall_1: 0.8667 - val_loss: 0.3598 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Removing-chest-pain">Removing chest pain<a class="anchor-link" href="#Removing-chest-pain">¶</a></h2><ul>
<li>val_accuracy: 0.8361</li>
<li>val_loss: 0.4152</li>
<li>val_precision: 0.8129</li>
<li>val_recall: 0.8968</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [174]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">CTTRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">RTRAIN</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">CTVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">RVALID</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_chest_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_chest_model"</span><span class="p">)</span>
<span class="n">less_chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,)))</span>
<span class="n">less_chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_chest_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_chest_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_chest_history</span> <span class="o">=</span> <span class="n">less_chest_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">CTTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">CTVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 18s - loss: 0.8772 - accuracy: 0.4688 - precision_1: 0.7862 - recall_1: 0.8389
Epoch 1: val_loss did not improve from 0.32645
30/30 [==============================] - 1s 10ms/step - loss: 0.7342 - accuracy: 0.5200 - precision_1: 0.5608 - recall_1: 0.9603 - val_loss: 0.6696 - val_accuracy: 0.5588 - val_precision_1: 0.5612 - val_recall_1: 0.9925
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7188 - accuracy: 0.5938 - precision_1: 0.5938 - recall_1: 1.0000
Epoch 2: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.5420 - precision_1: 0.5322 - recall_1: 0.9838 - val_loss: 0.6212 - val_accuracy: 0.6513 - val_precision_1: 0.6256 - val_recall_1: 0.9478
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6327 - accuracy: 0.6250 - precision_1: 0.6071 - recall_1: 0.9444
Epoch 3: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6859 - precision_1: 0.6339 - recall_1: 0.9374 - val_loss: 0.5816 - val_accuracy: 0.7563 - val_precision_1: 0.7500 - val_recall_1: 0.8507
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6214 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 4: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7847 - precision_1: 0.7483 - recall_1: 0.8828 - val_loss: 0.5516 - val_accuracy: 0.7773 - val_precision_1: 0.7914 - val_recall_1: 0.8209
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5444 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 5: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7931 - precision_1: 0.7801 - recall_1: 0.8384 - val_loss: 0.5273 - val_accuracy: 0.7815 - val_precision_1: 0.8154 - val_recall_1: 0.7910
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5387 - accuracy: 0.7500 - precision_1: 0.7059 - recall_1: 0.8000
Epoch 6: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7910 - precision_1: 0.7960 - recall_1: 0.8040 - val_loss: 0.5026 - val_accuracy: 0.7815 - val_precision_1: 0.8417 - val_recall_1: 0.7537
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4665 - accuracy: 0.7812 - precision_1: 0.8636 - recall_1: 0.8261
Epoch 7: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.8025 - precision_1: 0.8191 - recall_1: 0.7960 - val_loss: 0.4837 - val_accuracy: 0.7941 - val_precision_1: 0.8632 - val_recall_1: 0.7537
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5156 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 8: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8057 - precision_1: 0.8312 - recall_1: 0.7859 - val_loss: 0.4692 - val_accuracy: 0.7983 - val_precision_1: 0.8707 - val_recall_1: 0.7537
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4182 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 9: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.8078 - precision_1: 0.8319 - recall_1: 0.7899 - val_loss: 0.4602 - val_accuracy: 0.8025 - val_precision_1: 0.8718 - val_recall_1: 0.7612
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3848 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 10: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8141 - precision_1: 0.8340 - recall_1: 0.8020 - val_loss: 0.4546 - val_accuracy: 0.8109 - val_precision_1: 0.8678 - val_recall_1: 0.7836
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3661 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7778
Epoch 11: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8204 - precision_1: 0.8375 - recall_1: 0.8121 - val_loss: 0.4515 - val_accuracy: 0.8025 - val_precision_1: 0.8537 - val_recall_1: 0.7836
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3545 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 12: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8277 - precision_1: 0.8384 - recall_1: 0.8283 - val_loss: 0.4479 - val_accuracy: 0.8109 - val_precision_1: 0.8560 - val_recall_1: 0.7985
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5640 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.6667
Epoch 13: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8298 - precision_1: 0.8391 - recall_1: 0.8323 - val_loss: 0.4462 - val_accuracy: 0.8025 - val_precision_1: 0.8425 - val_recall_1: 0.7985
Epoch 14/100
30/30 [==============================] - ETA: 0s - loss: 0.4247 - accuracy: 0.8319 - precision_1: 0.8370 - recall_1: 0.8404
Epoch 14: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8319 - precision_1: 0.8370 - recall_1: 0.8404 - val_loss: 0.4449 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2455 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.7692
Epoch 15: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8403 - precision_1: 0.8437 - recall_1: 0.8505 - val_loss: 0.4435 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2463 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 16: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8403 - precision_1: 0.8383 - recall_1: 0.8586 - val_loss: 0.4444 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3517 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8125
Epoch 17: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8403 - precision_1: 0.8383 - recall_1: 0.8586 - val_loss: 0.4451 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2892 - accuracy: 0.8750 - precision_1: 0.9231 - recall_1: 0.8000
Epoch 18: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8372 - precision_1: 0.8386 - recall_1: 0.8505 - val_loss: 0.4424 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4448 - accuracy: 0.7812 - precision_1: 0.7857 - recall_1: 0.7333
Epoch 19: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8414 - precision_1: 0.8399 - recall_1: 0.8586 - val_loss: 0.4410 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5852 - accuracy: 0.7500 - precision_1: 0.7895 - recall_1: 0.7895
Epoch 20: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8424 - precision_1: 0.8389 - recall_1: 0.8626 - val_loss: 0.4403 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4451 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.9091
Epoch 21: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8424 - precision_1: 0.8376 - recall_1: 0.8646 - val_loss: 0.4397 - val_accuracy: 0.8151 - val_precision_1: 0.8516 - val_recall_1: 0.8134
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3850 - accuracy: 0.8438 - precision_1: 0.7857 - recall_1: 0.8462
Epoch 22: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8414 - precision_1: 0.8373 - recall_1: 0.8626 - val_loss: 0.4388 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3202 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 23: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8445 - precision_1: 0.8395 - recall_1: 0.8667 - val_loss: 0.4385 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5303 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 24: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8477 - precision_1: 0.8405 - recall_1: 0.8727 - val_loss: 0.4396 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3087 - accuracy: 0.8750 - precision_1: 0.9286 - recall_1: 0.8125
Epoch 25: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8445 - precision_1: 0.8395 - recall_1: 0.8667 - val_loss: 0.4377 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.7500
Epoch 26: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8477 - precision_1: 0.8391 - recall_1: 0.8747 - val_loss: 0.4388 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2701 - accuracy: 0.9062 - precision_1: 0.9500 - recall_1: 0.9048
Epoch 27: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8456 - precision_1: 0.8412 - recall_1: 0.8667 - val_loss: 0.4354 - val_accuracy: 0.8151 - val_precision_1: 0.8462 - val_recall_1: 0.8209
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2773 - accuracy: 0.9375 - precision_1: 0.9333 - recall_1: 0.9333
Epoch 28: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8456 - precision_1: 0.8425 - recall_1: 0.8646 - val_loss: 0.4326 - val_accuracy: 0.8109 - val_precision_1: 0.8397 - val_recall_1: 0.8209
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2328 - accuracy: 0.9375 - precision_1: 0.8947 - recall_1: 1.0000
Epoch 29: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8456 - precision_1: 0.8398 - recall_1: 0.8687 - val_loss: 0.4346 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3319 - accuracy: 0.8438 - precision_1: 0.8462 - recall_1: 0.7857
Epoch 30: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8424 - precision_1: 0.8389 - recall_1: 0.8626 - val_loss: 0.4352 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3050 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 31: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8487 - precision_1: 0.8448 - recall_1: 0.8687 - val_loss: 0.4365 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4536 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.7500
Epoch 32: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8466 - precision_1: 0.8455 - recall_1: 0.8626 - val_loss: 0.4297 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2679 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 33: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8466 - precision_1: 0.8455 - recall_1: 0.8626 - val_loss: 0.4300 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4066 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 34: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8456 - precision_1: 0.8425 - recall_1: 0.8646 - val_loss: 0.4289 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3651 - accuracy: 0.8438 - precision_1: 0.8750 - recall_1: 0.8235
Epoch 35: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8456 - precision_1: 0.8412 - recall_1: 0.8667 - val_loss: 0.4287 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1809 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9444
Epoch 36: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8498 - precision_1: 0.8451 - recall_1: 0.8707 - val_loss: 0.4323 - val_accuracy: 0.8193 - val_precision_1: 0.8583 - val_recall_1: 0.8134
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4247 - accuracy: 0.8438 - precision_1: 0.7059 - recall_1: 1.0000
Epoch 37: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8477 - precision_1: 0.8445 - recall_1: 0.8667 - val_loss: 0.4302 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4965 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 38: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8487 - precision_1: 0.8489 - recall_1: 0.8626 - val_loss: 0.4274 - val_accuracy: 0.8067 - val_precision_1: 0.8333 - val_recall_1: 0.8209
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5592 - accuracy: 0.7812 - precision_1: 0.7727 - recall_1: 0.8947
Epoch 39: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8508 - precision_1: 0.8454 - recall_1: 0.8727 - val_loss: 0.4290 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2392 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 40: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8498 - precision_1: 0.8438 - recall_1: 0.8727 - val_loss: 0.4288 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4035 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 41: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8477 - precision_1: 0.8458 - recall_1: 0.8646 - val_loss: 0.4267 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3371 - accuracy: 0.8125 - precision_1: 0.7222 - recall_1: 0.9286
Epoch 42: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8487 - precision_1: 0.8448 - recall_1: 0.8687 - val_loss: 0.4272 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2721 - accuracy: 0.9688 - precision_1: 0.9444 - recall_1: 1.0000
Epoch 43: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3768 - accuracy: 0.8456 - precision_1: 0.8425 - recall_1: 0.8646 - val_loss: 0.4275 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5115 - accuracy: 0.7500 - precision_1: 0.7857 - recall_1: 0.6875
Epoch 44: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3764 - accuracy: 0.8477 - precision_1: 0.8458 - recall_1: 0.8646 - val_loss: 0.4271 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4286 - accuracy: 0.8125 - precision_1: 0.8889 - recall_1: 0.8000
Epoch 45: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8519 - precision_1: 0.8540 - recall_1: 0.8626 - val_loss: 0.4235 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4029 - accuracy: 0.8125 - precision_1: 0.7000 - recall_1: 1.0000
Epoch 46: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8508 - precision_1: 0.8481 - recall_1: 0.8687 - val_loss: 0.4232 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4759 - accuracy: 0.7812 - precision_1: 0.8500 - recall_1: 0.8095
Epoch 47: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8519 - precision_1: 0.8498 - recall_1: 0.8687 - val_loss: 0.4248 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1988 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9375
Epoch 48: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8529 - precision_1: 0.8487 - recall_1: 0.8727 - val_loss: 0.4266 - val_accuracy: 0.8235 - val_precision_1: 0.8651 - val_recall_1: 0.8134
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1495 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000
Epoch 49: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8540 - precision_1: 0.8532 - recall_1: 0.8687 - val_loss: 0.4224 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3434 - accuracy: 0.8750 - precision_1: 0.9048 - recall_1: 0.9048
Epoch 50: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8540 - precision_1: 0.8490 - recall_1: 0.8747 - val_loss: 0.4241 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3462 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 51: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8561 - precision_1: 0.8566 - recall_1: 0.8687 - val_loss: 0.4220 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4286 - accuracy: 0.8125 - precision_1: 1.0000 - recall_1: 0.6667
Epoch 52: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8529 - precision_1: 0.8460 - recall_1: 0.8768 - val_loss: 0.4239 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3769 - accuracy: 0.8438 - precision_1: 0.7692 - recall_1: 0.8333
Epoch 53: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8550 - precision_1: 0.8507 - recall_1: 0.8747 - val_loss: 0.4264 - val_accuracy: 0.8277 - val_precision_1: 0.8661 - val_recall_1: 0.8209
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4495 - accuracy: 0.7812 - precision_1: 0.8182 - recall_1: 0.8571
Epoch 54: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3721 - accuracy: 0.8550 - precision_1: 0.8549 - recall_1: 0.8687 - val_loss: 0.4243 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3220 - accuracy: 0.8750 - precision_1: 0.7500 - recall_1: 1.0000
Epoch 55: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8571 - precision_1: 0.8569 - recall_1: 0.8707 - val_loss: 0.4217 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3704 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 0.9231
Epoch 56: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8561 - precision_1: 0.8552 - recall_1: 0.8707 - val_loss: 0.4202 - val_accuracy: 0.8235 - val_precision_1: 0.8485 - val_recall_1: 0.8358
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2874 - accuracy: 0.9375 - precision_1: 0.9444 - recall_1: 0.9444
Epoch 57: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3712 - accuracy: 0.8561 - precision_1: 0.8566 - recall_1: 0.8687 - val_loss: 0.4206 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5487 - accuracy: 0.7500 - precision_1: 0.7500 - recall_1: 0.8333
Epoch 58: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8550 - precision_1: 0.8549 - recall_1: 0.8687 - val_loss: 0.4243 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2983 - accuracy: 0.8438 - precision_1: 0.7895 - recall_1: 0.9375
Epoch 59: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8540 - precision_1: 0.8546 - recall_1: 0.8667 - val_loss: 0.4206 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6114 - accuracy: 0.7188 - precision_1: 0.6842 - recall_1: 0.8125
Epoch 60: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8540 - precision_1: 0.8490 - recall_1: 0.8747 - val_loss: 0.4226 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3671 - accuracy: 0.8438 - precision_1: 0.6875 - recall_1: 1.0000
Epoch 61: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3696 - accuracy: 0.8582 - precision_1: 0.8571 - recall_1: 0.8727 - val_loss: 0.4226 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3625 - accuracy: 0.8438 - precision_1: 0.9333 - recall_1: 0.7778
Epoch 62: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3697 - accuracy: 0.8571 - precision_1: 0.8554 - recall_1: 0.8727 - val_loss: 0.4232 - val_accuracy: 0.8193 - val_precision_1: 0.8527 - val_recall_1: 0.8209
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4380 - accuracy: 0.8750 - precision_1: 0.8947 - recall_1: 0.8947
Epoch 63: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8540 - precision_1: 0.8560 - recall_1: 0.8646 - val_loss: 0.4206 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2612 - accuracy: 0.8750 - precision_1: 0.7647 - recall_1: 1.0000
Epoch 64: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8571 - precision_1: 0.8540 - recall_1: 0.8747 - val_loss: 0.4246 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3039 - accuracy: 0.9062 - precision_1: 0.8750 - recall_1: 0.9333
Epoch 65: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8561 - precision_1: 0.8580 - recall_1: 0.8667 - val_loss: 0.4185 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2763 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 66: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3682 - accuracy: 0.8571 - precision_1: 0.8554 - recall_1: 0.8727 - val_loss: 0.4190 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4010 - accuracy: 0.8125 - precision_1: 0.8500 - recall_1: 0.8500
Epoch 67: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8540 - precision_1: 0.8532 - recall_1: 0.8687 - val_loss: 0.4217 - val_accuracy: 0.8235 - val_precision_1: 0.8594 - val_recall_1: 0.8209
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5396 - accuracy: 0.7500 - precision_1: 0.7333 - recall_1: 0.7333
Epoch 68: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8571 - precision_1: 0.8583 - recall_1: 0.8687 - val_loss: 0.4198 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2655 - accuracy: 0.8750 - precision_1: 0.8824 - recall_1: 0.8824
Epoch 69: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8571 - precision_1: 0.8569 - recall_1: 0.8707 - val_loss: 0.4243 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2553 - accuracy: 0.9375 - precision_1: 0.8750 - recall_1: 1.0000
Epoch 70: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3677 - accuracy: 0.8540 - precision_1: 0.8560 - recall_1: 0.8646 - val_loss: 0.4204 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9062 - precision_1: 0.8421 - recall_1: 1.0000
Epoch 71: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8550 - precision_1: 0.8577 - recall_1: 0.8646 - val_loss: 0.4177 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.1850 - accuracy: 0.9688 - precision_1: 1.0000 - recall_1: 0.9375
Epoch 72: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8561 - precision_1: 0.8566 - recall_1: 0.8687 - val_loss: 0.4198 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3128 - accuracy: 0.8750 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 73: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8571 - precision_1: 0.8569 - recall_1: 0.8707 - val_loss: 0.4219 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3436 - accuracy: 0.8750 - precision_1: 0.8462 - recall_1: 0.8462
Epoch 74: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8571 - precision_1: 0.8597 - recall_1: 0.8667 - val_loss: 0.4183 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2823 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 75: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8571 - precision_1: 0.8554 - recall_1: 0.8727 - val_loss: 0.4192 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2842 - accuracy: 0.9375 - precision_1: 0.9412 - recall_1: 0.9412
Epoch 76: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8582 - precision_1: 0.8586 - recall_1: 0.8707 - val_loss: 0.4185 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3950 - accuracy: 0.8125 - precision_1: 0.8333 - recall_1: 0.8333
Epoch 77: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8582 - precision_1: 0.8557 - recall_1: 0.8747 - val_loss: 0.4203 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4040 - accuracy: 0.8750 - precision_1: 0.8889 - recall_1: 0.8889
Epoch 78: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8571 - precision_1: 0.8583 - recall_1: 0.8687 - val_loss: 0.4193 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4271 - accuracy: 0.8438 - precision_1: 0.7059 - recall_1: 1.0000
Epoch 79: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8561 - precision_1: 0.8566 - recall_1: 0.8687 - val_loss: 0.4198 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2607 - accuracy: 0.9062 - precision_1: 0.8947 - recall_1: 0.9444
Epoch 80: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8592 - precision_1: 0.8588 - recall_1: 0.8727 - val_loss: 0.4199 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2268 - accuracy: 0.9688 - precision_1: 0.9565 - recall_1: 1.0000
Epoch 81: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8561 - precision_1: 0.8552 - recall_1: 0.8707 - val_loss: 0.4187 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4250 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 82: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8550 - precision_1: 0.8563 - recall_1: 0.8667 - val_loss: 0.4186 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2676 - accuracy: 0.9062 - precision_1: 0.8667 - recall_1: 0.9286
Epoch 83: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8561 - precision_1: 0.8580 - recall_1: 0.8667 - val_loss: 0.4179 - val_accuracy: 0.8193 - val_precision_1: 0.8473 - val_recall_1: 0.8284
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2836 - accuracy: 0.8438 - precision_1: 0.7143 - recall_1: 0.9091
Epoch 84: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8582 - precision_1: 0.8571 - recall_1: 0.8727 - val_loss: 0.4187 - val_accuracy: 0.8235 - val_precision_1: 0.8538 - val_recall_1: 0.8284
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3918 - accuracy: 0.7812 - precision_1: 0.8571 - recall_1: 0.7059
Epoch 85: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8592 - precision_1: 0.8574 - recall_1: 0.8747 - val_loss: 0.4209 - val_accuracy: 0.8361 - val_precision_1: 0.8740 - val_recall_1: 0.8284
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3590 - accuracy: 0.8750 - precision_1: 0.7500 - recall_1: 1.0000
Epoch 86: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8603 - precision_1: 0.8591 - recall_1: 0.8747 - val_loss: 0.4190 - val_accuracy: 0.8277 - val_precision_1: 0.8605 - val_recall_1: 0.8284
Epoch 86: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Remove-slope">Remove slope<a class="anchor-link" href="#Remove-slope">¶</a></h2><ul>
<li>val_accuracy: 0.8025</li>
<li>val_loss: 0.4664</li>
<li>val_precision: 0.8015</li>
<li>val_recall: 0.8333</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [175]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">STRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">CTTRAIN</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">SVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">CTVALID</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_slope_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_slope_model"</span><span class="p">)</span>
<span class="n">less_slope_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,)))</span>
<span class="n">less_slope_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_slope_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_slope_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_slope_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_slope_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_slope_history</span> <span class="o">=</span> <span class="n">less_slope_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">STRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">SVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 19s - loss: 0.7177 - accuracy: 0.3125 - precision_1: 0.8605 - recall_1: 0.7115
Epoch 1: val_loss did not improve from 0.32645
30/30 [==============================] - 1s 10ms/step - loss: 0.6820 - accuracy: 0.5357 - precision_1: 0.8614 - recall_1: 0.2766 - val_loss: 0.6724 - val_accuracy: 0.6134 - val_precision_1: 0.9200 - val_recall_1: 0.3433
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6546 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.3636
Epoch 2: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6838 - precision_1: 0.8819 - recall_1: 0.4525 - val_loss: 0.6580 - val_accuracy: 0.7227 - val_precision_1: 0.9474 - val_recall_1: 0.5373
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6648 - accuracy: 0.7812 - precision_1: 0.7692 - recall_1: 0.7143
Epoch 3: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.7437 - precision_1: 0.8438 - recall_1: 0.6222 - val_loss: 0.6422 - val_accuracy: 0.7899 - val_precision_1: 0.9468 - val_recall_1: 0.6642
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6058 - accuracy: 0.8750 - precision_1: 0.9231 - recall_1: 0.8000
Epoch 4: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.7532 - precision_1: 0.8457 - recall_1: 0.6424 - val_loss: 0.6242 - val_accuracy: 0.8025 - val_precision_1: 0.9485 - val_recall_1: 0.6866
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6491 - accuracy: 0.6875 - precision_1: 0.8889 - recall_1: 0.4706
Epoch 5: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.7553 - precision_1: 0.8325 - recall_1: 0.6626 - val_loss: 0.6016 - val_accuracy: 0.8067 - val_precision_1: 0.9400 - val_recall_1: 0.7015
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5282 - accuracy: 0.9688 - precision_1: 0.9375 - recall_1: 1.0000
Epoch 6: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7626 - precision_1: 0.8321 - recall_1: 0.6808 - val_loss: 0.5779 - val_accuracy: 0.8151 - val_precision_1: 0.9167 - val_recall_1: 0.7388
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6170 - accuracy: 0.7500 - precision_1: 0.8333 - recall_1: 0.7500
Epoch 7: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7752 - precision_1: 0.8230 - recall_1: 0.7232 - val_loss: 0.5512 - val_accuracy: 0.8109 - val_precision_1: 0.9083 - val_recall_1: 0.7388
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5744 - accuracy: 0.7188 - precision_1: 0.8750 - recall_1: 0.6667
Epoch 8: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7857 - precision_1: 0.8241 - recall_1: 0.7475 - val_loss: 0.5275 - val_accuracy: 0.8151 - val_precision_1: 0.9018 - val_recall_1: 0.7537
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6038 - accuracy: 0.6875 - precision_1: 0.8824 - recall_1: 0.6522
Epoch 9: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7868 - precision_1: 0.8188 - recall_1: 0.7576 - val_loss: 0.5072 - val_accuracy: 0.8109 - val_precision_1: 0.8938 - val_recall_1: 0.7537
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4847 - accuracy: 0.7812 - precision_1: 0.7895 - recall_1: 0.8333
Epoch 10: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7899 - precision_1: 0.8145 - recall_1: 0.7717 - val_loss: 0.4912 - val_accuracy: 0.8067 - val_precision_1: 0.8860 - val_recall_1: 0.7537
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5156 - accuracy: 0.7812 - precision_1: 0.7273 - recall_1: 0.9412
Epoch 11: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7857 - precision_1: 0.8076 - recall_1: 0.7717 - val_loss: 0.4789 - val_accuracy: 0.8067 - val_precision_1: 0.8793 - val_recall_1: 0.7612
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4071 - accuracy: 0.9062 - precision_1: 0.8571 - recall_1: 1.0000
Epoch 12: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7868 - precision_1: 0.8120 - recall_1: 0.7677 - val_loss: 0.4709 - val_accuracy: 0.8025 - val_precision_1: 0.8718 - val_recall_1: 0.7612
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4703 - accuracy: 0.7812 - precision_1: 0.6875 - recall_1: 0.8462
Epoch 13: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7899 - precision_1: 0.8145 - recall_1: 0.7717 - val_loss: 0.4659 - val_accuracy: 0.8025 - val_precision_1: 0.8718 - val_recall_1: 0.7612
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6762 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.6250
Epoch 14: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7899 - precision_1: 0.8118 - recall_1: 0.7758 - val_loss: 0.4631 - val_accuracy: 0.8025 - val_precision_1: 0.8718 - val_recall_1: 0.7612
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4198 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 15: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7931 - precision_1: 0.8157 - recall_1: 0.7778 - val_loss: 0.4617 - val_accuracy: 0.7983 - val_precision_1: 0.8707 - val_recall_1: 0.7537
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3915 - accuracy: 0.7812 - precision_1: 0.9231 - recall_1: 0.6667
Epoch 16: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7962 - precision_1: 0.8195 - recall_1: 0.7798 - val_loss: 0.4605 - val_accuracy: 0.7983 - val_precision_1: 0.8707 - val_recall_1: 0.7537
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4121 - accuracy: 0.8438 - precision_1: 0.8235 - recall_1: 0.8750
Epoch 17: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7941 - precision_1: 0.8174 - recall_1: 0.7778 - val_loss: 0.4595 - val_accuracy: 0.7983 - val_precision_1: 0.8707 - val_recall_1: 0.7537
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4838 - accuracy: 0.7812 - precision_1: 0.8571 - recall_1: 0.7059
Epoch 18: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7941 - precision_1: 0.8174 - recall_1: 0.7778 - val_loss: 0.4592 - val_accuracy: 0.7983 - val_precision_1: 0.8707 - val_recall_1: 0.7537
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3594 - accuracy: 0.9062 - precision_1: 0.9333 - recall_1: 0.8750
Epoch 19: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7973 - precision_1: 0.8172 - recall_1: 0.7859 - val_loss: 0.4593 - val_accuracy: 0.7941 - val_precision_1: 0.8696 - val_recall_1: 0.7463
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3664 - accuracy: 0.8438 - precision_1: 0.7500 - recall_1: 0.8182
Epoch 20: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7962 - precision_1: 0.8209 - recall_1: 0.7778 - val_loss: 0.4581 - val_accuracy: 0.7983 - val_precision_1: 0.8707 - val_recall_1: 0.7537
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5245 - accuracy: 0.7188 - precision_1: 0.6000 - recall_1: 0.5455
Epoch 21: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7973 - precision_1: 0.8186 - recall_1: 0.7838 - val_loss: 0.4582 - val_accuracy: 0.7941 - val_precision_1: 0.8696 - val_recall_1: 0.7463
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2714 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 22: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7952 - precision_1: 0.8191 - recall_1: 0.7778 - val_loss: 0.4580 - val_accuracy: 0.7941 - val_precision_1: 0.8696 - val_recall_1: 0.7463
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2998 - accuracy: 0.9062 - precision_1: 0.9333 - recall_1: 0.8750
Epoch 23: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7983 - precision_1: 0.8217 - recall_1: 0.7818 - val_loss: 0.4576 - val_accuracy: 0.7941 - val_precision_1: 0.8696 - val_recall_1: 0.7463
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4954 - accuracy: 0.7500 - precision_1: 0.7368 - recall_1: 0.8235
Epoch 24: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7983 - precision_1: 0.8189 - recall_1: 0.7859 - val_loss: 0.4575 - val_accuracy: 0.7857 - val_precision_1: 0.8547 - val_recall_1: 0.7463
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4659 - accuracy: 0.8125 - precision_1: 0.9412 - recall_1: 0.7619
Epoch 25: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.8015 - precision_1: 0.8214 - recall_1: 0.7899 - val_loss: 0.4576 - val_accuracy: 0.7899 - val_precision_1: 0.8559 - val_recall_1: 0.7537
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5311 - accuracy: 0.6875 - precision_1: 0.7333 - recall_1: 0.6471
Epoch 26: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.8004 - precision_1: 0.8197 - recall_1: 0.7899 - val_loss: 0.4575 - val_accuracy: 0.7899 - val_precision_1: 0.8559 - val_recall_1: 0.7537
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3518 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 27: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8004 - precision_1: 0.8197 - recall_1: 0.7899 - val_loss: 0.4575 - val_accuracy: 0.7899 - val_precision_1: 0.8559 - val_recall_1: 0.7537
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4621 - accuracy: 0.8750 - precision_1: 0.9524 - recall_1: 0.8696
Epoch 28: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.8015 - precision_1: 0.8214 - recall_1: 0.7899 - val_loss: 0.4570 - val_accuracy: 0.7857 - val_precision_1: 0.8487 - val_recall_1: 0.7537
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4240 - accuracy: 0.7812 - precision_1: 0.6667 - recall_1: 0.8333
Epoch 29: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7994 - precision_1: 0.8180 - recall_1: 0.7899 - val_loss: 0.4573 - val_accuracy: 0.7857 - val_precision_1: 0.8547 - val_recall_1: 0.7463
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5393 - accuracy: 0.6875 - precision_1: 0.8000 - recall_1: 0.6316
Epoch 30: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7983 - precision_1: 0.8189 - recall_1: 0.7859 - val_loss: 0.4560 - val_accuracy: 0.7815 - val_precision_1: 0.8475 - val_recall_1: 0.7463
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4734 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8000
Epoch 31: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7952 - precision_1: 0.8165 - recall_1: 0.7818 - val_loss: 0.4558 - val_accuracy: 0.7815 - val_precision_1: 0.8475 - val_recall_1: 0.7463
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4028 - accuracy: 0.8438 - precision_1: 0.9048 - recall_1: 0.8636
Epoch 32: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.8004 - precision_1: 0.8184 - recall_1: 0.7919 - val_loss: 0.4564 - val_accuracy: 0.7815 - val_precision_1: 0.8475 - val_recall_1: 0.7463
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3811 - accuracy: 0.8125 - precision_1: 0.7857 - recall_1: 0.7857
Epoch 33: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.8004 - precision_1: 0.8266 - recall_1: 0.7798 - val_loss: 0.4555 - val_accuracy: 0.7815 - val_precision_1: 0.8475 - val_recall_1: 0.7463
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3576 - accuracy: 0.8438 - precision_1: 0.7500 - recall_1: 0.9231
Epoch 34: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7962 - precision_1: 0.8195 - recall_1: 0.7798 - val_loss: 0.4553 - val_accuracy: 0.7815 - val_precision_1: 0.8475 - val_recall_1: 0.7463
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2993 - accuracy: 0.9375 - precision_1: 0.8824 - recall_1: 1.0000
Epoch 35: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7973 - precision_1: 0.8213 - recall_1: 0.7798 - val_loss: 0.4550 - val_accuracy: 0.7815 - val_precision_1: 0.8475 - val_recall_1: 0.7463
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5041 - accuracy: 0.7188 - precision_1: 0.7500 - recall_1: 0.7059
Epoch 36: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8004 - precision_1: 0.8238 - recall_1: 0.7838 - val_loss: 0.4549 - val_accuracy: 0.7857 - val_precision_1: 0.8487 - val_recall_1: 0.7537
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6931 - accuracy: 0.6562 - precision_1: 0.8667 - recall_1: 0.5909
Epoch 37: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8025 - precision_1: 0.8245 - recall_1: 0.7879 - val_loss: 0.4557 - val_accuracy: 0.7857 - val_precision_1: 0.8487 - val_recall_1: 0.7537
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4975 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 38: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8046 - precision_1: 0.8266 - recall_1: 0.7899 - val_loss: 0.4558 - val_accuracy: 0.7857 - val_precision_1: 0.8487 - val_recall_1: 0.7537
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4268 - accuracy: 0.7500 - precision_1: 0.8182 - recall_1: 0.6000
Epoch 39: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.8067 - precision_1: 0.8246 - recall_1: 0.7980 - val_loss: 0.4561 - val_accuracy: 0.7899 - val_precision_1: 0.8559 - val_recall_1: 0.7537
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6278 - accuracy: 0.6875 - precision_1: 0.6250 - recall_1: 0.7143
Epoch 40: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8015 - precision_1: 0.8283 - recall_1: 0.7798 - val_loss: 0.4557 - val_accuracy: 0.7857 - val_precision_1: 0.8487 - val_recall_1: 0.7537
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3146 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 41: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7973 - precision_1: 0.8159 - recall_1: 0.7879 - val_loss: 0.4566 - val_accuracy: 0.7899 - val_precision_1: 0.8559 - val_recall_1: 0.7537
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4703 - accuracy: 0.8125 - precision_1: 0.7273 - recall_1: 0.7273
Epoch 42: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.8057 - precision_1: 0.8270 - recall_1: 0.7919 - val_loss: 0.4555 - val_accuracy: 0.7815 - val_precision_1: 0.8417 - val_recall_1: 0.7537
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3732 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 43: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8046 - precision_1: 0.8266 - recall_1: 0.7899 - val_loss: 0.4555 - val_accuracy: 0.7857 - val_precision_1: 0.8430 - val_recall_1: 0.7612
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4424 - accuracy: 0.8125 - precision_1: 0.9375 - recall_1: 0.7500
Epoch 44: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8036 - precision_1: 0.8208 - recall_1: 0.7960 - val_loss: 0.4559 - val_accuracy: 0.7815 - val_precision_1: 0.8417 - val_recall_1: 0.7537
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4413 - accuracy: 0.7812 - precision_1: 0.8824 - recall_1: 0.7500
Epoch 45: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.8057 - precision_1: 0.8270 - recall_1: 0.7919 - val_loss: 0.4551 - val_accuracy: 0.7899 - val_precision_1: 0.8443 - val_recall_1: 0.7687
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4224 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 46: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8025 - precision_1: 0.8245 - recall_1: 0.7879 - val_loss: 0.4546 - val_accuracy: 0.7899 - val_precision_1: 0.8443 - val_recall_1: 0.7687
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8750 - precision_1: 0.9500 - recall_1: 0.8636
Epoch 47: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8015 - precision_1: 0.8201 - recall_1: 0.7919 - val_loss: 0.4545 - val_accuracy: 0.7899 - val_precision_1: 0.8443 - val_recall_1: 0.7687
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5298 - accuracy: 0.7812 - precision_1: 0.7391 - recall_1: 0.9444
Epoch 48: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.8046 - precision_1: 0.8253 - recall_1: 0.7919 - val_loss: 0.4532 - val_accuracy: 0.7857 - val_precision_1: 0.8374 - val_recall_1: 0.7687
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4152 - accuracy: 0.8438 - precision_1: 0.9500 - recall_1: 0.8261
Epoch 49: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8046 - precision_1: 0.8225 - recall_1: 0.7960 - val_loss: 0.4539 - val_accuracy: 0.7899 - val_precision_1: 0.8443 - val_recall_1: 0.7687
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4075 - accuracy: 0.7812 - precision_1: 0.8667 - recall_1: 0.7222
Epoch 50: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.8046 - precision_1: 0.8266 - recall_1: 0.7899 - val_loss: 0.4534 - val_accuracy: 0.7857 - val_precision_1: 0.8374 - val_recall_1: 0.7687
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3776 - accuracy: 0.8125 - precision_1: 0.7368 - recall_1: 0.9333
Epoch 51: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.8046 - precision_1: 0.8266 - recall_1: 0.7899 - val_loss: 0.4528 - val_accuracy: 0.7857 - val_precision_1: 0.8374 - val_recall_1: 0.7687
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3737 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 52: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.8046 - precision_1: 0.8253 - recall_1: 0.7919 - val_loss: 0.4523 - val_accuracy: 0.7857 - val_precision_1: 0.8374 - val_recall_1: 0.7687
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4320 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 0.8571
Epoch 53: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8057 - precision_1: 0.8243 - recall_1: 0.7960 - val_loss: 0.4528 - val_accuracy: 0.7857 - val_precision_1: 0.8374 - val_recall_1: 0.7687
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4716 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 54: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.8036 - precision_1: 0.8235 - recall_1: 0.7919 - val_loss: 0.4525 - val_accuracy: 0.7857 - val_precision_1: 0.8374 - val_recall_1: 0.7687
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3475 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 55: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8078 - precision_1: 0.8264 - recall_1: 0.7980 - val_loss: 0.4531 - val_accuracy: 0.7941 - val_precision_1: 0.8512 - val_recall_1: 0.7687
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3343 - accuracy: 0.9062 - precision_1: 0.9444 - recall_1: 0.8947
Epoch 56: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.8078 - precision_1: 0.8305 - recall_1: 0.7919 - val_loss: 0.4514 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4261 - accuracy: 0.8438 - precision_1: 0.8667 - recall_1: 0.8125
Epoch 57: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8046 - precision_1: 0.8225 - recall_1: 0.7960 - val_loss: 0.4516 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3924 - accuracy: 0.8125 - precision_1: 0.8889 - recall_1: 0.8000
Epoch 58: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.8078 - precision_1: 0.8264 - recall_1: 0.7980 - val_loss: 0.4515 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4643 - accuracy: 0.7500 - precision_1: 0.7857 - recall_1: 0.6875
Epoch 59: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8088 - precision_1: 0.8281 - recall_1: 0.7980 - val_loss: 0.4511 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 60/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3349 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 60: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8057 - precision_1: 0.8229 - recall_1: 0.7980 - val_loss: 0.4510 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 61/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4585 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.7692
Epoch 61: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8088 - precision_1: 0.8281 - recall_1: 0.7980 - val_loss: 0.4499 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 62/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3532 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 62: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8078 - precision_1: 0.8237 - recall_1: 0.8020 - val_loss: 0.4496 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 63/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4613 - accuracy: 0.7812 - precision_1: 0.8000 - recall_1: 0.8421
Epoch 63: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8088 - precision_1: 0.8240 - recall_1: 0.8040 - val_loss: 0.4496 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 64/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4445 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 64: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8120 - precision_1: 0.8305 - recall_1: 0.8020 - val_loss: 0.4490 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 65/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3753 - accuracy: 0.8438 - precision_1: 0.8421 - recall_1: 0.8889
Epoch 65: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8088 - precision_1: 0.8254 - recall_1: 0.8020 - val_loss: 0.4496 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 66/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3032 - accuracy: 0.8750 - precision_1: 0.9524 - recall_1: 0.8696
Epoch 66: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.8088 - precision_1: 0.8254 - recall_1: 0.8020 - val_loss: 0.4486 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 67/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2301 - accuracy: 0.9375 - precision_1: 1.0000 - recall_1: 0.8824
Epoch 67: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.8099 - precision_1: 0.8271 - recall_1: 0.8020 - val_loss: 0.4482 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 68/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3325 - accuracy: 0.9062 - precision_1: 0.9048 - recall_1: 0.9500
Epoch 68: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8088 - precision_1: 0.8254 - recall_1: 0.8020 - val_loss: 0.4470 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 69/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4566 - accuracy: 0.8750 - precision_1: 0.9000 - recall_1: 0.7500
Epoch 69: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8067 - precision_1: 0.8206 - recall_1: 0.8040 - val_loss: 0.4479 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 70/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5432 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 70: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8109 - precision_1: 0.8274 - recall_1: 0.8040 - val_loss: 0.4483 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 71/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4757 - accuracy: 0.8125 - precision_1: 0.7778 - recall_1: 0.8750
Epoch 71: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8109 - precision_1: 0.8288 - recall_1: 0.8020 - val_loss: 0.4472 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 72/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4912 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 72: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8109 - precision_1: 0.8274 - recall_1: 0.8040 - val_loss: 0.4467 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 73/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4898 - accuracy: 0.7500 - precision_1: 0.8824 - recall_1: 0.7143
Epoch 73: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8078 - precision_1: 0.8223 - recall_1: 0.8040 - val_loss: 0.4465 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 74/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5840 - accuracy: 0.6562 - precision_1: 0.7778 - recall_1: 0.6667
Epoch 74: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8078 - precision_1: 0.8223 - recall_1: 0.8040 - val_loss: 0.4468 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 75/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5105 - accuracy: 0.7188 - precision_1: 0.7333 - recall_1: 0.6875
Epoch 75: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8067 - precision_1: 0.8206 - recall_1: 0.8040 - val_loss: 0.4464 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 76/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3667 - accuracy: 0.8750 - precision_1: 1.0000 - recall_1: 0.7500
Epoch 76: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8057 - precision_1: 0.8189 - recall_1: 0.8040 - val_loss: 0.4457 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 77/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3354 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 77: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.8099 - precision_1: 0.8271 - recall_1: 0.8020 - val_loss: 0.4444 - val_accuracy: 0.7941 - val_precision_1: 0.8400 - val_recall_1: 0.7836
Epoch 78/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2912 - accuracy: 0.8750 - precision_1: 0.8235 - recall_1: 0.9333
Epoch 78: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8057 - precision_1: 0.8189 - recall_1: 0.8040 - val_loss: 0.4453 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 79/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5717 - accuracy: 0.7188 - precision_1: 0.7778 - recall_1: 0.7368
Epoch 79: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8067 - precision_1: 0.8206 - recall_1: 0.8040 - val_loss: 0.4456 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 80/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4180 - accuracy: 0.8438 - precision_1: 0.7647 - recall_1: 0.9286
Epoch 80: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8078 - precision_1: 0.8223 - recall_1: 0.8040 - val_loss: 0.4450 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 81/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4657 - accuracy: 0.7812 - precision_1: 0.7059 - recall_1: 0.8571
Epoch 81: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8078 - precision_1: 0.8223 - recall_1: 0.8040 - val_loss: 0.4443 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 82/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4939 - accuracy: 0.7812 - precision_1: 0.8235 - recall_1: 0.7778
Epoch 82: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8088 - precision_1: 0.8227 - recall_1: 0.8061 - val_loss: 0.4444 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 83/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6587 - accuracy: 0.6875 - precision_1: 0.6923 - recall_1: 0.6000
Epoch 83: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8088 - precision_1: 0.8227 - recall_1: 0.8061 - val_loss: 0.4449 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 84/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6656 - accuracy: 0.5938 - precision_1: 0.6667 - recall_1: 0.4706
Epoch 84: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8088 - precision_1: 0.8240 - recall_1: 0.8040 - val_loss: 0.4448 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 85/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3800 - accuracy: 0.8125 - precision_1: 0.8235 - recall_1: 0.8235
Epoch 85: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8109 - precision_1: 0.8274 - recall_1: 0.8040 - val_loss: 0.4434 - val_accuracy: 0.7983 - val_precision_1: 0.8413 - val_recall_1: 0.7910
Epoch 86/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4752 - accuracy: 0.8438 - precision_1: 0.8571 - recall_1: 0.8000
Epoch 86: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8078 - precision_1: 0.8223 - recall_1: 0.8040 - val_loss: 0.4431 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 87/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3398 - accuracy: 0.8438 - precision_1: 0.8125 - recall_1: 0.8667
Epoch 87: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.8067 - precision_1: 0.8206 - recall_1: 0.8040 - val_loss: 0.4430 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 88/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3234 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 88: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8067 - precision_1: 0.8206 - recall_1: 0.8040 - val_loss: 0.4436 - val_accuracy: 0.7899 - val_precision_1: 0.8387 - val_recall_1: 0.7761
Epoch 89/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3612 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 89: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.8078 - precision_1: 0.8210 - recall_1: 0.8061 - val_loss: 0.4445 - val_accuracy: 0.7983 - val_precision_1: 0.8525 - val_recall_1: 0.7761
Epoch 90/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5325 - accuracy: 0.7500 - precision_1: 0.9412 - recall_1: 0.6957
Epoch 90: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8120 - precision_1: 0.8292 - recall_1: 0.8040 - val_loss: 0.4441 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 91/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3389 - accuracy: 0.8438 - precision_1: 0.9412 - recall_1: 0.8000
Epoch 91: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.8120 - precision_1: 0.8278 - recall_1: 0.8061 - val_loss: 0.4439 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 92/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4441 - accuracy: 0.8438 - precision_1: 0.9091 - recall_1: 0.7143
Epoch 92: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8109 - precision_1: 0.8261 - recall_1: 0.8061 - val_loss: 0.4435 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 93/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5232 - accuracy: 0.7500 - precision_1: 0.8000 - recall_1: 0.7059
Epoch 93: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8099 - precision_1: 0.8257 - recall_1: 0.8040 - val_loss: 0.4437 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 94/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8750 - precision_1: 0.8421 - recall_1: 0.9412
Epoch 94: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8130 - precision_1: 0.8309 - recall_1: 0.8040 - val_loss: 0.4417 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 95/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5785 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.8333
Epoch 95: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8099 - precision_1: 0.8257 - recall_1: 0.8040 - val_loss: 0.4418 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 96/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2590 - accuracy: 0.9062 - precision_1: 0.9375 - recall_1: 0.8824
Epoch 96: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8109 - precision_1: 0.8274 - recall_1: 0.8040 - val_loss: 0.4413 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 97/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3885 - accuracy: 0.8438 - precision_1: 0.8333 - recall_1: 0.8824
Epoch 97: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8099 - precision_1: 0.8257 - recall_1: 0.8040 - val_loss: 0.4404 - val_accuracy: 0.8025 - val_precision_1: 0.8480 - val_recall_1: 0.7910
Epoch 98/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3634 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 98: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8120 - precision_1: 0.8292 - recall_1: 0.8040 - val_loss: 0.4402 - val_accuracy: 0.8025 - val_precision_1: 0.8480 - val_recall_1: 0.7910
Epoch 99/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.2649 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 99: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8088 - precision_1: 0.8227 - recall_1: 0.8061 - val_loss: 0.4406 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
Epoch 100/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4982 - accuracy: 0.7500 - precision_1: 0.7857 - recall_1: 0.6875
Epoch 100: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.8120 - precision_1: 0.8292 - recall_1: 0.8040 - val_loss: 0.4404 - val_accuracy: 0.7941 - val_precision_1: 0.8455 - val_recall_1: 0.7761
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Remove-Old-peak">Remove Old peak<a class="anchor-link" href="#Remove-Old-peak">¶</a></h2><ul>
<li>val_accuracy: 0.7311</li>
<li>val_loss: 0.5201</li>
<li>val_precision: 0.7627</li>
<li>val_recall: 0.7143</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [176]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">OTRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">STRAIN</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">OVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">SVALID</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_old_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_old_model"</span><span class="p">)</span>
<span class="n">less_old_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,)))</span>
<span class="n">less_old_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_old_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_old_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_old_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_old_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_old_history</span> <span class="o">=</span> <span class="n">less_old_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">OTRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">OVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 18s - loss: 0.6702 - accuracy: 0.5938 - precision_1: 0.8455 - recall_1: 0.7075
Epoch 1: val_loss did not improve from 0.32645
30/30 [==============================] - 1s 10ms/step - loss: 0.6889 - accuracy: 0.4779 - precision_1: 0.8029 - recall_1: 0.1749 - val_loss: 0.6782 - val_accuracy: 0.4496 - val_precision_1: 0.6667 - val_recall_1: 0.0448
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6732 - accuracy: 0.5625 - precision_1: 1.0000 - recall_1: 0.1250
Epoch 2: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5053 - precision_1: 0.6538 - recall_1: 0.1030 - val_loss: 0.6587 - val_accuracy: 0.5714 - val_precision_1: 0.8810 - val_recall_1: 0.2761
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6345 - accuracy: 0.6562 - precision_1: 0.8571 - recall_1: 0.3750
Epoch 3: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6691 - precision_1: 0.8169 - recall_1: 0.4687 - val_loss: 0.6430 - val_accuracy: 0.7227 - val_precision_1: 0.8953 - val_recall_1: 0.5746
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6737 - accuracy: 0.5938 - precision_1: 0.9167 - recall_1: 0.4783
Epoch 4: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.7237 - precision_1: 0.8187 - recall_1: 0.6020 - val_loss: 0.6296 - val_accuracy: 0.7227 - val_precision_1: 0.8696 - val_recall_1: 0.5970
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6734 - accuracy: 0.6875 - precision_1: 0.8000 - recall_1: 0.6316
Epoch 5: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.7405 - precision_1: 0.8147 - recall_1: 0.6485 - val_loss: 0.6196 - val_accuracy: 0.7395 - val_precision_1: 0.8750 - val_recall_1: 0.6269
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5800 - accuracy: 0.8125 - precision_1: 0.9231 - recall_1: 0.7059
Epoch 6: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7384 - precision_1: 0.7985 - recall_1: 0.6646 - val_loss: 0.6122 - val_accuracy: 0.7395 - val_precision_1: 0.8529 - val_recall_1: 0.6493
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5977 - accuracy: 0.6875 - precision_1: 0.7500 - recall_1: 0.6667
Epoch 7: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7426 - precision_1: 0.7841 - recall_1: 0.6970 - val_loss: 0.6057 - val_accuracy: 0.7563 - val_precision_1: 0.8519 - val_recall_1: 0.6866
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6667 - accuracy: 0.6250 - precision_1: 0.8000 - recall_1: 0.5714
Epoch 8: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7500 - precision_1: 0.7837 - recall_1: 0.7172 - val_loss: 0.5994 - val_accuracy: 0.7605 - val_precision_1: 0.8348 - val_recall_1: 0.7164
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5291 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 9: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7532 - precision_1: 0.7754 - recall_1: 0.7394 - val_loss: 0.5947 - val_accuracy: 0.7605 - val_precision_1: 0.8235 - val_recall_1: 0.7313
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5772 - accuracy: 0.6562 - precision_1: 0.5833 - recall_1: 0.5385
Epoch 10: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7553 - precision_1: 0.7729 - recall_1: 0.7495 - val_loss: 0.5906 - val_accuracy: 0.7605 - val_precision_1: 0.8235 - val_recall_1: 0.7313
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5162 - accuracy: 0.8438 - precision_1: 0.8889 - recall_1: 0.8421
Epoch 11: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7521 - precision_1: 0.7648 - recall_1: 0.7556 - val_loss: 0.5864 - val_accuracy: 0.7605 - val_precision_1: 0.8235 - val_recall_1: 0.7313
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5968 - accuracy: 0.7188 - precision_1: 0.7143 - recall_1: 0.6667
Epoch 12: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7532 - precision_1: 0.7653 - recall_1: 0.7576 - val_loss: 0.5825 - val_accuracy: 0.7731 - val_precision_1: 0.8279 - val_recall_1: 0.7537
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5004 - accuracy: 0.8750 - precision_1: 0.8667 - recall_1: 0.8667
Epoch 13: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7647 - precision_1: 0.7694 - recall_1: 0.7818 - val_loss: 0.5786 - val_accuracy: 0.7731 - val_precision_1: 0.8279 - val_recall_1: 0.7537
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5740 - accuracy: 0.7812 - precision_1: 0.8462 - recall_1: 0.6875
Epoch 14: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7647 - precision_1: 0.7652 - recall_1: 0.7899 - val_loss: 0.5756 - val_accuracy: 0.7773 - val_precision_1: 0.8293 - val_recall_1: 0.7612
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4962 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 15: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7668 - precision_1: 0.7703 - recall_1: 0.7859 - val_loss: 0.5716 - val_accuracy: 0.7731 - val_precision_1: 0.8175 - val_recall_1: 0.7687
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5221 - accuracy: 0.7812 - precision_1: 0.6667 - recall_1: 0.8333
Epoch 16: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7679 - precision_1: 0.7718 - recall_1: 0.7859 - val_loss: 0.5680 - val_accuracy: 0.7773 - val_precision_1: 0.8189 - val_recall_1: 0.7761
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5493 - accuracy: 0.7500 - precision_1: 0.6800 - recall_1: 1.0000
Epoch 17: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7679 - precision_1: 0.7665 - recall_1: 0.7960 - val_loss: 0.5654 - val_accuracy: 0.7731 - val_precision_1: 0.8175 - val_recall_1: 0.7687
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6555 - accuracy: 0.6875 - precision_1: 0.7059 - recall_1: 0.7059
Epoch 18: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7637 - precision_1: 0.7626 - recall_1: 0.7919 - val_loss: 0.5628 - val_accuracy: 0.7773 - val_precision_1: 0.8189 - val_recall_1: 0.7761
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5638 - accuracy: 0.7812 - precision_1: 0.8182 - recall_1: 0.8571
Epoch 19: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7637 - precision_1: 0.7626 - recall_1: 0.7919 - val_loss: 0.5598 - val_accuracy: 0.7773 - val_precision_1: 0.8189 - val_recall_1: 0.7761
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4976 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 20: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7658 - precision_1: 0.7667 - recall_1: 0.7899 - val_loss: 0.5565 - val_accuracy: 0.7815 - val_precision_1: 0.8203 - val_recall_1: 0.7836
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5789 - accuracy: 0.7812 - precision_1: 0.7895 - recall_1: 0.8333
Epoch 21: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7658 - precision_1: 0.7667 - recall_1: 0.7899 - val_loss: 0.5533 - val_accuracy: 0.7857 - val_precision_1: 0.8217 - val_recall_1: 0.7910
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6537 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 22: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7668 - precision_1: 0.7650 - recall_1: 0.7960 - val_loss: 0.5488 - val_accuracy: 0.7815 - val_precision_1: 0.8203 - val_recall_1: 0.7836
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4132 - accuracy: 0.9375 - precision_1: 0.9231 - recall_1: 0.9231
Epoch 23: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7605 - precision_1: 0.7623 - recall_1: 0.7838 - val_loss: 0.5264 - val_accuracy: 0.7815 - val_precision_1: 0.8203 - val_recall_1: 0.7836
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6892 - accuracy: 0.5938 - precision_1: 0.6111 - recall_1: 0.6471
Epoch 24: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7584 - precision_1: 0.7573 - recall_1: 0.7879 - val_loss: 0.5017 - val_accuracy: 0.7815 - val_precision_1: 0.8203 - val_recall_1: 0.7836
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5152 - accuracy: 0.6875 - precision_1: 0.7500 - recall_1: 0.6667
Epoch 25: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7626 - precision_1: 0.7612 - recall_1: 0.7919 - val_loss: 0.4886 - val_accuracy: 0.7815 - val_precision_1: 0.8203 - val_recall_1: 0.7836
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3467 - accuracy: 0.9062 - precision_1: 0.8889 - recall_1: 0.9412
Epoch 26: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7637 - precision_1: 0.7616 - recall_1: 0.7939 - val_loss: 0.4828 - val_accuracy: 0.7815 - val_precision_1: 0.8203 - val_recall_1: 0.7836
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5142 - accuracy: 0.7500 - precision_1: 0.7895 - recall_1: 0.7895
Epoch 27: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7637 - precision_1: 0.7637 - recall_1: 0.7899 - val_loss: 0.4799 - val_accuracy: 0.7857 - val_precision_1: 0.8268 - val_recall_1: 0.7836
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5554 - accuracy: 0.7188 - precision_1: 0.6429 - recall_1: 0.6923
Epoch 28: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7679 - precision_1: 0.7697 - recall_1: 0.7899 - val_loss: 0.4793 - val_accuracy: 0.7857 - val_precision_1: 0.8268 - val_recall_1: 0.7836
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3855 - accuracy: 0.8750 - precision_1: 0.8333 - recall_1: 0.9375
Epoch 29: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7668 - precision_1: 0.7692 - recall_1: 0.7879 - val_loss: 0.4788 - val_accuracy: 0.7815 - val_precision_1: 0.8254 - val_recall_1: 0.7761
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6436 - accuracy: 0.7188 - precision_1: 0.7222 - recall_1: 0.7647
Epoch 30: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7679 - precision_1: 0.7686 - recall_1: 0.7919 - val_loss: 0.4786 - val_accuracy: 0.7815 - val_precision_1: 0.8254 - val_recall_1: 0.7761
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5869 - accuracy: 0.7188 - precision_1: 0.7273 - recall_1: 0.8421
Epoch 31: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7721 - precision_1: 0.7736 - recall_1: 0.7939 - val_loss: 0.4786 - val_accuracy: 0.7773 - val_precision_1: 0.8240 - val_recall_1: 0.7687
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3489 - accuracy: 0.8438 - precision_1: 0.7895 - recall_1: 0.9375
Epoch 32: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7731 - precision_1: 0.7773 - recall_1: 0.7899 - val_loss: 0.4795 - val_accuracy: 0.7815 - val_precision_1: 0.8254 - val_recall_1: 0.7761
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4076 - accuracy: 0.8438 - precision_1: 0.8500 - recall_1: 0.8947
Epoch 33: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7710 - precision_1: 0.7764 - recall_1: 0.7859 - val_loss: 0.4798 - val_accuracy: 0.7773 - val_precision_1: 0.8240 - val_recall_1: 0.7687
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4499 - accuracy: 0.8438 - precision_1: 0.8824 - recall_1: 0.8333
Epoch 34: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7700 - precision_1: 0.7771 - recall_1: 0.7818 - val_loss: 0.4794 - val_accuracy: 0.7815 - val_precision_1: 0.8254 - val_recall_1: 0.7761
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6213 - accuracy: 0.6250 - precision_1: 0.6111 - recall_1: 0.6875
Epoch 35: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7700 - precision_1: 0.7717 - recall_1: 0.7919 - val_loss: 0.4803 - val_accuracy: 0.7773 - val_precision_1: 0.8240 - val_recall_1: 0.7687
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4258 - accuracy: 0.8438 - precision_1: 0.7778 - recall_1: 0.9333
Epoch 36: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7710 - precision_1: 0.7809 - recall_1: 0.7778 - val_loss: 0.4799 - val_accuracy: 0.7773 - val_precision_1: 0.8240 - val_recall_1: 0.7687
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5981 - accuracy: 0.8125 - precision_1: 0.8182 - recall_1: 0.9000
Epoch 37: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7710 - precision_1: 0.7776 - recall_1: 0.7838 - val_loss: 0.4812 - val_accuracy: 0.7731 - val_precision_1: 0.8226 - val_recall_1: 0.7612
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4902 - accuracy: 0.7812 - precision_1: 0.8125 - recall_1: 0.7647
Epoch 38: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7710 - precision_1: 0.7787 - recall_1: 0.7818 - val_loss: 0.4812 - val_accuracy: 0.7815 - val_precision_1: 0.8361 - val_recall_1: 0.7612
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5160 - accuracy: 0.7188 - precision_1: 0.7000 - recall_1: 0.8235
Epoch 39: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7700 - precision_1: 0.7782 - recall_1: 0.7798 - val_loss: 0.4818 - val_accuracy: 0.7815 - val_precision_1: 0.8361 - val_recall_1: 0.7612
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3298 - accuracy: 0.9062 - precision_1: 0.8824 - recall_1: 0.9375
Epoch 40: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7679 - precision_1: 0.7762 - recall_1: 0.7778 - val_loss: 0.4824 - val_accuracy: 0.7857 - val_precision_1: 0.8430 - val_recall_1: 0.7612
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5008 - accuracy: 0.8438 - precision_1: 0.9000 - recall_1: 0.6923
Epoch 41: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7700 - precision_1: 0.7805 - recall_1: 0.7758 - val_loss: 0.4828 - val_accuracy: 0.7857 - val_precision_1: 0.8430 - val_recall_1: 0.7612
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4758 - accuracy: 0.8438 - precision_1: 0.8095 - recall_1: 0.9444
Epoch 42: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7689 - precision_1: 0.7778 - recall_1: 0.7778 - val_loss: 0.4837 - val_accuracy: 0.7857 - val_precision_1: 0.8430 - val_recall_1: 0.7612
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6809 - accuracy: 0.6562 - precision_1: 0.6000 - recall_1: 0.6429
Epoch 43: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7710 - precision_1: 0.7821 - recall_1: 0.7758 - val_loss: 0.4834 - val_accuracy: 0.7857 - val_precision_1: 0.8430 - val_recall_1: 0.7612
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4849 - accuracy: 0.7188 - precision_1: 0.7273 - recall_1: 0.8421
Epoch 44: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7710 - precision_1: 0.7821 - recall_1: 0.7758 - val_loss: 0.4827 - val_accuracy: 0.7773 - val_precision_1: 0.8293 - val_recall_1: 0.7612
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6176 - accuracy: 0.6250 - precision_1: 0.7692 - recall_1: 0.5263
Epoch 45: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7700 - precision_1: 0.7805 - recall_1: 0.7758 - val_loss: 0.4828 - val_accuracy: 0.7857 - val_precision_1: 0.8430 - val_recall_1: 0.7612
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5714 - accuracy: 0.7812 - precision_1: 0.7222 - recall_1: 0.8667
Epoch 46: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7689 - precision_1: 0.7789 - recall_1: 0.7758 - val_loss: 0.4831 - val_accuracy: 0.7857 - val_precision_1: 0.8430 - val_recall_1: 0.7612
Epoch 46: early stopping
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Remove-Exercise-Angina">Remove Exercise Angina<a class="anchor-link" href="#Remove-Exercise-Angina">¶</a></h2><ul>
<li>val_accuracy: 0.7185</li>
<li>val_loss: 0.5657</li>
<li>val_precision: 0.7398</li>
<li>val_recall: 0.7222</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [177]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">ATRAIN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">OTRAIN</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">AVALID</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">OVALID</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span> <span class="p">)</span>
<span class="n">less_ang_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"less_ang_model"</span><span class="p">)</span>
<span class="n">less_ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,)))</span>
<span class="n">less_ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">less_ang_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">less_ang_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">less_ang_history</span> <span class="o">=</span> <span class="n">less_ang_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ATRAIN</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">AVALID</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">),</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">model_checkpoint</span><span class="p">,</span> <span class="n">early_stopping</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/100
 1/30 [&gt;.............................] - ETA: 20s - loss: 1.0477 - accuracy: 0.5625 - precision_1: 0.7843 - recall_1: 0.7895
Epoch 1: val_loss did not improve from 0.32645
30/30 [==============================] - 1s 11ms/step - loss: 0.8708 - accuracy: 0.5147 - precision_1: 0.5565 - recall_1: 0.9078 - val_loss: 0.7776 - val_accuracy: 0.5294 - val_precision_1: 0.5514 - val_recall_1: 0.8806
Epoch 2/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7868 - accuracy: 0.6250 - precision_1: 0.6000 - recall_1: 1.0000
Epoch 2: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.5168 - precision_1: 0.5211 - recall_1: 0.8727 - val_loss: 0.7087 - val_accuracy: 0.5588 - val_precision_1: 0.5775 - val_recall_1: 0.8060
Epoch 3/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.7735 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 0.8750
Epoch 3: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5830 - precision_1: 0.5694 - recall_1: 0.8121 - val_loss: 0.6628 - val_accuracy: 0.5966 - val_precision_1: 0.6173 - val_recall_1: 0.7463
Epoch 4/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6571 - accuracy: 0.5625 - precision_1: 0.5909 - recall_1: 0.7222
Epoch 4: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6439 - precision_1: 0.6296 - recall_1: 0.7657 - val_loss: 0.6331 - val_accuracy: 0.6597 - val_precision_1: 0.7023 - val_recall_1: 0.6866
Epoch 5/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6560 - accuracy: 0.6562 - precision_1: 0.5000 - recall_1: 0.8182
Epoch 5: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7164 - precision_1: 0.7264 - recall_1: 0.7293 - val_loss: 0.6147 - val_accuracy: 0.6891 - val_precision_1: 0.7419 - val_recall_1: 0.6866
Epoch 6/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5782 - accuracy: 0.7500 - precision_1: 0.7333 - recall_1: 0.7333
Epoch 6: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7300 - precision_1: 0.7399 - recall_1: 0.7414 - val_loss: 0.6030 - val_accuracy: 0.6807 - val_precision_1: 0.7339 - val_recall_1: 0.6791
Epoch 7/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6037 - accuracy: 0.6875 - precision_1: 0.8889 - recall_1: 0.6667
Epoch 7: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7321 - precision_1: 0.7429 - recall_1: 0.7414 - val_loss: 0.5962 - val_accuracy: 0.6891 - val_precision_1: 0.7500 - val_recall_1: 0.6716
Epoch 8/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4625 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 8: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7300 - precision_1: 0.7439 - recall_1: 0.7333 - val_loss: 0.5929 - val_accuracy: 0.6849 - val_precision_1: 0.7479 - val_recall_1: 0.6642
Epoch 9/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4593 - accuracy: 0.8125 - precision_1: 0.8125 - recall_1: 0.8125
Epoch 9: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7300 - precision_1: 0.7479 - recall_1: 0.7253 - val_loss: 0.5915 - val_accuracy: 0.6807 - val_precision_1: 0.7417 - val_recall_1: 0.6642
Epoch 10/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5849 - accuracy: 0.6875 - precision_1: 0.7368 - recall_1: 0.7368
Epoch 10: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7269 - precision_1: 0.7423 - recall_1: 0.7273 - val_loss: 0.5914 - val_accuracy: 0.6807 - val_precision_1: 0.7417 - val_recall_1: 0.6642
Epoch 11/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5688 - accuracy: 0.6562 - precision_1: 0.8235 - recall_1: 0.6364
Epoch 11: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7248 - precision_1: 0.7402 - recall_1: 0.7253 - val_loss: 0.5916 - val_accuracy: 0.6849 - val_precision_1: 0.7438 - val_recall_1: 0.6716
Epoch 12/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6221 - accuracy: 0.6875 - precision_1: 0.6875 - recall_1: 0.6875
Epoch 12: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7290 - precision_1: 0.7443 - recall_1: 0.7293 - val_loss: 0.5915 - val_accuracy: 0.6849 - val_precision_1: 0.7438 - val_recall_1: 0.6716
Epoch 13/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6676 - accuracy: 0.6250 - precision_1: 0.5000 - recall_1: 0.5000
Epoch 13: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7300 - precision_1: 0.7469 - recall_1: 0.7273 - val_loss: 0.5907 - val_accuracy: 0.6891 - val_precision_1: 0.7459 - val_recall_1: 0.6791
Epoch 14/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4878 - accuracy: 0.8125 - precision_1: 0.9333 - recall_1: 0.7368
Epoch 14: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7279 - precision_1: 0.7389 - recall_1: 0.7374 - val_loss: 0.5903 - val_accuracy: 0.6933 - val_precision_1: 0.7521 - val_recall_1: 0.6791
Epoch 15/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4110 - accuracy: 0.8750 - precision_1: 0.8125 - recall_1: 0.9286
Epoch 15: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7269 - precision_1: 0.7403 - recall_1: 0.7313 - val_loss: 0.5887 - val_accuracy: 0.6933 - val_precision_1: 0.7521 - val_recall_1: 0.6791
Epoch 16/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4831 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8000
Epoch 16: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7216 - precision_1: 0.7309 - recall_1: 0.7354 - val_loss: 0.5881 - val_accuracy: 0.6891 - val_precision_1: 0.7459 - val_recall_1: 0.6791
Epoch 17/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5365 - accuracy: 0.7188 - precision_1: 0.8333 - recall_1: 0.7143
Epoch 17: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7237 - precision_1: 0.7311 - recall_1: 0.7414 - val_loss: 0.5880 - val_accuracy: 0.6849 - val_precision_1: 0.7398 - val_recall_1: 0.6791
Epoch 18/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5314 - accuracy: 0.6875 - precision_1: 0.6000 - recall_1: 0.6923
Epoch 18: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7237 - precision_1: 0.7329 - recall_1: 0.7374 - val_loss: 0.5876 - val_accuracy: 0.6765 - val_precision_1: 0.7280 - val_recall_1: 0.6791
Epoch 19/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5655 - accuracy: 0.6875 - precision_1: 0.7222 - recall_1: 0.7222
Epoch 19: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7237 - precision_1: 0.7275 - recall_1: 0.7495 - val_loss: 0.5871 - val_accuracy: 0.6807 - val_precision_1: 0.7302 - val_recall_1: 0.6866
Epoch 20/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5520 - accuracy: 0.7188 - precision_1: 0.7895 - recall_1: 0.7500
Epoch 20: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7258 - precision_1: 0.7276 - recall_1: 0.7556 - val_loss: 0.5868 - val_accuracy: 0.6849 - val_precision_1: 0.7323 - val_recall_1: 0.6940
Epoch 21/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5827 - accuracy: 0.6562 - precision_1: 0.6875 - recall_1: 0.6471
Epoch 21: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7258 - precision_1: 0.7303 - recall_1: 0.7495 - val_loss: 0.5861 - val_accuracy: 0.6849 - val_precision_1: 0.7323 - val_recall_1: 0.6940
Epoch 22/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3913 - accuracy: 0.8750 - precision_1: 0.8750 - recall_1: 0.8750
Epoch 22: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7258 - precision_1: 0.7276 - recall_1: 0.7556 - val_loss: 0.5858 - val_accuracy: 0.6891 - val_precision_1: 0.7344 - val_recall_1: 0.7015
Epoch 23/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5637 - accuracy: 0.6875 - precision_1: 0.7143 - recall_1: 0.7895
Epoch 23: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7269 - precision_1: 0.7273 - recall_1: 0.7596 - val_loss: 0.5851 - val_accuracy: 0.6849 - val_precision_1: 0.7287 - val_recall_1: 0.7015
Epoch 24/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5647 - accuracy: 0.6875 - precision_1: 0.6923 - recall_1: 0.6000
Epoch 24: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7258 - precision_1: 0.7276 - recall_1: 0.7556 - val_loss: 0.5848 - val_accuracy: 0.6849 - val_precision_1: 0.7287 - val_recall_1: 0.7015
Epoch 25/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5015 - accuracy: 0.8125 - precision_1: 0.7647 - recall_1: 0.8667
Epoch 25: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7279 - precision_1: 0.7296 - recall_1: 0.7576 - val_loss: 0.5849 - val_accuracy: 0.6849 - val_precision_1: 0.7287 - val_recall_1: 0.7015
Epoch 26/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5556 - accuracy: 0.6562 - precision_1: 0.6471 - recall_1: 0.6875
Epoch 26: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7300 - precision_1: 0.7297 - recall_1: 0.7636 - val_loss: 0.5849 - val_accuracy: 0.6849 - val_precision_1: 0.7287 - val_recall_1: 0.7015
Epoch 27/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6165 - accuracy: 0.6875 - precision_1: 0.8667 - recall_1: 0.6190
Epoch 27: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7311 - precision_1: 0.7303 - recall_1: 0.7657 - val_loss: 0.5843 - val_accuracy: 0.6807 - val_precision_1: 0.7197 - val_recall_1: 0.7090
Epoch 28/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5159 - accuracy: 0.6875 - precision_1: 0.7059 - recall_1: 0.7059
Epoch 28: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7300 - precision_1: 0.7288 - recall_1: 0.7657 - val_loss: 0.5835 - val_accuracy: 0.6807 - val_precision_1: 0.7197 - val_recall_1: 0.7090
Epoch 29/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4798 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 29: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7290 - precision_1: 0.7292 - recall_1: 0.7616 - val_loss: 0.5837 - val_accuracy: 0.6849 - val_precision_1: 0.7218 - val_recall_1: 0.7164
Epoch 30/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3996 - accuracy: 0.9062 - precision_1: 1.0000 - recall_1: 0.8421
Epoch 30: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7321 - precision_1: 0.7281 - recall_1: 0.7737 - val_loss: 0.5834 - val_accuracy: 0.6807 - val_precision_1: 0.7197 - val_recall_1: 0.7090
Epoch 31/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.3790 - accuracy: 0.8750 - precision_1: 0.9444 - recall_1: 0.8500
Epoch 31: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7332 - precision_1: 0.7287 - recall_1: 0.7758 - val_loss: 0.5848 - val_accuracy: 0.6849 - val_precision_1: 0.7287 - val_recall_1: 0.7015
Epoch 32/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6036 - accuracy: 0.6250 - precision_1: 0.5882 - recall_1: 0.6667
Epoch 32: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7258 - precision_1: 0.7250 - recall_1: 0.7616 - val_loss: 0.5840 - val_accuracy: 0.6891 - val_precision_1: 0.7308 - val_recall_1: 0.7090
Epoch 33/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5999 - accuracy: 0.6875 - precision_1: 0.6957 - recall_1: 0.8421
Epoch 33: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7300 - precision_1: 0.7297 - recall_1: 0.7636 - val_loss: 0.5838 - val_accuracy: 0.6891 - val_precision_1: 0.7273 - val_recall_1: 0.7164
Epoch 34/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5589 - accuracy: 0.6875 - precision_1: 0.6471 - recall_1: 0.7333
Epoch 34: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7311 - precision_1: 0.7294 - recall_1: 0.7677 - val_loss: 0.5828 - val_accuracy: 0.6891 - val_precision_1: 0.7273 - val_recall_1: 0.7164
Epoch 35/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5044 - accuracy: 0.6875 - precision_1: 0.6667 - recall_1: 0.8889
Epoch 35: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7311 - precision_1: 0.7294 - recall_1: 0.7677 - val_loss: 0.5821 - val_accuracy: 0.6849 - val_precision_1: 0.7218 - val_recall_1: 0.7164
Epoch 36/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4739 - accuracy: 0.8125 - precision_1: 0.8750 - recall_1: 0.7778
Epoch 36: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7311 - precision_1: 0.7259 - recall_1: 0.7758 - val_loss: 0.5841 - val_accuracy: 0.6891 - val_precision_1: 0.7273 - val_recall_1: 0.7164
Epoch 37/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6491 - accuracy: 0.5625 - precision_1: 0.5455 - recall_1: 0.7500
Epoch 37: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7353 - precision_1: 0.7306 - recall_1: 0.7778 - val_loss: 0.5837 - val_accuracy: 0.6891 - val_precision_1: 0.7273 - val_recall_1: 0.7164
Epoch 38/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5844 - accuracy: 0.6562 - precision_1: 0.6667 - recall_1: 0.7059
Epoch 38: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7300 - precision_1: 0.7280 - recall_1: 0.7677 - val_loss: 0.5828 - val_accuracy: 0.6891 - val_precision_1: 0.7273 - val_recall_1: 0.7164
Epoch 39/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5510 - accuracy: 0.7188 - precision_1: 0.6316 - recall_1: 0.8571
Epoch 39: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7363 - precision_1: 0.7311 - recall_1: 0.7798 - val_loss: 0.5826 - val_accuracy: 0.6891 - val_precision_1: 0.7273 - val_recall_1: 0.7164
Epoch 40/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4358 - accuracy: 0.8125 - precision_1: 0.7619 - recall_1: 0.9412
Epoch 40: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7363 - precision_1: 0.7285 - recall_1: 0.7859 - val_loss: 0.5833 - val_accuracy: 0.6891 - val_precision_1: 0.7308 - val_recall_1: 0.7090
Epoch 41/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6069 - accuracy: 0.6562 - precision_1: 0.5294 - recall_1: 0.7500
Epoch 41: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7321 - precision_1: 0.7264 - recall_1: 0.7778 - val_loss: 0.5830 - val_accuracy: 0.6891 - val_precision_1: 0.7308 - val_recall_1: 0.7090
Epoch 42/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5720 - accuracy: 0.7500 - precision_1: 0.7647 - recall_1: 0.7647
Epoch 42: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7374 - precision_1: 0.7324 - recall_1: 0.7798 - val_loss: 0.5838 - val_accuracy: 0.6891 - val_precision_1: 0.7273 - val_recall_1: 0.7164
Epoch 43/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5337 - accuracy: 0.6875 - precision_1: 0.6842 - recall_1: 0.7647
Epoch 43: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7342 - precision_1: 0.7274 - recall_1: 0.7818 - val_loss: 0.5821 - val_accuracy: 0.6933 - val_precision_1: 0.7364 - val_recall_1: 0.7090
Epoch 44/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4107 - accuracy: 0.8125 - precision_1: 0.8000 - recall_1: 0.8000
Epoch 44: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7384 - precision_1: 0.7321 - recall_1: 0.7838 - val_loss: 0.5816 - val_accuracy: 0.6933 - val_precision_1: 0.7364 - val_recall_1: 0.7090
Epoch 45/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5314 - accuracy: 0.7188 - precision_1: 0.6316 - recall_1: 0.8571
Epoch 45: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7342 - precision_1: 0.7292 - recall_1: 0.7778 - val_loss: 0.5828 - val_accuracy: 0.6933 - val_precision_1: 0.7364 - val_recall_1: 0.7090
Epoch 46/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6986 - accuracy: 0.5938 - precision_1: 0.5294 - recall_1: 0.6429
Epoch 46: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7353 - precision_1: 0.7314 - recall_1: 0.7758 - val_loss: 0.5823 - val_accuracy: 0.6975 - val_precision_1: 0.7348 - val_recall_1: 0.7239
Epoch 47/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4337 - accuracy: 0.7812 - precision_1: 0.7059 - recall_1: 0.8571
Epoch 47: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7332 - precision_1: 0.7278 - recall_1: 0.7778 - val_loss: 0.5832 - val_accuracy: 0.7017 - val_precision_1: 0.7405 - val_recall_1: 0.7239
Epoch 48/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6749 - accuracy: 0.6875 - precision_1: 0.7000 - recall_1: 0.7778
Epoch 48: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7311 - precision_1: 0.7250 - recall_1: 0.7778 - val_loss: 0.5827 - val_accuracy: 0.7017 - val_precision_1: 0.7405 - val_recall_1: 0.7239
Epoch 49/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4664 - accuracy: 0.7812 - precision_1: 0.8333 - recall_1: 0.7895
Epoch 49: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7353 - precision_1: 0.7280 - recall_1: 0.7838 - val_loss: 0.5826 - val_accuracy: 0.6975 - val_precision_1: 0.7385 - val_recall_1: 0.7164
Epoch 50/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4892 - accuracy: 0.8125 - precision_1: 0.8571 - recall_1: 0.8571
Epoch 50: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7353 - precision_1: 0.7280 - recall_1: 0.7838 - val_loss: 0.5844 - val_accuracy: 0.6975 - val_precision_1: 0.7385 - val_recall_1: 0.7164
Epoch 51/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5626 - accuracy: 0.6562 - precision_1: 0.6000 - recall_1: 0.6429
Epoch 51: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7342 - precision_1: 0.7292 - recall_1: 0.7778 - val_loss: 0.5831 - val_accuracy: 0.7017 - val_precision_1: 0.7405 - val_recall_1: 0.7239
Epoch 52/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5738 - accuracy: 0.7812 - precision_1: 0.7500 - recall_1: 0.8824
Epoch 52: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7363 - precision_1: 0.7285 - recall_1: 0.7859 - val_loss: 0.5830 - val_accuracy: 0.7017 - val_precision_1: 0.7405 - val_recall_1: 0.7239
Epoch 53/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4345 - accuracy: 0.9375 - precision_1: 0.9091 - recall_1: 1.0000
Epoch 53: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7353 - precision_1: 0.7288 - recall_1: 0.7818 - val_loss: 0.5818 - val_accuracy: 0.7017 - val_precision_1: 0.7405 - val_recall_1: 0.7239
Epoch 54/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5312 - accuracy: 0.7812 - precision_1: 0.8095 - recall_1: 0.8500
Epoch 54: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7374 - precision_1: 0.7298 - recall_1: 0.7859 - val_loss: 0.5824 - val_accuracy: 0.7017 - val_precision_1: 0.7405 - val_recall_1: 0.7239
Epoch 55/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4712 - accuracy: 0.6875 - precision_1: 0.6471 - recall_1: 0.7333
Epoch 55: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7374 - precision_1: 0.7342 - recall_1: 0.7758 - val_loss: 0.5826 - val_accuracy: 0.6975 - val_precision_1: 0.7348 - val_recall_1: 0.7239
Epoch 56/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.5657 - accuracy: 0.6562 - precision_1: 0.7500 - recall_1: 0.6316
Epoch 56: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7342 - precision_1: 0.7283 - recall_1: 0.7798 - val_loss: 0.5832 - val_accuracy: 0.6975 - val_precision_1: 0.7348 - val_recall_1: 0.7239
Epoch 57/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4801 - accuracy: 0.7188 - precision_1: 0.6500 - recall_1: 0.8667
Epoch 57: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7374 - precision_1: 0.7307 - recall_1: 0.7838 - val_loss: 0.5828 - val_accuracy: 0.6975 - val_precision_1: 0.7348 - val_recall_1: 0.7239
Epoch 58/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.4866 - accuracy: 0.8125 - precision_1: 0.7500 - recall_1: 1.0000
Epoch 58: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7342 - precision_1: 0.7292 - recall_1: 0.7778 - val_loss: 0.5828 - val_accuracy: 0.6975 - val_precision_1: 0.7348 - val_recall_1: 0.7239
Epoch 59/100
 1/30 [&gt;.............................] - ETA: 0s - loss: 0.6497 - accuracy: 0.7188 - precision_1: 0.5556 - recall_1: 0.9091
Epoch 59: val_loss did not improve from 0.32645
30/30 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7374 - precision_1: 0.7298 - recall_1: 0.7859 - val_loss: 0.5848 - val_accuracy: 0.7017 - val_precision_1: 0.7405 - val_recall_1: 0.7239
Epoch 59: early stopping
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [187]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">less_rest</span> <span class="o">=</span> <span class="n">less_resting_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">less_ch</span> <span class="o">=</span> <span class="n">less_ch_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">less_fast</span> <span class="o">=</span> <span class="n">less_fasting_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">less_ecg</span> <span class="o">=</span> <span class="n">less_ecg_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">less_slop</span> <span class="o">=</span> <span class="n">less_slope_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">less_ang</span> <span class="o">=</span> <span class="n">less_ang_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">less_chest</span> <span class="o">=</span> <span class="n">less_chest_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">less_old</span> <span class="o">=</span> <span class="n">less_old_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">all</span> <span class="o">=</span> <span class="n">all_eights_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">plot_feature_reduction</span><span class="p">():</span>
  <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'All features'</span><span class="p">,</span> <span class="s1">'removing resting bp'</span><span class="p">,</span> <span class="s1">'removing cholesterol'</span><span class="p">,</span> <span class="s1">'removing fasting bs'</span><span class="p">,</span> <span class="s1">'removing ecg'</span><span class="p">,</span> <span class="s1">'removing chest pain'</span><span class="p">,</span> <span class="s1">'removing slope'</span><span class="p">,</span> <span class="s1">'removing old peak'</span><span class="p">,</span> <span class="s1">'remove ang'</span><span class="p">]</span>
  <span class="n">vals</span> <span class="o">=</span> <span class="p">[</span><span class="nb">all</span><span class="p">,</span> <span class="n">less_rest</span><span class="p">,</span> <span class="n">less_ch</span><span class="p">,</span> <span class="n">less_fast</span><span class="p">,</span> <span class="n">less_ecg</span><span class="p">,</span> <span class="n">less_chest</span><span class="p">,</span> <span class="n">less_slop</span><span class="p">,</span> <span class="n">less_old</span><span class="p">,</span> <span class="n">less_ang</span><span class="p">]</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="n">vals</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Features'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Performance when removing features'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_feature_reduction</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="overfit-by-passing-output-in">overfit by passing output in<a class="anchor-link" href="#overfit-by-passing-output-in">¶</a></h1>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [179]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Do not remove last column here</span>
<span class="n">XVALIDOUTPUT</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[:</span><span class="n">index_20percent</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">YVALID</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[:</span><span class="n">index_20percent</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">XTRAINOUTPUT</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[</span><span class="n">index_20percent</span><span class="p">:,</span> <span class="p">:]</span>
<span class="n">YTRAIN</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[</span><span class="n">index_20percent</span><span class="p">:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [180]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">XVALIDOUTPUT</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[180]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(238, 12)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [181]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">output_in_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"output_in"</span><span class="p">)</span>
<span class="n">output_in_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">XVALIDOUTPUT</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">output_in_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
<span class="n">output_in_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">output_in_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">output_in_history</span> <span class="o">=</span> <span class="n">output_in_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAINOUTPUT</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALIDOUTPUT</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
30/30 [==============================] - 1s 10ms/step - loss: 0.5842 - accuracy: 0.6964 - precision_1: 0.6865 - recall_1: 0.7870 - val_loss: 0.5805 - val_accuracy: 0.6975 - val_precision_1: 0.7719 - val_recall_1: 0.6567
Epoch 2/256
30/30 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7511 - precision_1: 0.7792 - recall_1: 0.7273 - val_loss: 0.5598 - val_accuracy: 0.7059 - val_precision_1: 0.7807 - val_recall_1: 0.6642
Epoch 3/256
30/30 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7710 - precision_1: 0.8017 - recall_1: 0.7434 - val_loss: 0.5396 - val_accuracy: 0.7185 - val_precision_1: 0.7863 - val_recall_1: 0.6866
Epoch 4/256
30/30 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7899 - precision_1: 0.8158 - recall_1: 0.7697 - val_loss: 0.5189 - val_accuracy: 0.7605 - val_precision_1: 0.8182 - val_recall_1: 0.7388
Epoch 5/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7983 - precision_1: 0.8217 - recall_1: 0.7818 - val_loss: 0.4979 - val_accuracy: 0.7773 - val_precision_1: 0.8293 - val_recall_1: 0.7612
Epoch 6/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8120 - precision_1: 0.8347 - recall_1: 0.7960 - val_loss: 0.4781 - val_accuracy: 0.7899 - val_precision_1: 0.8443 - val_recall_1: 0.7687
Epoch 7/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8277 - precision_1: 0.8575 - recall_1: 0.8020 - val_loss: 0.4593 - val_accuracy: 0.7941 - val_precision_1: 0.8512 - val_recall_1: 0.7687
Epoch 8/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8277 - precision_1: 0.8559 - recall_1: 0.8040 - val_loss: 0.4411 - val_accuracy: 0.8025 - val_precision_1: 0.8595 - val_recall_1: 0.7761
Epoch 9/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8414 - precision_1: 0.8629 - recall_1: 0.8263 - val_loss: 0.4227 - val_accuracy: 0.8151 - val_precision_1: 0.8689 - val_recall_1: 0.7910
Epoch 10/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8477 - precision_1: 0.8676 - recall_1: 0.8343 - val_loss: 0.4060 - val_accuracy: 0.8235 - val_precision_1: 0.8710 - val_recall_1: 0.8060
Epoch 11/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8571 - precision_1: 0.8779 - recall_1: 0.8424 - val_loss: 0.3898 - val_accuracy: 0.8361 - val_precision_1: 0.8800 - val_recall_1: 0.8209
Epoch 12/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8634 - precision_1: 0.8842 - recall_1: 0.8485 - val_loss: 0.3755 - val_accuracy: 0.8487 - val_precision_1: 0.9016 - val_recall_1: 0.8209
Epoch 13/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8687 - precision_1: 0.8854 - recall_1: 0.8586 - val_loss: 0.3611 - val_accuracy: 0.8697 - val_precision_1: 0.9120 - val_recall_1: 0.8507
Epoch 14/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8750 - precision_1: 0.8884 - recall_1: 0.8687 - val_loss: 0.3472 - val_accuracy: 0.8697 - val_precision_1: 0.9055 - val_recall_1: 0.8582
Epoch 15/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8782 - precision_1: 0.8891 - recall_1: 0.8747 - val_loss: 0.3334 - val_accuracy: 0.8697 - val_precision_1: 0.8992 - val_recall_1: 0.8657
Epoch 16/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8845 - precision_1: 0.8937 - recall_1: 0.8828 - val_loss: 0.3200 - val_accuracy: 0.8697 - val_precision_1: 0.8992 - val_recall_1: 0.8657
Epoch 17/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8876 - precision_1: 0.8959 - recall_1: 0.8869 - val_loss: 0.3069 - val_accuracy: 0.8782 - val_precision_1: 0.9008 - val_recall_1: 0.8806
Epoch 18/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8897 - precision_1: 0.8980 - recall_1: 0.8889 - val_loss: 0.2945 - val_accuracy: 0.8824 - val_precision_1: 0.9015 - val_recall_1: 0.8881
Epoch 19/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.8981 - precision_1: 0.9028 - recall_1: 0.9010 - val_loss: 0.2828 - val_accuracy: 0.8824 - val_precision_1: 0.9015 - val_recall_1: 0.8881
Epoch 20/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.9034 - precision_1: 0.9054 - recall_1: 0.9091 - val_loss: 0.2705 - val_accuracy: 0.8824 - val_precision_1: 0.9015 - val_recall_1: 0.8881
Epoch 21/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.9086 - precision_1: 0.9064 - recall_1: 0.9192 - val_loss: 0.2586 - val_accuracy: 0.8950 - val_precision_1: 0.9160 - val_recall_1: 0.8955
Epoch 22/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.9118 - precision_1: 0.9053 - recall_1: 0.9273 - val_loss: 0.2476 - val_accuracy: 0.9118 - val_precision_1: 0.9248 - val_recall_1: 0.9179
Epoch 23/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.9139 - precision_1: 0.9057 - recall_1: 0.9313 - val_loss: 0.2370 - val_accuracy: 0.9202 - val_precision_1: 0.9259 - val_recall_1: 0.9328
Epoch 24/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9212 - precision_1: 0.9054 - recall_1: 0.9475 - val_loss: 0.2267 - val_accuracy: 0.9244 - val_precision_1: 0.9265 - val_recall_1: 0.9403
Epoch 25/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9223 - precision_1: 0.9056 - recall_1: 0.9495 - val_loss: 0.2165 - val_accuracy: 0.9286 - val_precision_1: 0.9270 - val_recall_1: 0.9478
Epoch 26/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2194 - accuracy: 0.9233 - precision_1: 0.9058 - recall_1: 0.9515 - val_loss: 0.2069 - val_accuracy: 0.9328 - val_precision_1: 0.9275 - val_recall_1: 0.9552
Epoch 27/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9254 - precision_1: 0.9077 - recall_1: 0.9535 - val_loss: 0.1979 - val_accuracy: 0.9370 - val_precision_1: 0.9343 - val_recall_1: 0.9552
Epoch 28/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9307 - precision_1: 0.9101 - recall_1: 0.9616 - val_loss: 0.1889 - val_accuracy: 0.9454 - val_precision_1: 0.9353 - val_recall_1: 0.9701
Epoch 29/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9328 - precision_1: 0.9120 - recall_1: 0.9636 - val_loss: 0.1803 - val_accuracy: 0.9496 - val_precision_1: 0.9420 - val_recall_1: 0.9701
Epoch 30/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1868 - accuracy: 0.9370 - precision_1: 0.9159 - recall_1: 0.9677 - val_loss: 0.1726 - val_accuracy: 0.9580 - val_precision_1: 0.9429 - val_recall_1: 0.9851
Epoch 31/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9422 - precision_1: 0.9231 - recall_1: 0.9697 - val_loss: 0.1649 - val_accuracy: 0.9622 - val_precision_1: 0.9496 - val_recall_1: 0.9851
Epoch 32/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9454 - precision_1: 0.9251 - recall_1: 0.9737 - val_loss: 0.1573 - val_accuracy: 0.9622 - val_precision_1: 0.9496 - val_recall_1: 0.9851
Epoch 33/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9485 - precision_1: 0.9272 - recall_1: 0.9778 - val_loss: 0.1497 - val_accuracy: 0.9706 - val_precision_1: 0.9568 - val_recall_1: 0.9925
Epoch 34/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9517 - precision_1: 0.9293 - recall_1: 0.9818 - val_loss: 0.1422 - val_accuracy: 0.9748 - val_precision_1: 0.9638 - val_recall_1: 0.9925
Epoch 35/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9569 - precision_1: 0.9332 - recall_1: 0.9879 - val_loss: 0.1354 - val_accuracy: 0.9790 - val_precision_1: 0.9640 - val_recall_1: 1.0000
Epoch 36/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9580 - precision_1: 0.9350 - recall_1: 0.9879 - val_loss: 0.1290 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 37/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9590 - precision_1: 0.9351 - recall_1: 0.9899 - val_loss: 0.1227 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 38/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9590 - precision_1: 0.9351 - recall_1: 0.9899 - val_loss: 0.1166 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 39/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9622 - precision_1: 0.9371 - recall_1: 0.9939 - val_loss: 0.1107 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 40/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9664 - precision_1: 0.9443 - recall_1: 0.9939 - val_loss: 0.1049 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 41/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9695 - precision_1: 0.9498 - recall_1: 0.9939 - val_loss: 0.0993 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 42/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9748 - precision_1: 0.9591 - recall_1: 0.9939 - val_loss: 0.0939 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 43/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0978 - accuracy: 0.9800 - precision_1: 0.9630 - recall_1: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 44/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9811 - precision_1: 0.9649 - recall_1: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 45/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9811 - precision_1: 0.9649 - recall_1: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9874 - val_precision_1: 0.9781 - val_recall_1: 1.0000
Epoch 46/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9863 - precision_1: 0.9744 - recall_1: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 47/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9884 - precision_1: 0.9783 - recall_1: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 48/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9905 - precision_1: 0.9821 - recall_1: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 49/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9926 - precision_1: 0.9861 - recall_1: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 50/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 51/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 52/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 53/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9947 - precision_1: 0.9900 - recall_1: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 54/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9947 - precision_1: 0.9900 - recall_1: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 55/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9979 - precision_1: 0.9960 - recall_1: 1.0000 - val_loss: 0.0362 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 56/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 57/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 58/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 59/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 60/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0222 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 61/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0199 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 62/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 63/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 64/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 65/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 66/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 67/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 68/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 69/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 70/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 71/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 72/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 73/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 74/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 75/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 76/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 77/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 78/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 79/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 80/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 81/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 82/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 83/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 84/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 85/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.6908e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 86/256
30/30 [==============================] - 0s 3ms/step - loss: 9.2030e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.5416e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 87/256
30/30 [==============================] - 0s 3ms/step - loss: 7.9647e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.5470e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 88/256
30/30 [==============================] - 0s 3ms/step - loss: 6.8751e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 5.6832e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 89/256
30/30 [==============================] - 0s 3ms/step - loss: 5.9650e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.9532e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 90/256
30/30 [==============================] - 0s 3ms/step - loss: 5.1979e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.3043e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 91/256
30/30 [==============================] - 0s 3ms/step - loss: 4.5257e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.7521e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 92/256
30/30 [==============================] - 0s 3ms/step - loss: 3.9586e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.2892e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 93/256
30/30 [==============================] - 0s 3ms/step - loss: 3.4690e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.8955e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 94/256
30/30 [==============================] - 0s 3ms/step - loss: 3.0576e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.5578e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 95/256
30/30 [==============================] - 0s 3ms/step - loss: 2.7063e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.2740e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 96/256
30/30 [==============================] - 0s 3ms/step - loss: 2.4067e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.0300e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 97/256
30/30 [==============================] - 0s 5ms/step - loss: 2.1521e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.8206e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 98/256
30/30 [==============================] - 0s 3ms/step - loss: 1.9325e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.6450e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 99/256
30/30 [==============================] - 0s 3ms/step - loss: 1.7469e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.4932e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 100/256
30/30 [==============================] - 0s 3ms/step - loss: 1.5856e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.3616e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 101/256
30/30 [==============================] - 0s 3ms/step - loss: 1.4476e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2479e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 102/256
30/30 [==============================] - 0s 3ms/step - loss: 1.3282e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1493e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 103/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2239e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0637e-04 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 104/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1335e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.8903e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 105/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0546e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.2263e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 106/256
30/30 [==============================] - 0s 3ms/step - loss: 9.8493e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.6387e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 107/256
30/30 [==============================] - 0s 3ms/step - loss: 9.2263e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.1164e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 108/256
30/30 [==============================] - 0s 3ms/step - loss: 8.6713e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.6472e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 109/256
30/30 [==============================] - 0s 3ms/step - loss: 8.1797e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.2267e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 110/256
30/30 [==============================] - 0s 3ms/step - loss: 7.7343e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.8472e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 111/256
30/30 [==============================] - 0s 3ms/step - loss: 7.3294e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.5027e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 112/256
30/30 [==============================] - 0s 3ms/step - loss: 6.9647e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.1884e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 113/256
30/30 [==============================] - 0s 3ms/step - loss: 6.6289e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 5.9015e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 114/256
30/30 [==============================] - 0s 3ms/step - loss: 6.3226e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 5.6396e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 115/256
30/30 [==============================] - 0s 3ms/step - loss: 6.0447e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 5.3983e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 116/256
30/30 [==============================] - 0s 3ms/step - loss: 5.7855e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 5.1754e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 117/256
30/30 [==============================] - 0s 3ms/step - loss: 5.5478e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.9692e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 118/256
30/30 [==============================] - 0s 3ms/step - loss: 5.3287e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.7779e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 119/256
30/30 [==============================] - 0s 3ms/step - loss: 5.1254e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.6000e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 120/256
30/30 [==============================] - 0s 3ms/step - loss: 4.9359e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.4344e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 121/256
30/30 [==============================] - 0s 3ms/step - loss: 4.7592e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.2798e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 122/256
30/30 [==============================] - 0s 3ms/step - loss: 4.5929e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 4.1355e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 123/256
30/30 [==============================] - 0s 3ms/step - loss: 4.4391e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.9993e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 124/256
30/30 [==============================] - 0s 3ms/step - loss: 4.2937e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.8718e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 125/256
30/30 [==============================] - 0s 3ms/step - loss: 4.1581e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.7517e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 126/256
30/30 [==============================] - 0s 3ms/step - loss: 4.0296e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.6386e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 127/256
30/30 [==============================] - 0s 3ms/step - loss: 3.9084e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.5317e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 128/256
30/30 [==============================] - 0s 3ms/step - loss: 3.7934e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.4307e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 129/256
30/30 [==============================] - 0s 3ms/step - loss: 3.6851e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.3348e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 130/256
30/30 [==============================] - 0s 3ms/step - loss: 3.5828e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.2439e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 131/256
30/30 [==============================] - 0s 3ms/step - loss: 3.4857e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.1576e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 132/256
30/30 [==============================] - 0s 3ms/step - loss: 3.3937e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 3.0758e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 133/256
30/30 [==============================] - 0s 3ms/step - loss: 3.3050e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.9978e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 134/256
30/30 [==============================] - 0s 3ms/step - loss: 3.2214e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.9234e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 135/256
30/30 [==============================] - 0s 3ms/step - loss: 3.1419e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.8524e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 136/256
30/30 [==============================] - 0s 3ms/step - loss: 3.0659e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.7846e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 137/256
30/30 [==============================] - 0s 3ms/step - loss: 2.9937e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.7198e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 138/256
30/30 [==============================] - 0s 3ms/step - loss: 2.9241e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.6577e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 139/256
30/30 [==============================] - 0s 3ms/step - loss: 2.8581e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.5984e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 140/256
30/30 [==============================] - 0s 3ms/step - loss: 2.7944e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.5415e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 141/256
30/30 [==============================] - 0s 3ms/step - loss: 2.7340e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.4869e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 142/256
30/30 [==============================] - 0s 3ms/step - loss: 2.6753e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.4346e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 143/256
30/30 [==============================] - 0s 3ms/step - loss: 2.6193e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.3842e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 144/256
30/30 [==============================] - 0s 3ms/step - loss: 2.5654e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.3358e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 145/256
30/30 [==============================] - 0s 3ms/step - loss: 2.5134e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.2893e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 146/256
30/30 [==============================] - 0s 3ms/step - loss: 2.4636e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.2444e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 147/256
30/30 [==============================] - 0s 3ms/step - loss: 2.4156e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.2013e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 148/256
30/30 [==============================] - 0s 3ms/step - loss: 2.3695e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.1596e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 149/256
30/30 [==============================] - 0s 3ms/step - loss: 2.3247e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.1195e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 150/256
30/30 [==============================] - 0s 3ms/step - loss: 2.2817e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.0808e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 151/256
30/30 [==============================] - 0s 3ms/step - loss: 2.2404e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.0434e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 152/256
30/30 [==============================] - 0s 3ms/step - loss: 2.2004e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 2.0072e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 153/256
30/30 [==============================] - 0s 3ms/step - loss: 2.1615e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.9722e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 154/256
30/30 [==============================] - 0s 3ms/step - loss: 2.1243e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.9384e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 155/256
30/30 [==============================] - 0s 3ms/step - loss: 2.0881e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.9057e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 156/256
30/30 [==============================] - 0s 3ms/step - loss: 2.0530e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.8740e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 157/256
30/30 [==============================] - 0s 3ms/step - loss: 2.0188e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.8432e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 158/256
30/30 [==============================] - 0s 3ms/step - loss: 1.9860e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.8134e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 159/256
30/30 [==============================] - 0s 3ms/step - loss: 1.9541e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.7845e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 160/256
30/30 [==============================] - 0s 3ms/step - loss: 1.9233e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.7564e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 161/256
30/30 [==============================] - 0s 3ms/step - loss: 1.8933e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.7293e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 162/256
30/30 [==============================] - 0s 3ms/step - loss: 1.8642e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.7030e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 163/256
30/30 [==============================] - 0s 3ms/step - loss: 1.8359e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.6773e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 164/256
30/30 [==============================] - 0s 3ms/step - loss: 1.8085e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.6525e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 165/256
30/30 [==============================] - 0s 3ms/step - loss: 1.7816e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.6283e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 166/256
30/30 [==============================] - 0s 3ms/step - loss: 1.7559e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.6048e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 167/256
30/30 [==============================] - 0s 3ms/step - loss: 1.7306e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.5819e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 168/256
30/30 [==============================] - 0s 3ms/step - loss: 1.7061e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.5596e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 169/256
30/30 [==============================] - 0s 3ms/step - loss: 1.6822e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.5380e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 170/256
30/30 [==============================] - 0s 3ms/step - loss: 1.6590e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.5169e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 171/256
30/30 [==============================] - 0s 3ms/step - loss: 1.6362e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.4963e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 172/256
30/30 [==============================] - 0s 3ms/step - loss: 1.6142e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.4763e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 173/256
30/30 [==============================] - 0s 3ms/step - loss: 1.5927e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.4568e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 174/256
30/30 [==============================] - 0s 3ms/step - loss: 1.5717e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.4377e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 175/256
30/30 [==============================] - 0s 3ms/step - loss: 1.5514e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.4192e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 176/256
30/30 [==============================] - 0s 3ms/step - loss: 1.5314e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.4011e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 177/256
30/30 [==============================] - 0s 3ms/step - loss: 1.5121e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.3834e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 178/256
30/30 [==============================] - 0s 3ms/step - loss: 1.4931e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.3662e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 179/256
30/30 [==============================] - 0s 3ms/step - loss: 1.4747e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.3493e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 180/256
30/30 [==============================] - 0s 3ms/step - loss: 1.4564e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.3329e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 181/256
30/30 [==============================] - 0s 3ms/step - loss: 1.4389e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.3169e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 182/256
30/30 [==============================] - 0s 3ms/step - loss: 1.4214e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.3012e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 183/256
30/30 [==============================] - 0s 3ms/step - loss: 1.4046e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2858e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 184/256
30/30 [==============================] - 0s 3ms/step - loss: 1.3881e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2708e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 185/256
30/30 [==============================] - 0s 3ms/step - loss: 1.3720e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2562e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 186/256
30/30 [==============================] - 0s 3ms/step - loss: 1.3563e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2418e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 187/256
30/30 [==============================] - 0s 3ms/step - loss: 1.3409e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2278e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 188/256
30/30 [==============================] - 0s 3ms/step - loss: 1.3258e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2140e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 189/256
30/30 [==============================] - 0s 3ms/step - loss: 1.3110e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.2006e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 190/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2965e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1874e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 191/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2822e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1746e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 192/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2685e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1620e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 193/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2549e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1496e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 194/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2416e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1375e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 195/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2286e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1256e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 196/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2158e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1139e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 197/256
30/30 [==============================] - 0s 3ms/step - loss: 1.2033e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.1025e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 198/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1910e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0913e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 199/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1790e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0804e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 200/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1672e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0696e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 201/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1555e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0591e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 202/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1441e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0487e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 203/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1330e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0385e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 204/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1220e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0285e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 205/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1112e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0188e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 206/256
30/30 [==============================] - 0s 3ms/step - loss: 1.1007e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 1.0091e-05 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 207/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0903e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.9968e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 208/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0801e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.9042e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 209/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0701e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.8129e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 210/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0603e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.7236e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 211/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0507e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.6356e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 212/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0412e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.5491e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 213/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0319e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.4642e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 214/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0227e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.3806e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 215/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0137e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.2985e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 216/256
30/30 [==============================] - 0s 3ms/step - loss: 1.0048e-05 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.2178e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 217/256
30/30 [==============================] - 0s 3ms/step - loss: 9.9606e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.1383e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 218/256
30/30 [==============================] - 0s 3ms/step - loss: 9.8746e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 9.0603e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 219/256
30/30 [==============================] - 0s 3ms/step - loss: 9.7901e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.9835e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 220/256
30/30 [==============================] - 0s 3ms/step - loss: 9.7069e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.9079e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 221/256
30/30 [==============================] - 0s 3ms/step - loss: 9.6261e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.8334e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 222/256
30/30 [==============================] - 0s 3ms/step - loss: 9.5453e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.7602e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 223/256
30/30 [==============================] - 0s 3ms/step - loss: 9.4664e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.6881e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 224/256
30/30 [==============================] - 0s 3ms/step - loss: 9.3885e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.6171e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 225/256
30/30 [==============================] - 0s 3ms/step - loss: 9.3122e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.5472e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 226/256
30/30 [==============================] - 0s 3ms/step - loss: 9.2371e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.4783e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 227/256
30/30 [==============================] - 0s 3ms/step - loss: 9.1628e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.4106e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 228/256
30/30 [==============================] - 0s 3ms/step - loss: 9.0893e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.3439e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 229/256
30/30 [==============================] - 0s 3ms/step - loss: 9.0173e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.2783e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 230/256
30/30 [==============================] - 0s 3ms/step - loss: 8.9463e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.2137e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 231/256
30/30 [==============================] - 0s 3ms/step - loss: 8.8766e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.1501e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 232/256
30/30 [==============================] - 0s 3ms/step - loss: 8.8074e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.0874e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 233/256
30/30 [==============================] - 0s 3ms/step - loss: 8.7406e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 8.0255e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 234/256
30/30 [==============================] - 0s 3ms/step - loss: 8.6723e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.9644e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 235/256
30/30 [==============================] - 0s 3ms/step - loss: 8.6069e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.9042e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 236/256
30/30 [==============================] - 0s 3ms/step - loss: 8.5417e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.8449e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 237/256
30/30 [==============================] - 0s 3ms/step - loss: 8.4780e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.7866e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 238/256
30/30 [==============================] - 0s 3ms/step - loss: 8.4146e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.7290e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 239/256
30/30 [==============================] - 0s 3ms/step - loss: 8.3527e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.6721e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 240/256
30/30 [==============================] - 0s 3ms/step - loss: 8.2916e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.6160e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 241/256
30/30 [==============================] - 0s 3ms/step - loss: 8.2313e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.5608e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 242/256
30/30 [==============================] - 0s 3ms/step - loss: 8.1715e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.5062e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 243/256
30/30 [==============================] - 0s 3ms/step - loss: 8.1126e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.4526e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 244/256
30/30 [==============================] - 0s 3ms/step - loss: 8.0546e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.3998e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 245/256
30/30 [==============================] - 0s 3ms/step - loss: 7.9974e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.3475e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 246/256
30/30 [==============================] - 0s 3ms/step - loss: 7.9416e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.2960e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 247/256
30/30 [==============================] - 0s 3ms/step - loss: 7.8857e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.2451e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 248/256
30/30 [==============================] - 0s 3ms/step - loss: 7.8310e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.1950e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 249/256
30/30 [==============================] - 0s 3ms/step - loss: 7.7766e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.1455e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 250/256
30/30 [==============================] - 0s 3ms/step - loss: 7.7229e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.0967e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 251/256
30/30 [==============================] - 0s 3ms/step - loss: 7.6699e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.0485e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 252/256
30/30 [==============================] - 0s 3ms/step - loss: 7.6176e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 7.0008e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 253/256
30/30 [==============================] - 0s 3ms/step - loss: 7.5665e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.9538e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 254/256
30/30 [==============================] - 0s 3ms/step - loss: 7.5155e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.9074e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 255/256
30/30 [==============================] - 0s 3ms/step - loss: 7.4656e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.8616e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 256/256
30/30 [==============================] - 0s 3ms/step - loss: 7.4163e-06 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 6.8164e-06 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [182]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">one_output_in_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"one_output"</span><span class="p">)</span>
<span class="n">one_output_in_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">XVALIDOUTPUT</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)))</span>
<span class="n">one_output_in_model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>
<span class="c1"># compile the model</span>
<span class="n">one_output_in_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">])</span>

<span class="c1"># fit the model</span>
<span class="n">one_output_in_history</span> <span class="o">=</span> <span class="n">one_output_in_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XTRAINOUTPUT</span><span class="p">,</span> <span class="n">YTRAIN</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">XVALIDOUTPUT</span><span class="p">,</span> <span class="n">YVALID</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Epoch 1/256
30/30 [==============================] - 2s 11ms/step - loss: 0.5597 - accuracy: 0.7153 - precision_1: 0.7648 - recall_1: 0.8219 - val_loss: 0.5623 - val_accuracy: 0.7227 - val_precision_1: 0.7537 - val_recall_1: 0.7537
Epoch 2/256
30/30 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7405 - precision_1: 0.7271 - recall_1: 0.8020 - val_loss: 0.5335 - val_accuracy: 0.7395 - val_precision_1: 0.7687 - val_recall_1: 0.7687
Epoch 3/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7637 - precision_1: 0.7519 - recall_1: 0.8141 - val_loss: 0.5093 - val_accuracy: 0.7521 - val_precision_1: 0.7778 - val_recall_1: 0.7836
Epoch 4/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7847 - precision_1: 0.7715 - recall_1: 0.8323 - val_loss: 0.4867 - val_accuracy: 0.7731 - val_precision_1: 0.8077 - val_recall_1: 0.7836
Epoch 5/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.8036 - precision_1: 0.7906 - recall_1: 0.8465 - val_loss: 0.4665 - val_accuracy: 0.7899 - val_precision_1: 0.8134 - val_recall_1: 0.8134
Epoch 6/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.8109 - precision_1: 0.8011 - recall_1: 0.8465 - val_loss: 0.4486 - val_accuracy: 0.7941 - val_precision_1: 0.8148 - val_recall_1: 0.8209
Epoch 7/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8193 - precision_1: 0.8112 - recall_1: 0.8505 - val_loss: 0.4322 - val_accuracy: 0.8067 - val_precision_1: 0.8188 - val_recall_1: 0.8433
Epoch 8/256
30/30 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8246 - precision_1: 0.8178 - recall_1: 0.8525 - val_loss: 0.4169 - val_accuracy: 0.8067 - val_precision_1: 0.8188 - val_recall_1: 0.8433
Epoch 9/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8340 - precision_1: 0.8285 - recall_1: 0.8586 - val_loss: 0.4030 - val_accuracy: 0.8109 - val_precision_1: 0.8248 - val_recall_1: 0.8433
Epoch 10/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8382 - precision_1: 0.8324 - recall_1: 0.8626 - val_loss: 0.3908 - val_accuracy: 0.8277 - val_precision_1: 0.8394 - val_recall_1: 0.8582
Epoch 11/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3704 - accuracy: 0.8435 - precision_1: 0.8379 - recall_1: 0.8667 - val_loss: 0.3792 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 12/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8466 - precision_1: 0.8428 - recall_1: 0.8667 - val_loss: 0.3683 - val_accuracy: 0.8319 - val_precision_1: 0.8507 - val_recall_1: 0.8507
Epoch 13/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8508 - precision_1: 0.8468 - recall_1: 0.8707 - val_loss: 0.3582 - val_accuracy: 0.8403 - val_precision_1: 0.8582 - val_recall_1: 0.8582
Epoch 14/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8571 - precision_1: 0.8540 - recall_1: 0.8747 - val_loss: 0.3481 - val_accuracy: 0.8571 - val_precision_1: 0.8623 - val_recall_1: 0.8881
Epoch 15/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8592 - precision_1: 0.8546 - recall_1: 0.8788 - val_loss: 0.3393 - val_accuracy: 0.8613 - val_precision_1: 0.8686 - val_recall_1: 0.8881
Epoch 16/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8624 - precision_1: 0.8569 - recall_1: 0.8828 - val_loss: 0.3310 - val_accuracy: 0.8655 - val_precision_1: 0.8696 - val_recall_1: 0.8955
Epoch 17/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8676 - precision_1: 0.8639 - recall_1: 0.8848 - val_loss: 0.3226 - val_accuracy: 0.8697 - val_precision_1: 0.8759 - val_recall_1: 0.8955
Epoch 18/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8729 - precision_1: 0.8696 - recall_1: 0.8889 - val_loss: 0.3148 - val_accuracy: 0.8655 - val_precision_1: 0.8750 - val_recall_1: 0.8881
Epoch 19/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3097 - accuracy: 0.8729 - precision_1: 0.8696 - recall_1: 0.8889 - val_loss: 0.3077 - val_accuracy: 0.8655 - val_precision_1: 0.8750 - val_recall_1: 0.8881
Epoch 20/256
30/30 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8729 - precision_1: 0.8696 - recall_1: 0.8889 - val_loss: 0.3008 - val_accuracy: 0.8655 - val_precision_1: 0.8750 - val_recall_1: 0.8881
Epoch 21/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8729 - precision_1: 0.8681 - recall_1: 0.8909 - val_loss: 0.2941 - val_accuracy: 0.8655 - val_precision_1: 0.8750 - val_recall_1: 0.8881
Epoch 22/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8718 - precision_1: 0.8679 - recall_1: 0.8889 - val_loss: 0.2876 - val_accuracy: 0.8739 - val_precision_1: 0.8881 - val_recall_1: 0.8881
Epoch 23/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8771 - precision_1: 0.8735 - recall_1: 0.8929 - val_loss: 0.2817 - val_accuracy: 0.8782 - val_precision_1: 0.8947 - val_recall_1: 0.8881
Epoch 24/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.8782 - precision_1: 0.8738 - recall_1: 0.8949 - val_loss: 0.2761 - val_accuracy: 0.8782 - val_precision_1: 0.8947 - val_recall_1: 0.8881
Epoch 25/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8782 - precision_1: 0.8738 - recall_1: 0.8949 - val_loss: 0.2706 - val_accuracy: 0.8824 - val_precision_1: 0.8955 - val_recall_1: 0.8955
Epoch 26/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8834 - precision_1: 0.8750 - recall_1: 0.9051 - val_loss: 0.2652 - val_accuracy: 0.8824 - val_precision_1: 0.8955 - val_recall_1: 0.8955
Epoch 27/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8866 - precision_1: 0.8757 - recall_1: 0.9111 - val_loss: 0.2601 - val_accuracy: 0.8908 - val_precision_1: 0.9030 - val_recall_1: 0.9030
Epoch 28/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2665 - accuracy: 0.8939 - precision_1: 0.8818 - recall_1: 0.9192 - val_loss: 0.2551 - val_accuracy: 0.8950 - val_precision_1: 0.9037 - val_recall_1: 0.9104
Epoch 29/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8950 - precision_1: 0.8820 - recall_1: 0.9212 - val_loss: 0.2506 - val_accuracy: 0.8950 - val_precision_1: 0.9037 - val_recall_1: 0.9104
Epoch 30/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8960 - precision_1: 0.8822 - recall_1: 0.9232 - val_loss: 0.2459 - val_accuracy: 0.9034 - val_precision_1: 0.9051 - val_recall_1: 0.9254
Epoch 31/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9013 - precision_1: 0.8893 - recall_1: 0.9253 - val_loss: 0.2416 - val_accuracy: 0.9076 - val_precision_1: 0.9058 - val_recall_1: 0.9328
Epoch 32/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9023 - precision_1: 0.8911 - recall_1: 0.9253 - val_loss: 0.2375 - val_accuracy: 0.9118 - val_precision_1: 0.9124 - val_recall_1: 0.9328
Epoch 33/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 0.9055 - precision_1: 0.8947 - recall_1: 0.9273 - val_loss: 0.2335 - val_accuracy: 0.9118 - val_precision_1: 0.9124 - val_recall_1: 0.9328
Epoch 34/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9065 - precision_1: 0.8965 - recall_1: 0.9273 - val_loss: 0.2299 - val_accuracy: 0.9118 - val_precision_1: 0.9124 - val_recall_1: 0.9328
Epoch 35/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2417 - accuracy: 0.9097 - precision_1: 0.8986 - recall_1: 0.9313 - val_loss: 0.2261 - val_accuracy: 0.9160 - val_precision_1: 0.9191 - val_recall_1: 0.9328
Epoch 36/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2386 - accuracy: 0.9107 - precision_1: 0.8988 - recall_1: 0.9333 - val_loss: 0.2226 - val_accuracy: 0.9160 - val_precision_1: 0.9191 - val_recall_1: 0.9328
Epoch 37/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.9107 - precision_1: 0.8988 - recall_1: 0.9333 - val_loss: 0.2191 - val_accuracy: 0.9286 - val_precision_1: 0.9398 - val_recall_1: 0.9328
Epoch 38/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9139 - precision_1: 0.9010 - recall_1: 0.9374 - val_loss: 0.2159 - val_accuracy: 0.9286 - val_precision_1: 0.9398 - val_recall_1: 0.9328
Epoch 39/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9160 - precision_1: 0.9045 - recall_1: 0.9374 - val_loss: 0.2126 - val_accuracy: 0.9370 - val_precision_1: 0.9542 - val_recall_1: 0.9328
Epoch 40/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9170 - precision_1: 0.9062 - recall_1: 0.9374 - val_loss: 0.2095 - val_accuracy: 0.9370 - val_precision_1: 0.9542 - val_recall_1: 0.9328
Epoch 41/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2242 - accuracy: 0.9170 - precision_1: 0.9047 - recall_1: 0.9394 - val_loss: 0.2066 - val_accuracy: 0.9370 - val_precision_1: 0.9542 - val_recall_1: 0.9328
Epoch 42/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9170 - precision_1: 0.9047 - recall_1: 0.9394 - val_loss: 0.2037 - val_accuracy: 0.9370 - val_precision_1: 0.9542 - val_recall_1: 0.9328
Epoch 43/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9212 - precision_1: 0.9086 - recall_1: 0.9434 - val_loss: 0.2010 - val_accuracy: 0.9370 - val_precision_1: 0.9542 - val_recall_1: 0.9328
Epoch 44/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9233 - precision_1: 0.9105 - recall_1: 0.9455 - val_loss: 0.1983 - val_accuracy: 0.9412 - val_precision_1: 0.9545 - val_recall_1: 0.9403
Epoch 45/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9275 - precision_1: 0.9144 - recall_1: 0.9495 - val_loss: 0.1957 - val_accuracy: 0.9412 - val_precision_1: 0.9545 - val_recall_1: 0.9403
Epoch 46/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9286 - precision_1: 0.9162 - recall_1: 0.9495 - val_loss: 0.1931 - val_accuracy: 0.9496 - val_precision_1: 0.9552 - val_recall_1: 0.9552
Epoch 47/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9286 - precision_1: 0.9146 - recall_1: 0.9515 - val_loss: 0.1905 - val_accuracy: 0.9496 - val_precision_1: 0.9552 - val_recall_1: 0.9552
Epoch 48/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9328 - precision_1: 0.9201 - recall_1: 0.9535 - val_loss: 0.1880 - val_accuracy: 0.9496 - val_precision_1: 0.9552 - val_recall_1: 0.9552
Epoch 49/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9359 - precision_1: 0.9238 - recall_1: 0.9556 - val_loss: 0.1856 - val_accuracy: 0.9538 - val_precision_1: 0.9556 - val_recall_1: 0.9627
Epoch 50/256
30/30 [==============================] - 0s 3ms/step - loss: 0.2015 - accuracy: 0.9359 - precision_1: 0.9238 - recall_1: 0.9556 - val_loss: 0.1832 - val_accuracy: 0.9538 - val_precision_1: 0.9556 - val_recall_1: 0.9627
Epoch 51/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9391 - precision_1: 0.9243 - recall_1: 0.9616 - val_loss: 0.1810 - val_accuracy: 0.9538 - val_precision_1: 0.9556 - val_recall_1: 0.9627
Epoch 52/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9412 - precision_1: 0.9279 - recall_1: 0.9616 - val_loss: 0.1787 - val_accuracy: 0.9580 - val_precision_1: 0.9559 - val_recall_1: 0.9701
Epoch 53/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1947 - accuracy: 0.9412 - precision_1: 0.9279 - recall_1: 0.9616 - val_loss: 0.1765 - val_accuracy: 0.9580 - val_precision_1: 0.9559 - val_recall_1: 0.9701
Epoch 54/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9412 - precision_1: 0.9279 - recall_1: 0.9616 - val_loss: 0.1744 - val_accuracy: 0.9622 - val_precision_1: 0.9630 - val_recall_1: 0.9701
Epoch 55/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1902 - accuracy: 0.9422 - precision_1: 0.9297 - recall_1: 0.9616 - val_loss: 0.1722 - val_accuracy: 0.9622 - val_precision_1: 0.9630 - val_recall_1: 0.9701
Epoch 56/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9443 - precision_1: 0.9333 - recall_1: 0.9616 - val_loss: 0.1701 - val_accuracy: 0.9622 - val_precision_1: 0.9630 - val_recall_1: 0.9701
Epoch 57/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9443 - precision_1: 0.9333 - recall_1: 0.9616 - val_loss: 0.1680 - val_accuracy: 0.9622 - val_precision_1: 0.9630 - val_recall_1: 0.9701
Epoch 58/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9443 - precision_1: 0.9333 - recall_1: 0.9616 - val_loss: 0.1660 - val_accuracy: 0.9664 - val_precision_1: 0.9701 - val_recall_1: 0.9701
Epoch 59/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9443 - precision_1: 0.9333 - recall_1: 0.9616 - val_loss: 0.1640 - val_accuracy: 0.9664 - val_precision_1: 0.9701 - val_recall_1: 0.9701
Epoch 60/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1796 - accuracy: 0.9454 - precision_1: 0.9335 - recall_1: 0.9636 - val_loss: 0.1620 - val_accuracy: 0.9664 - val_precision_1: 0.9701 - val_recall_1: 0.9701
Epoch 61/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.9454 - precision_1: 0.9335 - recall_1: 0.9636 - val_loss: 0.1601 - val_accuracy: 0.9706 - val_precision_1: 0.9704 - val_recall_1: 0.9776
Epoch 62/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9485 - precision_1: 0.9373 - recall_1: 0.9657 - val_loss: 0.1582 - val_accuracy: 0.9790 - val_precision_1: 0.9778 - val_recall_1: 0.9851
Epoch 63/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9506 - precision_1: 0.9392 - recall_1: 0.9677 - val_loss: 0.1563 - val_accuracy: 0.9790 - val_precision_1: 0.9778 - val_recall_1: 0.9851
Epoch 64/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9506 - precision_1: 0.9392 - recall_1: 0.9677 - val_loss: 0.1543 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 65/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9517 - precision_1: 0.9411 - recall_1: 0.9677 - val_loss: 0.1525 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 66/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1673 - accuracy: 0.9517 - precision_1: 0.9411 - recall_1: 0.9677 - val_loss: 0.1507 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 67/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9517 - precision_1: 0.9411 - recall_1: 0.9677 - val_loss: 0.1489 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 68/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9517 - precision_1: 0.9411 - recall_1: 0.9677 - val_loss: 0.1471 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 69/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9538 - precision_1: 0.9448 - recall_1: 0.9677 - val_loss: 0.1454 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 70/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9548 - precision_1: 0.9449 - recall_1: 0.9697 - val_loss: 0.1436 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 71/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1576 - accuracy: 0.9559 - precision_1: 0.9450 - recall_1: 0.9717 - val_loss: 0.1419 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 72/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9580 - precision_1: 0.9470 - recall_1: 0.9737 - val_loss: 0.1403 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 73/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9590 - precision_1: 0.9488 - recall_1: 0.9737 - val_loss: 0.1386 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 74/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9590 - precision_1: 0.9488 - recall_1: 0.9737 - val_loss: 0.1369 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 75/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9590 - precision_1: 0.9488 - recall_1: 0.9737 - val_loss: 0.1352 - val_accuracy: 0.9832 - val_precision_1: 0.9851 - val_recall_1: 0.9851
Epoch 76/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9590 - precision_1: 0.9488 - recall_1: 0.9737 - val_loss: 0.1335 - val_accuracy: 0.9874 - val_precision_1: 0.9852 - val_recall_1: 0.9925
Epoch 77/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9622 - precision_1: 0.9527 - recall_1: 0.9758 - val_loss: 0.1319 - val_accuracy: 0.9874 - val_precision_1: 0.9852 - val_recall_1: 0.9925
Epoch 78/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9653 - precision_1: 0.9547 - recall_1: 0.9798 - val_loss: 0.1302 - val_accuracy: 0.9874 - val_precision_1: 0.9852 - val_recall_1: 0.9925
Epoch 79/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9685 - precision_1: 0.9568 - recall_1: 0.9838 - val_loss: 0.1286 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 80/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9685 - precision_1: 0.9568 - recall_1: 0.9838 - val_loss: 0.1271 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 81/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9716 - precision_1: 0.9570 - recall_1: 0.9899 - val_loss: 0.1255 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 82/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1380 - accuracy: 0.9716 - precision_1: 0.9570 - recall_1: 0.9899 - val_loss: 0.1240 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 83/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9716 - precision_1: 0.9570 - recall_1: 0.9899 - val_loss: 0.1225 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 84/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9727 - precision_1: 0.9589 - recall_1: 0.9899 - val_loss: 0.1211 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 85/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9727 - precision_1: 0.9589 - recall_1: 0.9899 - val_loss: 0.1196 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 86/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9727 - precision_1: 0.9589 - recall_1: 0.9899 - val_loss: 0.1182 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 87/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9727 - precision_1: 0.9589 - recall_1: 0.9899 - val_loss: 0.1167 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 88/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9748 - precision_1: 0.9591 - recall_1: 0.9939 - val_loss: 0.1152 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 89/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9748 - precision_1: 0.9591 - recall_1: 0.9939 - val_loss: 0.1138 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 90/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9758 - precision_1: 0.9609 - recall_1: 0.9939 - val_loss: 0.1125 - val_accuracy: 0.9916 - val_precision_1: 0.9853 - val_recall_1: 1.0000
Epoch 91/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9790 - precision_1: 0.9630 - recall_1: 0.9980 - val_loss: 0.1111 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 92/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9811 - precision_1: 0.9667 - recall_1: 0.9980 - val_loss: 0.1097 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 93/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9811 - precision_1: 0.9667 - recall_1: 0.9980 - val_loss: 0.1084 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 94/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9832 - precision_1: 0.9705 - recall_1: 0.9980 - val_loss: 0.1071 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 95/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9832 - precision_1: 0.9705 - recall_1: 0.9980 - val_loss: 0.1058 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 96/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9832 - precision_1: 0.9705 - recall_1: 0.9980 - val_loss: 0.1045 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 97/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9853 - precision_1: 0.9744 - recall_1: 0.9980 - val_loss: 0.1032 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 98/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9853 - precision_1: 0.9744 - recall_1: 0.9980 - val_loss: 0.1020 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 99/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9905 - precision_1: 0.9821 - recall_1: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 100/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9895 - precision_1: 0.9802 - recall_1: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 101/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9905 - precision_1: 0.9821 - recall_1: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 102/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9905 - precision_1: 0.9821 - recall_1: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 103/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9905 - precision_1: 0.9821 - recall_1: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 104/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9926 - precision_1: 0.9861 - recall_1: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 105/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 106/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 107/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 108/256
30/30 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 109/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0989 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 110/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0976 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9958 - val_precision_1: 0.9926 - val_recall_1: 1.0000
Epoch 111/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0867 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 112/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 113/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0845 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 114/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0834 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 115/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0824 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 116/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0813 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 117/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0803 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 118/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9937 - precision_1: 0.9880 - recall_1: 1.0000 - val_loss: 0.0793 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 119/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9947 - precision_1: 0.9900 - recall_1: 1.0000 - val_loss: 0.0782 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 120/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9947 - precision_1: 0.9900 - recall_1: 1.0000 - val_loss: 0.0773 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 121/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 122/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 123/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 124/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0734 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 125/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0725 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 126/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0716 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 127/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0707 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 128/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0697 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 129/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 130/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 0.9958 - precision_1: 0.9920 - recall_1: 1.0000 - val_loss: 0.0679 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 131/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9979 - precision_1: 0.9960 - recall_1: 1.0000 - val_loss: 0.0670 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 132/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9979 - precision_1: 0.9960 - recall_1: 1.0000 - val_loss: 0.0661 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 133/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9979 - precision_1: 0.9960 - recall_1: 1.0000 - val_loss: 0.0653 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 134/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9979 - precision_1: 0.9960 - recall_1: 1.0000 - val_loss: 0.0644 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 135/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9979 - precision_1: 0.9960 - recall_1: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 136/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9979 - precision_1: 0.9960 - recall_1: 1.0000 - val_loss: 0.0627 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 137/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0619 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 138/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 139/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0603 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 140/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0595 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 141/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0587 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 142/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 143/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 144/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 145/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0557 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 146/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 147/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 148/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0535 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 149/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 150/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0521 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 151/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 152/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 153/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0501 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 154/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 155/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 156/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 157/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 158/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 159/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0463 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 160/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0457 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 161/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 162/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0444 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 163/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0438 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 164/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 165/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0427 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 166/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0421 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 167/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0416 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 168/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 169/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0404 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 170/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 171/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 172/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 173/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 174/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 175/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0373 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 176/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 177/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0363 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 178/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0358 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 179/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0353 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 180/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 181/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 182/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0339 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 183/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 184/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0330 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 185/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9989 - precision_1: 0.9980 - recall_1: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 186/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 187/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 188/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 189/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 190/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 191/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 192/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0296 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 193/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 194/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 195/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 196/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 197/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0305 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 198/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 199/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 200/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 201/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 202/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 203/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 204/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 205/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 206/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 207/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 208/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 209/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 210/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 211/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 212/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 213/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0221 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 214/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 215/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 216/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 217/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 218/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0207 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 219/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0204 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 220/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 221/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 222/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 223/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 224/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 225/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 226/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 227/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 228/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 229/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0177 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 230/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 231/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0172 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 232/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 233/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 234/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 235/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 236/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 237/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 238/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 239/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 240/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 241/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 242/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 243/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 244/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 245/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 246/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 247/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 248/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 249/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 250/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 251/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 252/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 253/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 254/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 255/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
Epoch 256/256
30/30 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000 - val_precision_1: 1.0000 - val_recall_1: 1.0000
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [183]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">one_output_in_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">one_output_in_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Overfit with output passed in'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'training data'</span><span class="p">,</span> <span class="s1">'validation data'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [184]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">output_in_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">output_in_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_accuracy'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Overfit with output passed in'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'training data'</span><span class="p">,</span> <span class="s1">'validation data'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [185]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">calc_percents</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">percent</span> <span class="o">=</span> <span class="p">{</span><span class="n">value</span><span class="p">:</span> <span class="n">count</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span><span class="p">)}</span>
  <span class="k">return</span> <span class="n">percent</span>


<span class="n">train_percet</span> <span class="o">=</span> <span class="n">calc_percents</span><span class="p">(</span><span class="n">YTRAIN</span><span class="p">)</span>
<span class="n">valid_percet</span> <span class="o">=</span> <span class="n">calc_percents</span><span class="p">(</span><span class="n">YVALID</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_percet</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">valid_percet</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>{0.0: 0.4800420168067227, 1.0: 0.5199579831932774}
{0.0: 0.4369747899159664, 1.0: 0.5630252100840336}
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [193]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [188]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">best_model</span><span class="o">.</span><span class="n">name</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[188]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'all_eights_model'</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [189]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">XVALID</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>8/8 [==============================] - 0s 1ms/step
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [190]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">XVALID</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[190]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(238, 11)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [194]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">model_performances</span><span class="p">(</span><span class="n">yvalid</span><span class="p">,</span> <span class="n">ypred</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"ROC Curve"</span><span class="p">):</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">YVALID</span><span class="p">,</span> <span class="n">ypred</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s2">"dashed"</span> <span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"b"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span> <span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="p">(</span><span class="s1">'Area under the curve: '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">),</span> <span class="mi">4</span><span class="p">)))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'False Positive Rate'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'True Positive Rate'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">model_performances</span><span class="p">(</span><span class="n">YVALID</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [195]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">model_performances</span><span class="p">(</span><span class="n">YVALID</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
